Writing to /root/.config/pip/pip.conf
Writing to /root/.config/pip/pip.conf
Writing to /root/.config/pip/pip.conf
Looking in indexes: http://cache-service.nginx-pypi-cache.svc.cluster.local/pypi/simple, https://pypi.tuna.tsinghua.edu.cn/simple
Collecting kubernetes
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/ca/ec/65f7d563aa4a62dd58777e8f6aa882f15db53b14eb29aba0c28a20f7eb26/kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)
Requirement already satisfied: certifi>=14.05.14 in /usr/local/python3.11.13/lib/python3.11/site-packages (from kubernetes) (2025.11.12)
Requirement already satisfied: six>=1.9.0 in /usr/local/python3.11.13/lib/python3.11/site-packages (from kubernetes) (1.17.0)
Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/python3.11.13/lib/python3.11/site-packages (from kubernetes) (2.9.0.post0)
Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/python3.11.13/lib/python3.11/site-packages (from kubernetes) (6.0.3)
Collecting google-auth>=1.0.1 (from kubernetes)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/aa/54/b03b568bff5748fd62327a1e36f40dcfa436eaf592fd7a481aa8bd4a3ee7/google_auth-2.46.0-py3-none-any.whl (233 kB)
Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/34/db/b10e48aa8fff7407e67470363eac595018441cf32d5e1001567a7aeba5d2/websocket_client-1.9.0-py3-none-any.whl (82 kB)
Requirement already satisfied: requests in /usr/local/python3.11.13/lib/python3.11/site-packages (from kubernetes) (2.32.5)
Collecting requests-oauthlib (from kubernetes)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)
Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c8/19/4ec628951a74043532ca2cf5d97b7b14863931476d117c471e8e2b1eb39f/urllib3-2.3.0-py3-none-any.whl (128 kB)
Collecting durationpy>=0.7 (from kubernetes)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b0/0d/9feae160378a3553fa9a339b0e9c1a048e147a4127210e286ef18b730f03/durationpy-0.10-py3-none-any.whl (3.9 kB)
Collecting cachetools<7.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/2c/fc/1d7b80d0eb7b714984ce40efc78859c022cd930e402f599d8ca9e39c78a4/cachetools-6.2.4-py3-none-any.whl (11 kB)
Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/47/8d/d529b5d697919ba8c11ad626e835d4039be708a35b0d22de83a269a6682c/pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)
Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/64/8d/0133e4eb4beed9e425d9a98ed6e081a55d195481b7632472be1af08d2f6b/rsa-4.9.1-py3-none-any.whl (34 kB)
Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/c8/f1/d6a797abb14f6283c0ddff96bbdd46937f64122b8c925cab503dd37f8214/pyasn1-0.6.1-py3-none-any.whl (83 kB)
Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/python3.11.13/lib/python3.11/site-packages (from requests->kubernetes) (3.4.4)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/python3.11.13/lib/python3.11/site-packages (from requests->kubernetes) (3.11)
Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/be/9c/92789c596b8df838baa98fa71844d84283302f7604ed565dafe5a6b5041a/oauthlib-3.3.1-py3-none-any.whl (160 kB)
Installing collected packages: durationpy, websocket-client, urllib3, pyasn1, oauthlib, cachetools, rsa, pyasn1-modules, requests-oauthlib, google-auth, kubernetes
  Attempting uninstall: urllib3
    Found existing installation: urllib3 2.5.0
    Uninstalling urllib3-2.5.0:
      Successfully uninstalled urllib3-2.5.0

Successfully installed cachetools-6.2.4 durationpy-0.10 google-auth-2.46.0 kubernetes-34.1.0 oauthlib-3.3.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-oauthlib-2.0.0 rsa-4.9.1 urllib3-2.3.0 websocket-client-1.9.0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0100  732k  100  732k    0     0  1151k      0 --:--:-- --:--:-- --:--:-- 1151k
performance
vm.swappiness = 0
kernel.numa_balancing = 0
kernel.sched_migration_cost_ns = 50000
Running test case test/registered/ascend/performance/test_ascend_qwen3_235b_w8a8_8p_in3k5_out1k5_50ms.py
The nic name matched is enp23s0f3
The nic name matched is enp23s0f3
Nic name: enp23s0f3
ENV_VAR_CASE PYTORCH_NPU_ALLOC_CONF:expandable_segments:True
ENV_VAR_CASE SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT:600
ENV_VAR_CASE HCCL_BUFFSIZE:1600
ENV_VAR_CASE HCCL_SOCKET_IFNAME:enp23s0f3
ENV_VAR_CASE GLOO_SOCKET_IFNAME:enp23s0f3
ENV_VAR_CASE HCCL_OP_EXPANSION_MODE:AIV
ENV_VAR_CASE SGLANG_ENABLE_OVERLAP_PLAN_STREAM:1
ENV_VAR_CASE SGLANG_ENABLE_SPEC_V2:1
ENV_VAR_CASE SGLANG_SCHEDULER_DECREASE_PREFILL_IDLE:1
ENV_VAR_OTHER PYTORCH_NPU_ALLOC_CONF:expandable_segments:True
ENV_VAR_OTHER SGLANG_DISAGGREGATION_BOOTSTRAP_TIMEOUT:600
ENV_VAR_OTHER HCCL_BUFFSIZE:1600
ENV_VAR_OTHER HCCL_SOCKET_IFNAME:enp23s0f3
ENV_VAR_OTHER GLOO_SOCKET_IFNAME:enp23s0f3
ENV_VAR_OTHER HCCL_OP_EXPANSION_MODE:AIV
ENV_VAR_OTHER SGLANG_ENABLE_OVERLAP_PLAN_STREAM:1
ENV_VAR_OTHER SGLANG_ENABLE_SPEC_V2:1
ENV_VAR_OTHER SGLANG_SCHEDULER_DECREASE_PREFILL_IDLE:1
command=python3 -m sglang.launch_server --model-path /root/.cache/modelscope/hub/models/vllm-ascend/Qwen3-235B-A22B-W8A8 --trust-remote-code --nnodes 1 --node-rank 0 --attention-backend ascend --device npu --quantization modelslim --max-running-requests 272 --context-length 8192 --dtype bfloat16 --chunked-prefill-size 32768 --max-prefill-tokens 32768 --speculative-algorithm EAGLE3 --speculative-draft-model-path /root/.cache/modelscope/hub/models/Qwen/Qwen3-235B-A22B-Eagle3 --speculative-num-steps 3 --speculative-eagle-topk 1 --speculative-num-draft-tokens 4 --disable-radix-cache --moe-a2a-backend deepep --deepep-mode auto --speculative-draft-model-quantization unquant --tp 16 --dp-size 16 --enable-dp-attention --enable-dp-lm-head --mem-fraction-static 0.8 --cuda-graph-bs 3 4 6 8 10 12 13 14 15 16 17 --device npu --host 127.0.0.1 --port 21000
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
[2026-01-06 22:18:54] WARNING model_config.py:814: modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-06 22:18:54] WARNING server_args.py:1776: DP attention is enabled. The chunked prefill size is adjusted to 2048 to avoid MoE kernel issues. 
[2026-01-06 22:18:54] WARNING server_args.py:1829: DeepEP MoE is enabled. The expert parallel size is adjusted to be the same as the tensor parallel size[16].
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-06 22:18:56] port 21234 is in use. Waiting for 15 seconds for port_base to be available. port_base is used by a process already. process.name()='python3'' process.cmdline()=['python3', '-m', 'sglang.launch_server', '--model-path', '/root/.cache/modelscope/hub/models/vllm-ascend/Qwen3-235B-A22B-W8A8', '--trust-remote-code', '--nnodes', '1', '--node-rank', '0', '--attention-backend', 'ascend', '--device', 'npu', '--quantization', 'modelslim', '--max-running-requests', '272', '--context-length', '8192', '--dtype', 'bfloat16', '--chunked-prefill-size', '32768', '--max-prefill-tokens', '32768', '--speculative-algorithm', 'EAGLE3', '--speculative-draft-model-path', '/root/.cache/modelscope/hub/models/Qwen/Qwen3-235B-A22B-Eagle3', '--speculative-num-steps', '3', '--speculative-eagle-topk', '1', '--speculative-num-draft-tokens', '4', '--disable-radix-cache', '--moe-a2a-backend', 'deepep', '--deepep-mode', 'auto', '--speculative-draft-model-quantization', 'unquant', '--tp', '16', '--dp-size', '16', '--enable-dp-attention', '--enable-dp-lm-head', '--mem-fraction-static', '0.8', '--cuda-graph-bs', '3', '4', '6', '8', '10', '12', '13', '14', '15', '16', '17', '--device', 'npu', '--host', '127.0.0.1', '--port', '21000'] process.status()='running' pid=799
[2026-01-06 22:18:56] port 21234 is in use. Waiting for 20 seconds for port_base to be available. port_base is used by a process already. process.name()='python3'' process.cmdline()=['python3', '-m', 'sglang.launch_server', '--model-path', '/root/.cache/modelscope/hub/models/vllm-ascend/Qwen3-235B-A22B-W8A8', '--trust-remote-code', '--nnodes', '1', '--node-rank', '0', '--attention-backend', 'ascend', '--device', 'npu', '--quantization', 'modelslim', '--max-running-requests', '272', '--context-length', '8192', '--dtype', 'bfloat16', '--chunked-prefill-size', '32768', '--max-prefill-tokens', '32768', '--speculative-algorithm', 'EAGLE3', '--speculative-draft-model-path', '/root/.cache/modelscope/hub/models/Qwen/Qwen3-235B-A22B-Eagle3', '--speculative-num-steps', '3', '--speculative-eagle-topk', '1', '--speculative-num-draft-tokens', '4', '--disable-radix-cache', '--moe-a2a-backend', 'deepep', '--deepep-mode', 'auto', '--speculative-draft-model-quantization', 'unquant', '--tp', '16', '--dp-size', '16', '--enable-dp-attention', '--enable-dp-lm-head', '--mem-fraction-static', '0.8', '--cuda-graph-bs', '3', '4', '6', '8', '10', '12', '13', '14', '15', '16', '17', '--device', 'npu', '--host', '127.0.0.1', '--port', '21000'] process.status()='running' pid=799
[2026-01-06 22:18:57] port 21234 is in use. Waiting for 25 seconds for port_base to be available. port_base is used by a process already. process.name()='python3'' process.cmdline()=['python3', '-m', 'sglang.launch_server', '--model-path', '/root/.cache/modelscope/hub/models/vllm-ascend/Qwen3-235B-A22B-W8A8', '--trust-remote-code', '--nnodes', '1', '--node-rank', '0', '--attention-backend', 'ascend', '--device', 'npu', '--quantization', 'modelslim', '--max-running-requests', '272', '--context-length', '8192', '--dtype', 'bfloat16', '--chunked-prefill-size', '32768', '--max-prefill-tokens', '32768', '--speculative-algorithm', 'EAGLE3', '--speculative-draft-model-path', '/root/.cache/modelscope/hub/models/Qwen/Qwen3-235B-A22B-Eagle3', '--speculative-num-steps', '3', '--speculative-eagle-topk', '1', '--speculative-num-draft-tokens', '4', '--disable-radix-cache', '--moe-a2a-backend', 'deepep', '--deepep-mode', 'auto', '--speculative-draft-model-quantization', 'unquant', '--tp', '16', '--dp-size', '16', '--enable-dp-attention', '--enable-dp-lm-head', '--mem-fraction-static', '0.8', '--cuda-graph-bs', '3', '4', '6', '8', '10', '12', '13', '14', '15', '16', '17', '--device', 'npu', '--host', '127.0.0.1', '--port', '21000'] process.status()='running' pid=799
[2026-01-06 22:18:57] Port is already in use. dist_init_port=21233 port_base=21234 detokenizer_port=21235 nccl_port=21242 scheduler_input_port=21238
Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/server_args.py", line 5142, in init_new
    wait_port_available(port_base, "port_base")
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py", line 675, in wait_port_available
    raise ValueError(
ValueError: port_base at 21234 is not available in 30 seconds. port_base is used by a process already. process.name()='python3'' process.cmdline()=['python3', '-m', 'sglang.launch_server', '--model-path', '/root/.cache/modelscope/hub/models/vllm-ascend/Qwen3-235B-A22B-W8A8', '--trust-remote-code', '--nnodes', '1', '--node-rank', '0', '--attention-backend', 'ascend', '--device', 'npu', '--quantization', 'modelslim', '--max-running-requests', '272', '--context-length', '8192', '--dtype', 'bfloat16', '--chunked-prefill-size', '32768', '--max-prefill-tokens', '32768', '--speculative-algorithm', 'EAGLE3', '--speculative-draft-model-path', '/root/.cache/modelscope/hub/models/Qwen/Qwen3-235B-A22B-Eagle3', '--speculative-num-steps', '3', '--speculative-eagle-topk', '1', '--speculative-num-draft-tokens', '4', '--disable-radix-cache', '--moe-a2a-backend', 'deepep', '--deepep-mode', 'auto', '--speculative-draft-model-quantization', 'unquant', '--tp', '16', '--dp-size', '16', '--enable-dp-attention', '--enable-dp-lm-head', '--mem-fraction-static', '0.8', '--cuda-graph-bs', '3', '4', '6', '8', '10', '12', '13', '14', '15', '16', '17', '--device', 'npu', '--host', '127.0.0.1', '--port', '21000'] process.status()='running' pid=799
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/launch_server.py", line 32, in <module>
    run_server(server_args)
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/launch_server.py", line 25, in run_server
    launch_server(server_args)
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/entrypoints/http_server.py", line 1704, in launch_server
    launch_subprocesses_func(server_args=server_args)
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/entrypoints/engine.py", line 107, in _launch_subprocesses
    port_args = PortArgs.init_new(server_args)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/server_args.py", line 5142, in init_new
    wait_port_available(port_base, "port_base")
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py", line 675, in wait_port_available
    raise ValueError(
ValueError: port_base at 21234 is not available in 30 seconds. port_base is used by a process already. process.name()='python3'' process.cmdline()=['python3', '-m', 'sglang.launch_server', '--model-path', '/root/.cache/modelscope/hub/models/vllm-ascend/Qwen3-235B-A22B-W8A8', '--trust-remote-code', '--nnodes', '1', '--node-rank', '0', '--attention-backend', 'ascend', '--device', 'npu', '--quantization', 'modelslim', '--max-running-requests', '272', '--context-length', '8192', '--dtype', 'bfloat16', '--chunked-prefill-size', '32768', '--max-prefill-tokens', '32768', '--speculative-algorithm', 'EAGLE3', '--speculative-draft-model-path', '/root/.cache/modelscope/hub/models/Qwen/Qwen3-235B-A22B-Eagle3', '--speculative-num-steps', '3', '--speculative-eagle-topk', '1', '--speculative-num-draft-tokens', '4', '--disable-radix-cache', '--moe-a2a-backend', 'deepep', '--deepep-mode', 'auto', '--speculative-draft-model-quantization', 'unquant', '--tp', '16', '--dp-size', '16', '--enable-dp-attention', '--enable-dp-lm-head', '--mem-fraction-static', '0.8', '--cuda-graph-bs', '3', '4', '6', '8', '10', '12', '13', '14', '15', '16', '17', '--device', 'npu', '--host', '127.0.0.1', '--port', '21000'] process.status()='running' pid=799
[ERROR] 2026-01-06-22:18:58 (PID:799, Device:-1, RankID:-1) ERR99999 UNKNOWN applicaiton exception
E
======================================================================
ERROR: setUpClass (__main__.TestQwen3_235B)
----------------------------------------------------------------------
Traceback (most recent call last):
  File "/data/d00662834/0104_dev/sglang/test/registered/ascend/performance/test_ascend_single_mix_utils.py", line 106, in setUpClass
    cls.process = popen_launch_server(
                  ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/test/test_utils.py", line 659, in popen_launch_server
    raise Exception(
Exception: Server process exited with code 1. Check server logs for errors.

----------------------------------------------------------------------
Ran 0 tests in 20.007s

FAILED (errors=1)
Finished test case test/registered/ascend/performance/test_ascend_qwen3_235b_w8a8_8p_in3k5_out1k5_50ms.py
