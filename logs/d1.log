Writing to /root/.config/pip/pip.conf
Writing to /root/.config/pip/pip.conf
Writing to /root/.config/pip/pip.conf
Looking in indexes: http://cache-service.nginx-pypi-cache.svc.cluster.local/pypi/simple, https://pypi.tuna.tsinghua.edu.cn/simple
WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab4153d0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/kubernetes/
WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab416910>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/kubernetes/
WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab417b50>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/kubernetes/
WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab428f90>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/kubernetes/
WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab429f10>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/kubernetes/
Collecting kubernetes
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ca/ec/65f7d563aa4a62dd58777e8f6aa882f15db53b14eb29aba0c28a20f7eb26/kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 7.5 MB/s  0:00:00
Requirement already satisfied: certifi>=14.05.14 in /usr/local/python3.11.13/lib/python3.11/site-packages (from kubernetes) (2025.11.12)
Requirement already satisfied: six>=1.9.0 in /usr/local/python3.11.13/lib/python3.11/site-packages (from kubernetes) (1.17.0)
Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/python3.11.13/lib/python3.11/site-packages (from kubernetes) (2.9.0.post0)
Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/python3.11.13/lib/python3.11/site-packages (from kubernetes) (6.0.3)
WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab2e8c10>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/google-auth/
WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab2e9b90>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/google-auth/
WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab2ea810>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/google-auth/
WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab2eb490>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/google-auth/
WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab2ec150>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/google-auth/
Collecting google-auth>=1.0.1 (from kubernetes)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/db/18/79e9008530b79527e0d5f79e7eef08d3b179b7f851cfd3a2f27822fbdfa9/google_auth-2.47.0-py3-none-any.whl (234 kB)
WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab2d1390>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/websocket-client/
WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab2d2310>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/websocket-client/
WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab2d3d90>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/websocket-client/
WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab2ef710>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/websocket-client/
WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab300990>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/websocket-client/
Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/34/db/b10e48aa8fff7407e67470363eac595018441cf32d5e1001567a7aeba5d2/websocket_client-1.9.0-py3-none-any.whl (82 kB)
Requirement already satisfied: requests in /usr/local/python3.11.13/lib/python3.11/site-packages (from kubernetes) (2.32.5)
WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa9e6850>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/requests-oauthlib/
WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa9e7810>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/requests-oauthlib/
WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa9e8350>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/requests-oauthlib/
WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa9e8fd0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/requests-oauthlib/
WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa9e9ad0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/requests-oauthlib/
Collecting requests-oauthlib (from kubernetes)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/3b/5d/63d4ae3b9daea098d5d6f5da83984853c1bbacd5dc826764b249fe119d24/requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)
WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa9fa690>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/urllib3/
WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa9fb510>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/urllib3/
WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa9f4190>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/urllib3/
WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa9f4cd0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/urllib3/
WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa9f5890>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/urllib3/
Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c8/19/4ec628951a74043532ca2cf5d97b7b14863931476d117c471e8e2b1eb39f/urllib3-2.3.0-py3-none-any.whl (128 kB)
WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab3159d0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/durationpy/
WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab2d1f90>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/durationpy/
WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab2d28d0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/durationpy/
WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab2d1150>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/durationpy/
WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaaa49210>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/durationpy/
Collecting durationpy>=0.7 (from kubernetes)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b0/0d/9feae160378a3553fa9a339b0e9c1a048e147a4127210e286ef18b730f03/durationpy-0.10-py3-none-any.whl (3.9 kB)
WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaaa5d510>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/pyasn1-modules/
WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaaa541d0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/pyasn1-modules/
WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab2d0310>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/pyasn1-modules/
WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab2d1490>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/pyasn1-modules/
WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffab2d3e50>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/pyasn1-modules/
Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/47/8d/d529b5d697919ba8c11ad626e835d4039be708a35b0d22de83a269a6682c/pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)
WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa8c40d0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/rsa/
WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa8c4d10>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/rsa/
WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa8c5810>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/rsa/
WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa8c6910>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/rsa/
WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa8c76d0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/rsa/
Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/64/8d/0133e4eb4beed9e425d9a98ed6e081a55d195481b7632472be1af08d2f6b/rsa-4.9.1-py3-none-any.whl (34 kB)
WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa8dd6d0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/pyasn1/
WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa8de610>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/pyasn1/
WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa8df250>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/pyasn1/
WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa8dfe10>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/pyasn1/
WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa8e4a10>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/pyasn1/
Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c8/f1/d6a797abb14f6283c0ddff96bbdd46937f64122b8c925cab503dd37f8214/pyasn1-0.6.1-py3-none-any.whl (83 kB)
Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/python3.11.13/lib/python3.11/site-packages (from requests->kubernetes) (3.4.4)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/python3.11.13/lib/python3.11/site-packages (from requests->kubernetes) (3.11)
WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa7880d0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/oauthlib/
WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa788e50>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/oauthlib/
WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaa789a10>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/oauthlib/
WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaaa5ced0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/oauthlib/
WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPConnection object at 0xffffaaa5d2d0>: Failed to establish a new connection: [Errno -2] Name or service not known')': /pypi/simple/oauthlib/
Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/be/9c/92789c596b8df838baa98fa71844d84283302f7604ed565dafe5a6b5041a/oauthlib-3.3.1-py3-none-any.whl (160 kB)
Installing collected packages: durationpy, websocket-client, urllib3, pyasn1, oauthlib, rsa, pyasn1-modules, requests-oauthlib, google-auth, kubernetes
  Attempting uninstall: urllib3
    Found existing installation: urllib3 2.5.0
    Uninstalling urllib3-2.5.0:
      Successfully uninstalled urllib3-2.5.0

Successfully installed durationpy-0.10 google-auth-2.47.0 kubernetes-34.1.0 oauthlib-3.3.1 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-oauthlib-2.0.0 rsa-4.9.1 urllib3-2.3.0 websocket-client-1.9.0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.
performance
vm.swappiness = 0
kernel.numa_balancing = 0
kernel.sched_migration_cost_ns = 50000
CANN: version=8.3.RC2
Set env for CANN 8.3
Running test case test/registered/ascend/performance/test_ascend_deepseek_r1_w8a8_2p1d_32p_in3k5_out1k5_50ms.py
The nic name matched is enp23s0f3
The nic name matched is enp23s0f3
Nic name: enp23s0f3
Init 172.22.3.244 cls.role=None!
[CI Test Method] Test_DeepSeek_R1_W8A8_2P1D.test_throughput
launch_node start ......None node started, keeping test alive for 3600 seconds

Successfully queried ConfigMap sglang-info in namespace sglang-multi-debug
Retrieved ConfigMap data: {'sglang-multi-debug-sglang-decode-0': '172.22.3.209', 'sglang-multi-debug-sglang-decode-1': '172.22.3.244', 'sglang-multi-debug-sglang-prefill-0': '172.22.3.245', 'sglang-multi-debug-sglang-prefill-1': '172.22.3.191', 'sglang-multi-debug-sglang-router-0': '172.22.3.245'}
Setting ENV_VAR ASCEND_MF_STORE_URL=tcp://172.22.3.245:24666
Launching decode node with dist_init_addr=172.22.3.209:5000
Setting ENV_VAR SGLANG_SET_CPU_AFFINITY=1
Setting ENV_VAR PYTORCH_NPU_ALLOC_CONF=expandable_segments:True
Setting ENV_VAR STREAMS_PER_DEVICE=32
Setting ENV_VAR SGLANG_NPU_USE_MLAPO=1
Setting ENV_VAR SGLANG_USE_FIA_NZ=1
Setting ENV_VAR SGLANG_ENABLE_OVERLAP_PLAN_STREAM=1
Setting ENV_VAR SGLANG_ENABLE_SPEC_V2=1
Setting ENV_VAR HCCL_BUFFSIZE=650
Setting ENV_VAR SGLANG_DEEPEP_NUM_MAX_DISPATCH_TOKENS_PER_RANK=78
Setting ENV_VAR TASK_QUEUE_ENABLE=0
Setting ENV_VAR SGLANG_SCHEDULER_SKIP_ALL_GATHER=1
Setting ENV_VAR HCCL_SOCKET_IFNAME=enp23s0f3
Setting ENV_VAR GLOO_SOCKET_IFNAME=enp23s0f3
No node-rank specified - all decode nodes will form a single instance.
Starting decode node on 172.22.3.244 with args: ['--trust-remote-code', '--attention-backend', 'ascend', '--device', 'npu', '--disaggregation-transfer-backend', 'ascend', '--nnodes', '2', '--disaggregation-mode', 'decode', '--tp-size', 32, '--dp-size', 32, '--mem-fraction-static', 0.815, '--max-running-requests', 832, '--quantization', 'modelslim', '--moe-a2a-backend', 'deepep', '--enable-dp-attention', '--deepep-mode', 'low_latency', '--enable-dp-lm-head', '--moe-dense-tp', '1', '--cuda-graph-bs', 12, 14, 16, 18, 20, 22, 24, 26, '--watchdog-timeout', 9000, '--context-length', 8192, '--speculative-algorithm', 'NEXTN', '--speculative-num-steps', 2, '--speculative-eagle-topk', 1, '--speculative-num-draft-tokens', 3, '--tokenizer-worker-num', 4, '--prefill-round-robin-balance', '--disable-shared-experts-fusion', '--dtype', 'bfloat16', '--load-balance-method', 'decode_round_robin', '--dist-init-addr', '172.22.3.209:5000', '--node-rank', '1']
command=python3 -m sglang.launch_server --model-path /root/.cache/modelscope/hub/models/Howeee/DeepSeek-R1-0528-w8a8 --trust-remote-code --attention-backend ascend --device npu --disaggregation-transfer-backend ascend --nnodes 2 --disaggregation-mode decode --tp-size 32 --dp-size 32 --mem-fraction-static 0.815 --max-running-requests 832 --quantization modelslim --moe-a2a-backend deepep --enable-dp-attention --deepep-mode low_latency --enable-dp-lm-head --moe-dense-tp 1 --cuda-graph-bs 12 14 16 18 20 22 24 26 --watchdog-timeout 9000 --context-length 8192 --speculative-algorithm NEXTN --speculative-num-steps 2 --speculative-eagle-topk 1 --speculative-num-draft-tokens 3 --tokenizer-worker-num 4 --prefill-round-robin-balance --disable-shared-experts-fusion --dtype bfloat16 --load-balance-method decode_round_robin --dist-init-addr 172.22.3.209:5000 --node-rank 1 --device npu --host 172.22.3.244 --port 8000
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
[2026-01-14 11:57:20] WARNING model_config.py:819: modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:20] WARNING server_args.py:1780: DP attention is enabled. The chunked prefill size is adjusted to 256 to avoid MoE kernel issues. 
[2026-01-14 11:57:20] WARNING server_args.py:1833: DeepEP MoE is enabled. The expert parallel size is adjusted to be the same as the tensor parallel size[32].
[2026-01-14 11:57:20] WARNING server_args.py:1975: Beta spec is enabled for eagle speculative decoding and overlap schedule is turned on.
[2026-01-14 11:57:20] WARNING server_args.py:2213: KV cache is forced as chunk cache for decode server
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:57:21] server_args=ServerArgs(model_path='/root/.cache/modelscope/hub/models/Howeee/DeepSeek-R1-0528-w8a8', tokenizer_path='/root/.cache/modelscope/hub/models/Howeee/DeepSeek-R1-0528-w8a8', tokenizer_mode='auto', tokenizer_worker_num=4, skip_tokenizer_init=False, load_format='auto', model_loader_extra_config='{}', trust_remote_code=True, context_length=8192, is_embedding=False, enable_multimodal=None, limit_mm_data_per_request=None, revision=None, model_impl='auto', host='172.22.3.244', port=8000, fastapi_root_path='', grpc_mode=False, skip_server_warmup=False, warmups=None, nccl_port=None, checkpoint_engine_wait_weights_before_ready=False, dtype='bfloat16', quantization='modelslim', quantization_param_path=None, kv_cache_dtype='auto', enable_fp32_lm_head=False, modelopt_quant=None, modelopt_checkpoint_restore_path=None, modelopt_checkpoint_save_path=None, modelopt_export_path=None, quantize_and_serve=False, rl_quant_profile=None, mem_fraction_static=0.815, max_running_requests=832, max_queued_requests=None, max_total_tokens=None, chunked_prefill_size=256, enable_dynamic_chunking=False, max_prefill_tokens=16384, prefill_max_requests=None, schedule_policy='fcfs', enable_priority_scheduling=False, abort_on_priority_when_disabled=False, schedule_low_priority_values_first=False, priority_scheduling_preemption_threshold=10, schedule_conservativeness=0.3, page_size=128, hybrid_kvcache_ratio=None, swa_full_tokens_ratio=0.8, disable_hybrid_swa_memory=False, radix_eviction_policy='lru', device='npu', tp_size=32, pp_size=1, pp_max_micro_batch_size=None, pp_async_batch_depth=0, stream_interval=1, stream_output=False, random_seed=17699833, constrained_json_whitespace_pattern=None, constrained_json_disable_any_whitespace=False, watchdog_timeout=9000.0, soft_watchdog_timeout=None, dist_timeout=None, download_dir=None, base_gpu_id=0, gpu_id_step=1, sleep_on_idle=False, custom_sigquit_handler=None, log_level='info', log_level_http=None, log_requests=False, log_requests_level=2, crash_dump_folder=None, show_time_cost=False, enable_metrics=False, enable_metrics_for_all_schedulers=False, tokenizer_metrics_custom_labels_header='x-custom-labels', tokenizer_metrics_allowed_custom_labels=None, bucket_time_to_first_token=None, bucket_inter_token_latency=None, bucket_e2e_request_latency=None, collect_tokens_histogram=False, prompt_tokens_buckets=None, generation_tokens_buckets=None, gc_warning_threshold_secs=0.0, decode_log_interval=40, enable_request_time_stats_logging=False, kv_events_config=None, enable_trace=False, otlp_traces_endpoint='localhost:4317', export_metrics_to_file=False, export_metrics_to_file_dir=None, api_key=None, served_model_name='/root/.cache/modelscope/hub/models/Howeee/DeepSeek-R1-0528-w8a8', weight_version='default', chat_template=None, completion_template=None, file_storage_path='sglang_storage', enable_cache_report=False, reasoning_parser=None, tool_call_parser=None, tool_server=None, sampling_defaults='model', dp_size=32, load_balance_method='decode_round_robin', load_watch_interval=0.1, prefill_round_robin_balance=True, dist_init_addr='172.22.3.209:5000', nnodes=2, node_rank=1, json_model_override_args='{}', preferred_sampling_params=None, enable_lora=None, max_lora_rank=None, lora_target_modules=None, lora_paths=None, max_loaded_loras=None, max_loras_per_batch=8, lora_eviction_policy='lru', lora_backend='csgmv', max_lora_chunk_size=16, attention_backend='ascend', decode_attention_backend='ascend', prefill_attention_backend='ascend', sampling_backend='pytorch', grammar_backend='xgrammar', mm_attention_backend=None, fp8_gemm_runner_backend='auto', nsa_prefill_backend='flashmla_sparse', nsa_decode_backend='fa3', disable_flashinfer_autotune=False, speculative_algorithm='EAGLE', speculative_draft_model_path='/root/.cache/modelscope/hub/models/Howeee/DeepSeek-R1-0528-w8a8', speculative_draft_model_revision=None, speculative_draft_load_format=None, speculative_num_steps=2, speculative_eagle_topk=1, speculative_num_draft_tokens=3, speculative_accept_threshold_single=1.0, speculative_accept_threshold_acc=1.0, speculative_token_map=None, speculative_attention_mode='prefill', speculative_draft_attention_backend=None, speculative_moe_runner_backend='auto', speculative_moe_a2a_backend=None, speculative_draft_model_quantization='modelslim', speculative_ngram_min_match_window_size=1, speculative_ngram_max_match_window_size=12, speculative_ngram_min_bfs_breadth=1, speculative_ngram_max_bfs_breadth=10, speculative_ngram_match_type='BFS', speculative_ngram_branch_length=18, speculative_ngram_capacity=10000000, speculative_suffix_max_tree_depth=24, speculative_suffix_max_cached_requests=50000, speculative_suffix_max_spec_factor=1.0, speculative_suffix_min_token_prob=0.1, enable_mtp=False, ep_size=32, moe_a2a_backend='deepep', moe_runner_backend='auto', flashinfer_mxfp4_moe_precision='default', enable_flashinfer_allreduce_fusion=False, deepep_mode='low_latency', ep_num_redundant_experts=0, ep_dispatch_algorithm=None, init_expert_location='trivial', enable_eplb=False, enable_async_eplb=False, eplb_algorithm='auto', eplb_rebalance_num_iterations=1000, eplb_rebalance_layers_per_chunk=None, eplb_min_rebalancing_utilization_threshold=1.0, expert_distribution_recorder_mode=None, expert_distribution_recorder_buffer_size=1000, enable_expert_distribution_metrics=False, deepep_config=None, moe_dense_tp_size=1, elastic_ep_backend=None, mooncake_ib_device=None, max_mamba_cache_size=None, mamba_ssm_dtype='float32', mamba_full_memory_ratio=0.9, mamba_scheduler_strategy='no_buffer', mamba_track_interval=256, enable_hierarchical_cache=False, hicache_ratio=2.0, hicache_size=0, hicache_write_policy='write_through', hicache_io_backend='kernel', hicache_mem_layout='layer_first', hicache_storage_backend=None, hicache_storage_prefetch_policy='best_effort', hicache_storage_backend_extra_config=None, enable_lmcache=False, kt_weight_path=None, kt_method='AMXINT4', kt_cpuinfer=None, kt_threadpool_count=2, kt_num_gpu_experts=None, kt_max_deferred_experts_per_token=None, dllm_algorithm=None, dllm_algorithm_config=None, enable_double_sparsity=False, ds_channel_config_path=None, ds_heavy_channel_num=32, ds_heavy_token_num=256, ds_heavy_channel_type='qk', ds_sparse_decode_threshold=4096, cpu_offload_gb=0, offload_group_size=-1, offload_num_in_group=1, offload_prefetch_step=1, offload_mode='cpu', multi_item_scoring_delimiter=None, disable_radix_cache=True, cuda_graph_max_bs=26, cuda_graph_bs=[12, 14, 16, 18, 20, 22, 24, 26], disable_cuda_graph=False, disable_cuda_graph_padding=False, enable_profile_cuda_graph=False, enable_cudagraph_gc=False, enable_layerwise_nvtx_marker=False, enable_nccl_nvls=False, enable_symm_mem=False, disable_flashinfer_cutlass_moe_fp4_allgather=False, enable_tokenizer_batch_encode=False, disable_tokenizer_batch_decode=False, disable_outlines_disk_cache=False, disable_custom_all_reduce=True, enable_mscclpp=False, enable_torch_symm_mem=False, disable_overlap_schedule=False, enable_mixed_chunk=False, enable_dp_attention=True, enable_dp_lm_head=True, enable_two_batch_overlap=False, enable_single_batch_overlap=False, tbo_token_distribution_threshold=0.48, enable_torch_compile=False, enable_piecewise_cuda_graph=False, enable_torch_compile_debug_mode=False, torch_compile_max_bs=32, piecewise_cuda_graph_max_tokens=4096, piecewise_cuda_graph_tokens=[4, 8, 12, 16, 20, 24, 28, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 640, 768, 896, 1024, 1152, 1280, 1408, 1536, 1664, 1792, 1920, 2048, 2176, 2304, 2432, 2560, 2688, 2816, 2944, 3072, 3200, 3328, 3456, 3584, 3712, 3840, 3968, 4096], piecewise_cuda_graph_compiler='eager', torchao_config='', enable_nan_detection=False, enable_p2p_check=False, triton_attention_reduce_in_fp32=False, triton_attention_num_kv_splits=8, triton_attention_split_tile_size=None, num_continuous_decode_steps=1, delete_ckpt_after_loading=False, enable_memory_saver=False, enable_weights_cpu_backup=False, enable_draft_weights_cpu_backup=False, allow_auto_truncate=False, enable_custom_logit_processor=False, flashinfer_mla_disable_ragged=False, disable_shared_experts_fusion=True, disable_chunked_prefix_cache=False, disable_fast_image_processor=False, keep_mm_feature_on_device=False, enable_return_hidden_states=False, enable_return_routed_experts=False, scheduler_recv_interval=1, numa_node=None, enable_deterministic_inference=False, rl_on_policy_target=None, enable_attn_tp_input_scattered=False, enable_nsa_prefill_context_parallel=False, enable_fused_qk_norm_rope=False, enable_dynamic_batch_tokenizer=False, dynamic_batch_tokenizer_batch_size=32, dynamic_batch_tokenizer_batch_timeout=0.002, debug_tensor_dump_output_folder=None, debug_tensor_dump_layers=None, debug_tensor_dump_input_file=None, debug_tensor_dump_inject=False, disaggregation_mode='decode', disaggregation_transfer_backend='ascend', disaggregation_bootstrap_port=8998, disaggregation_decode_tp=None, disaggregation_decode_dp=None, disaggregation_prefill_pp=1, disaggregation_ib_device=None, disaggregation_decode_enable_offload_kvcache=False, num_reserved_decode_tokens=512, disaggregation_decode_polling_interval=1, encoder_only=False, language_only=False, encoder_transfer_backend='zmq_to_scheduler', encoder_urls=[], custom_weight_loader=[], weight_loader_disable_mmap=False, remote_instance_weight_loader_seed_instance_ip=None, remote_instance_weight_loader_seed_instance_service_port=None, remote_instance_weight_loader_send_weights_group_ports=None, remote_instance_weight_loader_backend='nccl', remote_instance_weight_loader_start_seed_via_transfer_engine=False, enable_pdmux=False, pdmux_config_path=None, sm_group_num=8, mm_max_concurrent_calls=32, mm_per_request_timeout=10.0, enable_broadcast_mm_inputs_process=False, enable_prefix_mm_cache=False, mm_enable_dp_encoder=False, mm_process_config={}, decrypted_config_file=None, decrypted_draft_config_file=None, forward_hooks=None)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
[2026-01-14 11:57:39 DP17 TP17 EP17] Process 1453 gpu_id 1 is running on CPUs: [20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]
[2026-01-14 11:57:39 DP17 TP17 EP17] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
[2026-01-14 11:57:39 DP16 TP16 EP16] Process 1452 gpu_id 0 is running on CPUs: [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]
[2026-01-14 11:57:39 DP16 TP16 EP16] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:57:39 DP20 TP20 EP20] Process 1456 gpu_id 4 is running on CPUs: [80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]
[2026-01-14 11:57:39 DP20 TP20 EP20] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/awq.py:77: UserWarning: Only CUDA, HIP and XPU support AWQ currently.
  warnings.warn(f"Only CUDA, HIP and XPU support AWQ currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:57:39 DP29 TP29 EP29] Process 2221 gpu_id 13 is running on CPUs: [260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279]
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:57:39 DP29 TP29 EP29] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
[2026-01-14 11:57:39 DP23 TP23 EP23] Process 1459 gpu_id 7 is running on CPUs: [140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159]
[2026-01-14 11:57:39 DP23 TP23 EP23] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:57:39 DP21 TP21 EP21] Process 1457 gpu_id 5 is running on CPUs: [100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119]
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:57:39 DP18 TP18 EP18] Process 1454 gpu_id 2 is running on CPUs: [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:57:39 DP24 TP24 EP24] Process 1460 gpu_id 8 is running on CPUs: [160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179]
[2026-01-14 11:57:39 DP21 TP21 EP21] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:39 DP18 TP18 EP18] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
[2026-01-14 11:57:39 DP24 TP24 EP24] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:57:40 DP22 TP22 EP22] Process 1458 gpu_id 6 is running on CPUs: [120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139]
[2026-01-14 11:57:40 DP22 TP22 EP22] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:40 DP31 TP31 EP31] Process 2223 gpu_id 15 is running on CPUs: [300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319]
[2026-01-14 11:57:40 DP31 TP31 EP31] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:57:40 DP17 TP17 EP17] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:40 DP17 TP17 EP17] Init torch distributed begin.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
[2026-01-14 11:57:40 DP19 TP19 EP19] Process 1455 gpu_id 3 is running on CPUs: [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79]
[2026-01-14 11:57:40 DP19 TP19 EP19] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
[2026-01-14 11:57:40 DP27 TP27 EP27] Process 1463 gpu_id 11 is running on CPUs: [220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239]
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:57:40 DP27 TP27 EP27] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:57:40 DP16 TP16 EP16] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:40 DP16 TP16 EP16] Init torch distributed begin.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/layers/quantization/gguf.py:46: UserWarning: Only CUDA support GGUF quantization currently.
  warnings.warn(f"Only CUDA support GGUF quantization currently.")
[2026-01-14 11:57:40 DP26 TP26 EP26] Process 1462 gpu_id 10 is running on CPUs: [200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219]
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:57:40 DP26 TP26 EP26] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:57:40 DP20 TP20 EP20] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:40 DP20 TP20 EP20] Init torch distributed begin.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
[2026-01-14 11:57:40 DP28 TP28 EP28] Process 2220 gpu_id 12 is running on CPUs: [240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259]
[2026-01-14 11:57:40 DP28 TP28 EP28] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
[2026-01-14 11:57:40 DP30 TP30 EP30] Process 2222 gpu_id 14 is running on CPUs: [280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299]
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:57:40 DP30 TP30 EP30] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:40 DP25 TP25 EP25] Process 1461 gpu_id 9 is running on CPUs: [180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]
[2026-01-14 11:57:40 DP25 TP25 EP25] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
[2026-01-14 11:57:40 DP29 TP29 EP29] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:40 DP29 TP29 EP29] Init torch distributed begin.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
[2026-01-14 11:57:40 DP23 TP23 EP23] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:40 DP23 TP23 EP23] Init torch distributed begin.
[2026-01-14 11:57:40 DP24 TP24 EP24] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:40 DP24 TP24 EP24] Init torch distributed begin.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
[2026-01-14 11:57:40 DP21 TP21 EP21] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:40 DP21 TP21 EP21] Init torch distributed begin.
[2026-01-14 11:57:40 DP22 TP22 EP22] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:40 DP22 TP22 EP22] Init torch distributed begin.
[2026-01-14 11:57:40 DP18 TP18 EP18] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:40 DP18 TP18 EP18] Init torch distributed begin.
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:347: ImportWarning: 
    *************************************************************************************************************
    The torch.Tensor.cuda and torch.nn.Module.cuda are replaced with torch.Tensor.npu and torch.nn.Module.npu now..
    The torch.cuda.DoubleTensor is replaced with torch.npu.FloatTensor cause the double type is not supported now..
    The backend in torch.distributed.init_process_group set to hccl now..
    The torch.cuda.* and torch.cuda.amp.* are replaced with torch.npu.* and torch.npu.amp.* now..
    The device parameters have been replaced with npu in the function below:
    torch.logspace, torch.randint, torch.hann_window, torch.rand, torch.full_like, torch.ones_like, torch.rand_like, torch.randperm, torch.arange, torch.frombuffer, torch.normal, torch._empty_per_channel_affine_quantized, torch.empty_strided, torch.empty_like, torch.scalar_tensor, torch.tril_indices, torch.bartlett_window, torch.ones, torch.sparse_coo_tensor, torch.randn, torch.kaiser_window, torch.tensor, torch.triu_indices, torch.as_tensor, torch.zeros, torch.randint_like, torch.full, torch.eye, torch._sparse_csr_tensor_unsafe, torch.empty, torch._sparse_coo_tensor_unsafe, torch.blackman_window, torch.zeros_like, torch.range, torch.sparse_csr_tensor, torch.randn_like, torch.from_file, torch._cudnn_init_dropout_state, torch._empty_affine_quantized, torch.linspace, torch.hamming_window, torch.empty_quantized, torch._pin_memory, torch.load, torch.set_default_device, torch.get_device_module, torch.sparse_compressed_tensor, torch.Tensor.new_empty, torch.Tensor.new_empty_strided, torch.Tensor.new_full, torch.Tensor.new_ones, torch.Tensor.new_tensor, torch.Tensor.new_zeros, torch.Tensor.to, torch.Tensor.pin_memory, torch.nn.Module.to, torch.nn.Module.to_empty
    *************************************************************************************************************
    
  warnings.warn(msg, ImportWarning)
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/contrib/transfer_to_npu.py:276: RuntimeWarning: torch.jit.script and torch.jit.script_method will be disabled by transfer_to_npu, which currently does not support them, if you need to enable them, please do not use transfer_to_npu.
  warnings.warn(msg, RuntimeWarning)
[2026-01-14 11:57:40 DP31 TP31 EP31] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:40 DP31 TP31 EP31] Init torch distributed begin.
[2026-01-14 11:57:41 DP19 TP19 EP19] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:41 DP19 TP19 EP19] Init torch distributed begin.
[2026-01-14 11:57:41 DP27 TP27 EP27] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:41 DP27 TP27 EP27] Init torch distributed begin.
[2026-01-14 11:57:41 DP26 TP26 EP26] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:41 DP26 TP26 EP26] Init torch distributed begin.
[2026-01-14 11:57:41 DP28 TP28 EP28] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:41 DP28 TP28 EP28] Init torch distributed begin.
[2026-01-14 11:57:41 DP30 TP30 EP30] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:41 DP30 TP30 EP30] Init torch distributed begin.
[2026-01-14 11:57:41 DP25 TP25 EP25] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 11:57:41 DP25 TP25 EP25] Init torch distributed begin.
[Gloo] Rank 31 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 16 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 17 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 18 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 19 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 23 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 22 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 20 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 21 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 25 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 27 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 26 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 24 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 28 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 29 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 30 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 31 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 28 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 29 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 19 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 18 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 16 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 23 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 25 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 20 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 22 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 21 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 24 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 17 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 27 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 30 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 26 is connected to 31 peer ranks. Expected number of connected peer ranks is : 31
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[2026-01-14 11:58:05 DP29 TP29 EP29] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 11:58:05 DP31 TP31 EP31] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 11:58:05 DP30 TP30 EP30] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 11:58:05 DP28 TP28 EP28] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 11:58:05 DP21 TP21 EP21] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 11:58:05 DP22 TP22 EP22] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 11:58:05 DP26 TP26 EP26] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 11:58:05 DP20 TP20 EP20] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 11:58:05 DP24 TP24 EP24] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 11:58:05 DP19 TP19 EP19] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 11:58:05 DP27 TP27 EP27] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 11:58:05 DP23 TP23 EP23] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 11:58:05 DP17 TP17 EP17] Init torch distributed ends. mem usage=-0.00 GB
[2026-01-14 11:58:05 DP25 TP25 EP25] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 11:58:05 DP16 TP16 EP16] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 11:58:05 DP18 TP18 EP18] Init torch distributed ends. mem usage=0.00 GB
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:58:06 DP23 TP23 EP23] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP22 TP22 EP22] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP24 TP24 EP24] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP26 TP26 EP26] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP28 TP28 EP28] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP29 TP29 EP29] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP25 TP25 EP25] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP27 TP27 EP27] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP16 TP16 EP16] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP21 TP21 EP21] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP20 TP20 EP20] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP17 TP17 EP17] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP31 TP31 EP31] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP30 TP30 EP30] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP19 TP19 EP19] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP18 TP18 EP18] Ignore import error when loading sglang.srt.models.midashenglm: No module named 'torchaudio'
[2026-01-14 11:58:06 DP23 TP23 EP23] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2026-01-14 11:58:06 DP28 TP28 EP28] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2026-01-14 11:58:06 DP26 TP26 EP26] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2026-01-14 11:58:06 DP27 TP27 EP27] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2026-01-14 11:58:06 DP22 TP22 EP22] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2026-01-14 11:58:06 DP25 TP25 EP25] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2026-01-14 11:58:06 DP16 TP16 EP16] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2026-01-14 11:58:06 DP24 TP24 EP24] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2026-01-14 11:58:06 DP20 TP20 EP20] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2026-01-14 11:58:06 DP29 TP29 EP29] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2026-01-14 11:58:06 DP21 TP21 EP21] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2026-01-14 11:58:06 DP30 TP30 EP30] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2026-01-14 11:58:06 DP31 TP31 EP31] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2026-01-14 11:58:06 DP17 TP17 EP17] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2026-01-14 11:58:06 DP18 TP18 EP18] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
[2026-01-14 11:58:06 DP19 TP19 EP19] Ignore import error when loading sglang.srt.models.mindspore: No module named 'mindspore'
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
/usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/dynamo/torchair/configs/compiler_config.py:106: UserWarning: The following torchair config or properties may not take effect or report error in max-autotune mode: config.debug.aclgraph.clone_input:True
  warnings.warn(
[2026-01-14 11:58:07 DP24 TP24 EP24] Load weight begin. avail mem=60.80 GB
[2026-01-14 11:58:07 DP23 TP23 EP23] Load weight begin. avail mem=61.07 GB
[2026-01-14 11:58:07 DP22 TP22 EP22] Load weight begin. avail mem=60.81 GB
[2026-01-14 11:58:07 DP26 TP26 EP26] Load weight begin. avail mem=60.80 GB
[2026-01-14 11:58:07 DP21 TP21 EP21] Load weight begin. avail mem=61.08 GB
[2026-01-14 11:58:07 DP25 TP25 EP25] Load weight begin. avail mem=61.08 GB
[2026-01-14 11:58:07 DP20 TP20 EP20] Load weight begin. avail mem=60.80 GB
[2026-01-14 11:58:07 DP17 TP17 EP17] Load weight begin. avail mem=61.08 GB
[2026-01-14 11:58:07 DP29 TP29 EP29] Load weight begin. avail mem=61.07 GB
[2026-01-14 11:58:07 DP28 TP28 EP28] Load weight begin. avail mem=60.81 GB
[2026-01-14 11:58:07 DP16 TP16 EP16] Load weight begin. avail mem=60.73 GB
[2026-01-14 11:58:07 DP27 TP27 EP27] Load weight begin. avail mem=61.08 GB
[2026-01-14 11:58:07 DP19 TP19 EP19] Load weight begin. avail mem=61.08 GB
[2026-01-14 11:58:07 DP31 TP31 EP31] Load weight begin. avail mem=61.08 GB
[2026-01-14 11:58:07 DP30 TP30 EP30] Load weight begin. avail mem=60.80 GB
[2026-01-14 11:58:07 DP18 TP18 EP18] Load weight begin. avail mem=60.80 GB
[2026-01-14 12:01:06 DP21 TP21 EP21] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.53 GB, mem usage=41.55 GB.
[2026-01-14 12:01:06 DP16 TP16 EP16] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.18 GB, mem usage=41.55 GB.
[2026-01-14 12:01:06 DP20 TP20 EP20] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.25 GB, mem usage=41.55 GB.
[2026-01-14 12:01:06 DP28 TP28 EP28] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.26 GB, mem usage=41.55 GB.
[2026-01-14 12:01:06 DP22 TP22 EP22] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.26 GB, mem usage=41.55 GB.
[2026-01-14 12:01:06 DP24 TP24 EP24] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.25 GB, mem usage=41.55 GB.
[2026-01-14 12:01:06 DP30 TP30 EP30] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.25 GB, mem usage=41.55 GB.
[2026-01-14 12:01:06 DP17 TP17 EP17] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.53 GB, mem usage=41.55 GB.
[2026-01-14 12:01:06 DP23 TP23 EP23] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.52 GB, mem usage=41.55 GB.
[2026-01-14 12:01:06 DP26 TP26 EP26] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.25 GB, mem usage=41.55 GB.
[2026-01-14 12:01:06 DP29 TP29 EP29] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.52 GB, mem usage=41.55 GB.
[2026-01-14 12:01:06 DP31 TP31 EP31] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.53 GB, mem usage=41.55 GB.
[2026-01-14 12:01:07 DP25 TP25 EP25] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.54 GB, mem usage=41.55 GB.
[2026-01-14 12:01:07 DP18 TP18 EP18] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.25 GB, mem usage=41.55 GB.
[2026-01-14 12:01:07 DP27 TP27 EP27] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.53 GB, mem usage=41.55 GB.
[2026-01-14 12:01:07 DP19 TP19 EP19] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=19.53 GB, mem usage=41.55 GB.
[2026-01-14 12:02:22 DP31 TP31 EP31] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP30 TP30 EP30] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP29 TP29 EP29] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP28 TP28 EP28] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP26 TP26 EP26] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP27 TP27 EP27] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP24 TP24 EP24] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP25 TP25 EP25] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP23 TP23 EP23] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP22 TP22 EP22] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP21 TP21 EP21] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP20 TP20 EP20] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP19 TP19 EP19] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP18 TP18 EP18] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP17 TP17 EP17] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP16 TP16 EP16] The available memory for KV cache is 7.94 GB.
[2026-01-14 12:02:22 DP18 TP18 EP18] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP18 TP18 EP18] Memory pool end. avail mem=11.03 GB
[2026-01-14 12:02:22 DP28 TP28 EP28] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP22 TP22 EP22] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP28 TP28 EP28] Memory pool end. avail mem=11.04 GB
[2026-01-14 12:02:22 DP22 TP22 EP22] Memory pool end. avail mem=11.04 GB
[2026-01-14 12:02:22 DP16 TP16 EP16] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP16 TP16 EP16] Memory pool end. avail mem=10.96 GB
[2026-01-14 12:02:22 DP20 TP20 EP20] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP20 TP20 EP20] Memory pool end. avail mem=11.03 GB
[2026-01-14 12:02:22 DP19 TP19 EP19] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP19 TP19 EP19] Memory pool end. avail mem=11.31 GB
[2026-01-14 12:02:22 DP23 TP23 EP23] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP29 TP29 EP29] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP23 TP23 EP23] Memory pool end. avail mem=11.30 GB
[2026-01-14 12:02:22 DP29 TP29 EP29] Memory pool end. avail mem=11.30 GB
[2026-01-14 12:02:22 DP17 TP17 EP17] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP21 TP21 EP21] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP17 TP17 EP17] Memory pool end. avail mem=11.31 GB
[2026-01-14 12:02:22 DP21 TP21 EP21] Memory pool end. avail mem=11.31 GB
[2026-01-14 12:02:22 DP26 TP26 EP26] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP26 TP26 EP26] Memory pool end. avail mem=11.03 GB
[2026-01-14 12:02:22 DP30 TP30 EP30] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP31 TP31 EP31] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP30 TP30 EP30] Memory pool end. avail mem=11.03 GB
[2026-01-14 12:02:22 DP31 TP31 EP31] Memory pool end. avail mem=11.31 GB
[2026-01-14 12:02:22 DP25 TP25 EP25] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP24 TP24 EP24] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP25 TP25 EP25] Memory pool end. avail mem=11.31 GB
[2026-01-14 12:02:22 DP24 TP24 EP24] Memory pool end. avail mem=11.03 GB
[2026-01-14 12:02:22 DP27 TP27 EP27] KV Cache is allocated. #tokens: 125440, KV size: 8.22 GB
[2026-01-14 12:02:22 DP27 TP27 EP27] Memory pool end. avail mem=11.31 GB
[2026-01-14 12:02:23 DP17 TP17 EP17] Capture npu graph begin. This can take up to several minutes. avail mem=11.31 GB
[2026-01-14 12:02:23 DP28 TP28 EP28] Capture npu graph begin. This can take up to several minutes. avail mem=11.04 GB
[2026-01-14 12:02:23 DP16 TP16 EP16] Capture npu graph begin. This can take up to several minutes. avail mem=10.96 GB
[2026-01-14 12:02:23 DP22 TP22 EP22] Capture npu graph begin. This can take up to several minutes. avail mem=11.04 GB
[2026-01-14 12:02:23 DP31 TP31 EP31] Capture npu graph begin. This can take up to several minutes. avail mem=11.31 GB
[2026-01-14 12:02:23 DP20 TP20 EP20] Capture npu graph begin. This can take up to several minutes. avail mem=11.03 GB
[2026-01-14 12:02:23 DP21 TP21 EP21] Capture npu graph begin. This can take up to several minutes. avail mem=11.31 GB
[2026-01-14 12:02:23 DP29 TP29 EP29] Capture npu graph begin. This can take up to several minutes. avail mem=11.30 GB
[2026-01-14 12:02:23 DP30 TP30 EP30] Capture npu graph begin. This can take up to several minutes. avail mem=11.03 GB
[2026-01-14 12:02:23 DP18 TP18 EP18] Capture npu graph begin. This can take up to several minutes. avail mem=11.03 GB
[2026-01-14 12:02:23 DP23 TP23 EP23] Capture npu graph begin. This can take up to several minutes. avail mem=11.30 GB
[2026-01-14 12:02:23 DP26 TP26 EP26] Capture npu graph begin. This can take up to several minutes. avail mem=11.03 GB
[2026-01-14 12:02:23 DP19 TP19 EP19] Capture npu graph begin. This can take up to several minutes. avail mem=11.31 GB
[2026-01-14 12:02:23 DP27 TP27 EP27] Capture npu graph begin. This can take up to several minutes. avail mem=11.31 GB
[2026-01-14 12:02:23 DP24 TP24 EP24] Capture npu graph begin. This can take up to several minutes. avail mem=11.03 GB
[2026-01-14 12:02:23 DP25 TP25 EP25] Capture npu graph begin. This can take up to several minutes. avail mem=11.31 GB
[rank28]:[W114 12:02:28.565399377 compiler_depend.ts:198] Warning: Driver Version: "����" is invalid or not supported yet. (function operator())
[rank29]:[W114 12:02:28.565399497 compiler_depend.ts:198] Warning: Driver Version: "����" is invalid or not supported yet. (function operator())
[rank23]:[W114 12:02:28.591935868 compiler_depend.ts:198] Warning: Driver Version: "�n���" is invalid or not supported yet. (function operator())
[rank22]:[W114 12:02:28.592223190 compiler_depend.ts:198] Warning: Driver Version: "�~���" is invalid or not supported yet. (function operator())
[rank31]:[W114 12:02:28.599530058 compiler_depend.ts:198] Warning: Driver Version: "�²��" is invalid or not supported yet. (function operator())
[rank30]:[W114 12:02:28.599530128 compiler_depend.ts:198] Warning: Driver Version: "�Ã��" is invalid or not supported yet. (function operator())
[rank20]:[W114 12:02:28.600739045 compiler_depend.ts:198] Warning: Driver Version: "�����" is invalid or not supported yet. (function operator())
[rank21]:[W114 12:02:28.600738885 compiler_depend.ts:198] Warning: Driver Version: "�����" is invalid or not supported yet. (function operator())
[rank24]:[W114 12:02:28.652744461 compiler_depend.ts:198] Warning: Driver Version: "�u���" is invalid or not supported yet. (function operator())
[rank25]:[W114 12:02:28.655287414 compiler_depend.ts:198] Warning: Driver Version: "��|��" is invalid or not supported yet. (function operator())
[rank26]:[W114 12:02:28.798490784 compiler_depend.ts:198] Warning: Driver Version: "�}{��" is invalid or not supported yet. (function operator())
[rank27]:[W114 12:02:28.798493234 compiler_depend.ts:198] Warning: Driver Version: "�����" is invalid or not supported yet. (function operator())
[rank29]:[W114 12:02:28.872705088 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[rank28]:[W114 12:02:28.872705318 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[rank16]:[W114 12:02:28.899958932 compiler_depend.ts:198] Warning: Driver Version: "�����" is invalid or not supported yet. (function operator())
[rank17]:[W114 12:02:28.899959072 compiler_depend.ts:198] Warning: Driver Version: "�5���" is invalid or not supported yet. (function operator())
[rank23]:[W114 12:02:28.906144145 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[rank22]:[W114 12:02:28.906144215 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[rank30]:[W114 12:02:28.919372875 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[rank31]:[W114 12:02:28.919372605 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[rank21]:[W114 12:02:28.932422204 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[rank20]:[W114 12:02:28.932424324 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[rank24]:[W114 12:02:28.055937230 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[rank25]:[W114 12:02:28.057703319 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[rank19]:[W114 12:02:29.158948566 compiler_depend.ts:198] Warning: Driver Version: "�����" is invalid or not supported yet. (function operator())
[rank18]:[W114 12:02:29.162038462 compiler_depend.ts:198] Warning: Driver Version: "�}��" is invalid or not supported yet. (function operator())
[rank27]:[W114 12:02:29.175461364 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[rank26]:[W114 12:02:29.178850842 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[rank17]:[W114 12:02:29.220707314 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[rank16]:[W114 12:02:29.234973219 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[rank18]:[W114 12:02:29.534199097 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[rank19]:[W114 12:02:29.534198647 compiler_depend.ts:83] Warning: [Check][offset] Check input storage_offset[%ld] = 0 failed, result is untrustworthy128 (function operator())
[2026-01-14 12:02:50 DP24 TP24 EP24] Capture npu graph end. Time elapsed: 27.55 s. mem usage=6.08 GB. avail mem=4.95 GB.
[2026-01-14 12:02:50 DP23 TP23 EP23] Capture npu graph end. Time elapsed: 27.60 s. mem usage=6.07 GB. avail mem=5.23 GB.
[2026-01-14 12:02:50 DP21 TP21 EP21] Capture npu graph end. Time elapsed: 27.77 s. mem usage=6.07 GB. avail mem=5.24 GB.
[2026-01-14 12:02:50 DP26 TP26 EP26] Capture npu graph end. Time elapsed: 27.72 s. mem usage=6.08 GB. avail mem=4.95 GB.
[2026-01-14 12:02:50 DP22 TP22 EP22] Capture npu graph end. Time elapsed: 27.80 s. mem usage=6.08 GB. avail mem=4.96 GB.
[2026-01-14 12:02:50 DP25 TP25 EP25] Capture npu graph end. Time elapsed: 27.70 s. mem usage=6.07 GB. avail mem=5.24 GB.
[2026-01-14 12:02:50 DP29 TP29 EP29] Capture npu graph end. Time elapsed: 27.83 s. mem usage=6.07 GB. avail mem=5.22 GB.
[2026-01-14 12:02:50 DP20 TP20 EP20] Capture npu graph end. Time elapsed: 27.86 s. mem usage=6.07 GB. avail mem=4.95 GB.
[2026-01-14 12:02:50 DP28 TP28 EP28] Capture npu graph end. Time elapsed: 27.88 s. mem usage=6.08 GB. avail mem=4.96 GB.
[2026-01-14 12:02:50 DP17 TP17 EP17] Capture npu graph end. Time elapsed: 27.92 s. mem usage=6.08 GB. avail mem=5.24 GB.
[2026-01-14 12:02:51 DP16 TP16 EP16] Capture npu graph end. Time elapsed: 27.89 s. mem usage=6.08 GB. avail mem=4.88 GB.
[2026-01-14 12:02:51 DP19 TP19 EP19] Capture npu graph end. Time elapsed: 27.81 s. mem usage=6.07 GB. avail mem=5.24 GB.
[2026-01-14 12:02:51 DP30 TP30 EP30] Capture npu graph end. Time elapsed: 27.89 s. mem usage=6.07 GB. avail mem=4.95 GB.
[2026-01-14 12:02:51 DP31 TP31 EP31] Capture npu graph end. Time elapsed: 27.93 s. mem usage=6.07 GB. avail mem=5.24 GB.
[2026-01-14 12:02:51 DP18 TP18 EP18] Capture npu graph end. Time elapsed: 27.89 s. mem usage=6.08 GB. avail mem=4.95 GB.
[2026-01-14 12:02:51 DP27 TP27 EP27] Capture npu graph end. Time elapsed: 27.84 s. mem usage=6.07 GB. avail mem=5.24 GB.
[2026-01-14 12:02:51 DP24 TP24 EP24] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP25 TP25 EP25] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP20 TP20 EP20] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP21 TP21 EP21] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP28 TP28 EP28] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP29 TP29 EP29] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP17 TP17 EP17] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP16 TP16 EP16] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP24 TP24 EP24] Init torch distributed begin.
[2026-01-14 12:02:51 DP21 TP21 EP21] Init torch distributed begin.
[2026-01-14 12:02:51 DP20 TP20 EP20] Init torch distributed begin.
[2026-01-14 12:02:51 DP25 TP25 EP25] Init torch distributed begin.
[2026-01-14 12:02:51 DP29 TP29 EP29] Init torch distributed begin.
[2026-01-14 12:02:51 DP28 TP28 EP28] Init torch distributed begin.
[2026-01-14 12:02:51 DP17 TP17 EP17] Init torch distributed begin.
[2026-01-14 12:02:51 DP16 TP16 EP16] Init torch distributed begin.
[2026-01-14 12:02:51 DP23 TP23 EP23] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP23 TP23 EP23] Init torch distributed begin.
[2026-01-14 12:02:51 DP19 TP19 EP19] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP19 TP19 EP19] Init torch distributed begin.
[2026-01-14 12:02:51 DP31 TP31 EP31] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP31 TP31 EP31] Init torch distributed begin.
[2026-01-14 12:02:51 DP22 TP22 EP22] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP22 TP22 EP22] Init torch distributed begin.
[2026-01-14 12:02:51 DP18 TP18 EP18] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP30 TP30 EP30] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP18 TP18 EP18] Init torch distributed begin.
[2026-01-14 12:02:51 DP26 TP26 EP26] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP30 TP30 EP30] Init torch distributed begin.
[2026-01-14 12:02:51 DP26 TP26 EP26] Init torch distributed begin.
[2026-01-14 12:02:51 DP27 TP27 EP27] modelslim quantization is not fully optimized yet. The speed can be slower than non-quantized models.
[2026-01-14 12:02:51 DP27 TP27 EP27] Init torch distributed begin.
[2026-01-14 12:02:51 DP31 TP31 EP31] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 12:02:51 DP30 TP30 EP30] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 12:02:51 DP27 TP27 EP27] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 12:02:51 DP26 TP26 EP26] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 12:02:51 DP29 TP29 EP29] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 12:02:51 DP24 TP24 EP24] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 12:02:51 DP28 TP28 EP28] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 12:02:51 DP25 TP25 EP25] Init torch distributed ends. mem usage=-0.00 GB
[2026-01-14 12:02:51 DP23 TP23 EP23] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 12:02:51 DP21 TP21 EP21] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 12:02:51 DP22 TP22 EP22] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 12:02:51 DP20 TP20 EP20] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 12:02:51 DP18 TP18 EP18] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 12:02:51 DP19 TP19 EP19] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 12:02:51 DP16 TP16 EP16] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 12:02:51 DP17 TP17 EP17] Init torch distributed ends. mem usage=0.00 GB
[2026-01-14 12:02:51 DP27 TP27 EP27] Load weight begin. avail mem=5.24 GB
[2026-01-14 12:02:51 DP31 TP31 EP31] Load weight begin. avail mem=5.24 GB
[2026-01-14 12:02:51 DP26 TP26 EP26] Load weight begin. avail mem=4.95 GB
[2026-01-14 12:02:51 DP24 TP24 EP24] Load weight begin. avail mem=4.95 GB
[2026-01-14 12:02:51 DP21 TP21 EP21] Load weight begin. avail mem=5.24 GB
[2026-01-14 12:02:51 DP30 TP30 EP30] Load weight begin. avail mem=4.95 GB
[2026-01-14 12:02:51 DP25 TP25 EP25] Load weight begin. avail mem=5.24 GB
[2026-01-14 12:02:51 DP29 TP29 EP29] Load weight begin. avail mem=5.22 GB
[2026-01-14 12:02:51 DP28 TP28 EP28] Load weight begin. avail mem=4.96 GB
[2026-01-14 12:02:51 DP23 TP23 EP23] Load weight begin. avail mem=5.23 GB
[2026-01-14 12:02:51 DP22 TP22 EP22] Load weight begin. avail mem=4.96 GB
[2026-01-14 12:02:51 DP20 TP20 EP20] Load weight begin. avail mem=4.95 GB
[2026-01-14 12:02:51 DP19 TP19 EP19] Load weight begin. avail mem=5.24 GB
[2026-01-14 12:02:51 DP17 TP17 EP17] Load weight begin. avail mem=5.24 GB
[2026-01-14 12:02:51 DP16 TP16 EP16] Load weight begin. avail mem=4.88 GB
[2026-01-14 12:02:51 DP18 TP18 EP18] Load weight begin. avail mem=4.95 GB
[2026-01-14 12:03:05 DP21 TP21 EP21] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=1.03 GB, mem usage=4.21 GB.
[2026-01-14 12:03:05 DP20 TP20 EP20] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=0.74 GB, mem usage=4.21 GB.
[2026-01-14 12:03:05 DP26 TP26 EP26] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=0.74 GB, mem usage=4.21 GB.
[2026-01-14 12:03:05 DP27 TP27 EP27] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=1.03 GB, mem usage=4.21 GB.
[2026-01-14 12:03:05 DP25 TP25 EP25] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=1.03 GB, mem usage=4.21 GB.
[2026-01-14 12:03:05 DP29 TP29 EP29] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=1.02 GB, mem usage=4.21 GB.
[2026-01-14 12:03:05 DP17 TP17 EP17] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=1.04 GB, mem usage=4.20 GB.
[2026-01-14 12:03:05 DP23 TP23 EP23] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=1.02 GB, mem usage=4.20 GB.
[2026-01-14 12:03:05 DP22 TP22 EP22] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=0.76 GB, mem usage=4.21 GB.
[2026-01-14 12:03:05 DP28 TP28 EP28] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=0.76 GB, mem usage=4.21 GB.
[2026-01-14 12:03:05 DP24 TP24 EP24] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=0.74 GB, mem usage=4.21 GB.
[2026-01-14 12:03:05 DP30 TP30 EP30] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=0.74 GB, mem usage=4.21 GB.
[2026-01-14 12:03:05 DP18 TP18 EP18] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=0.74 GB, mem usage=4.21 GB.
[2026-01-14 12:03:05 DP31 TP31 EP31] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=1.03 GB, mem usage=4.20 GB.
[2026-01-14 12:03:05 DP16 TP16 EP16] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=0.68 GB, mem usage=4.20 GB.
[2026-01-14 12:03:05 DP19 TP19 EP19] Load weight end. type=DeepseekV3ForCausalLMNextN, dtype=torch.bfloat16, avail mem=1.03 GB, mem usage=4.21 GB.
[2026-01-14 12:03:05 DP31 TP31 EP31] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP30 TP30 EP30] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP29 TP29 EP29] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP28 TP28 EP28] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP27 TP27 EP27] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP26 TP26 EP26] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP25 TP25 EP25] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP24 TP24 EP24] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP23 TP23 EP23] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP22 TP22 EP22] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP21 TP21 EP21] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP20 TP20 EP20] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP19 TP19 EP19] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP18 TP18 EP18] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP17 TP17 EP17] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP16 TP16 EP16] The available memory for KV cache is -0.22 GB.
[2026-01-14 12:03:05 DP28 TP28 EP28] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP29 TP29 EP29] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP23 TP23 EP23] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP22 TP22 EP22] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP31 TP31 EP31] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP30 TP30 EP30] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP24 TP24 EP24] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP25 TP25 EP25] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP21 TP21 EP21] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP20 TP20 EP20] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP27 TP27 EP27] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP26 TP26 EP26] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP17 TP17 EP17] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP16 TP16 EP16] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP18 TP18 EP18] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP19 TP19 EP19] KV Cache is allocated. #tokens: 125440, KV size: 0.13 GB
[2026-01-14 12:03:05 DP31 TP31 EP31] Memory pool end. avail mem=0.92 GB
[2026-01-14 12:03:05 DP23 TP23 EP23] Memory pool end. avail mem=0.91 GB
[2026-01-14 12:03:05 DP29 TP29 EP29] Memory pool end. avail mem=0.90 GB
[2026-01-14 12:03:05 DP22 TP22 EP22] Memory pool end. avail mem=0.64 GB
[2026-01-14 12:03:05 DP28 TP28 EP28] Memory pool end. avail mem=0.64 GB
[2026-01-14 12:03:05 DP30 TP30 EP30] Memory pool end. avail mem=0.62 GB
[2026-01-14 12:03:05 DP24 TP24 EP24] Memory pool end. avail mem=0.63 GB
[2026-01-14 12:03:05 DP21 TP21 EP21] Memory pool end. avail mem=0.91 GB
[2026-01-14 12:03:05 DP20 TP20 EP20] Memory pool end. avail mem=0.62 GB
[2026-01-14 12:03:05 DP25 TP25 EP25] Memory pool end. avail mem=0.92 GB
[2026-01-14 12:03:05 DP17 TP17 EP17] Memory pool end. avail mem=0.91 GB
[2026-01-14 12:03:05 DP16 TP16 EP16] Memory pool end. avail mem=0.56 GB
[2026-01-14 12:03:05 DP26 TP26 EP26] Memory pool end. avail mem=0.63 GB
[2026-01-14 12:03:05 DP27 TP27 EP27] Memory pool end. avail mem=0.92 GB
[2026-01-14 12:03:05 DP18 TP18 EP18] Memory pool end. avail mem=0.62 GB
[2026-01-14 12:03:05 DP19 TP19 EP19] Memory pool end. avail mem=0.91 GB
[2026-01-14 12:03:06 DP17 TP17 EP17] Capture draft cuda graph begin. This can take up to several minutes. avail mem=4.33 GB
[2026-01-14 12:03:06 DP28 TP28 EP28] Capture draft cuda graph begin. This can take up to several minutes. avail mem=4.06 GB
[2026-01-14 12:03:06 DP29 TP29 EP29] Capture draft cuda graph begin. This can take up to several minutes. avail mem=4.32 GB
[2026-01-14 12:03:06 DP16 TP16 EP16] Capture draft cuda graph begin. This can take up to several minutes. avail mem=3.98 GB
[2026-01-14 12:03:07 DP21 TP21 EP21] Capture draft cuda graph begin. This can take up to several minutes. avail mem=4.33 GB
[2026-01-14 12:03:07 DP23 TP23 EP23] Capture draft cuda graph begin. This can take up to several minutes. avail mem=4.32 GB
[2026-01-14 12:03:07 DP22 TP22 EP22] Capture draft cuda graph begin. This can take up to several minutes. avail mem=4.06 GB
[2026-01-14 12:03:07 DP20 TP20 EP20] Capture draft cuda graph begin. This can take up to several minutes. avail mem=4.05 GB
[2026-01-14 12:03:07 DP31 TP31 EP31] Capture draft cuda graph begin. This can take up to several minutes. avail mem=4.33 GB
[2026-01-14 12:03:07 DP24 TP24 EP24] Capture draft cuda graph begin. This can take up to several minutes. avail mem=4.05 GB
[2026-01-14 12:03:07 DP30 TP30 EP30] Capture draft cuda graph begin. This can take up to several minutes. avail mem=4.05 GB
[2026-01-14 12:03:07 DP25 TP25 EP25] Capture draft cuda graph begin. This can take up to several minutes. avail mem=4.34 GB
[2026-01-14 12:03:07 DP27 TP27 EP27] Capture draft cuda graph begin. This can take up to several minutes. avail mem=4.33 GB
[2026-01-14 12:03:07 DP26 TP26 EP26] Capture draft cuda graph begin. This can take up to several minutes. avail mem=4.05 GB
[2026-01-14 12:03:07 DP19 TP19 EP19] Capture draft cuda graph begin. This can take up to several minutes. avail mem=4.33 GB
[2026-01-14 12:03:07 DP18 TP18 EP18] Capture draft cuda graph begin. This can take up to several minutes. avail mem=4.05 GB
[2026-01-14 12:03:11 DP24 TP24 EP24] Capture draft cuda graph end. Time elapsed: 4.33 s. mem usage=0.62 GB. avail mem=3.43 GB.
[2026-01-14 12:03:11 DP24 TP24 EP24] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.43 GB
[2026-01-14 12:03:11 DP23 TP23 EP23] Capture draft cuda graph end. Time elapsed: 4.57 s. mem usage=0.62 GB. avail mem=3.70 GB.
[2026-01-14 12:03:11 DP23 TP23 EP23] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.70 GB
[2026-01-14 12:03:11 DP22 TP22 EP22] Capture draft cuda graph end. Time elapsed: 4.67 s. mem usage=0.63 GB. avail mem=3.43 GB.
[2026-01-14 12:03:11 DP22 TP22 EP22] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.43 GB
[2026-01-14 12:03:11 DP21 TP21 EP21] Capture draft cuda graph end. Time elapsed: 4.76 s. mem usage=0.62 GB. avail mem=3.71 GB.
[2026-01-14 12:03:11 DP21 TP21 EP21] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.71 GB
[2026-01-14 12:03:11 DP26 TP26 EP26] Capture draft cuda graph end. Time elapsed: 4.27 s. mem usage=0.62 GB. avail mem=3.43 GB.
[2026-01-14 12:03:11 DP26 TP26 EP26] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.43 GB
[2026-01-14 12:03:11 DP25 TP25 EP25] Capture draft cuda graph end. Time elapsed: 4.41 s. mem usage=0.62 GB. avail mem=3.71 GB.
[2026-01-14 12:03:11 DP25 TP25 EP25] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.71 GB
[2026-01-14 12:03:11 DP29 TP29 EP29] Capture draft cuda graph end. Time elapsed: 4.86 s. mem usage=0.62 GB. avail mem=3.70 GB.
[2026-01-14 12:03:11 DP29 TP29 EP29] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.70 GB
[2026-01-14 12:03:11 DP20 TP20 EP20] Capture draft cuda graph end. Time elapsed: 4.74 s. mem usage=0.62 GB. avail mem=3.43 GB.
[2026-01-14 12:03:11 DP20 TP20 EP20] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.43 GB
[2026-01-14 12:03:11 DP28 TP28 EP28] Capture draft cuda graph end. Time elapsed: 4.88 s. mem usage=0.62 GB. avail mem=3.44 GB.
[2026-01-14 12:03:11 DP28 TP28 EP28] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.44 GB
[2026-01-14 12:03:11 DP17 TP17 EP17] Capture draft cuda graph end. Time elapsed: 4.98 s. mem usage=0.62 GB. avail mem=3.71 GB.
[2026-01-14 12:03:11 DP17 TP17 EP17] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.71 GB
[2026-01-14 12:03:11 DP16 TP16 EP16] Capture draft cuda graph end. Time elapsed: 4.88 s. mem usage=0.62 GB. avail mem=3.36 GB.
[2026-01-14 12:03:11 DP16 TP16 EP16] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.36 GB
[2026-01-14 12:03:11 DP27 TP27 EP27] Capture draft cuda graph end. Time elapsed: 4.42 s. mem usage=0.62 GB. avail mem=3.71 GB.
[2026-01-14 12:03:11 DP27 TP27 EP27] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.71 GB
[2026-01-14 12:03:11 DP19 TP19 EP19] Capture draft cuda graph end. Time elapsed: 4.39 s. mem usage=0.62 GB. avail mem=3.71 GB.
[2026-01-14 12:03:11 DP30 TP30 EP30] Capture draft cuda graph end. Time elapsed: 4.53 s. mem usage=0.62 GB. avail mem=3.43 GB.
[2026-01-14 12:03:11 DP19 TP19 EP19] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.71 GB
[2026-01-14 12:03:11 DP30 TP30 EP30] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.43 GB
[2026-01-14 12:03:11 DP31 TP31 EP31] Capture draft cuda graph end. Time elapsed: 4.62 s. mem usage=0.62 GB. avail mem=3.71 GB.
[2026-01-14 12:03:11 DP31 TP31 EP31] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.71 GB
[2026-01-14 12:03:11 DP18 TP18 EP18] Capture draft cuda graph end. Time elapsed: 4.38 s. mem usage=0.62 GB. avail mem=3.43 GB.
[2026-01-14 12:03:11 DP18 TP18 EP18] Capture draft extend cuda graph begin. This can take up to several minutes. avail mem=3.43 GB
[2026-01-14 12:03:14 DP24 TP24 EP24] Capture draft extend cuda graph end. Time elapsed: 2.63 s. mem usage=0.56 GB. avail mem=2.86 GB.
[2026-01-14 12:03:14 DP23 TP23 EP23] Capture draft extend cuda graph end. Time elapsed: 2.65 s. mem usage=0.55 GB. avail mem=3.14 GB.
[2026-01-14 12:03:14 DP26 TP26 EP26] Capture draft extend cuda graph end. Time elapsed: 2.62 s. mem usage=0.56 GB. avail mem=2.87 GB.
[2026-01-14 12:03:14 DP21 TP21 EP21] Capture draft extend cuda graph end. Time elapsed: 2.64 s. mem usage=0.56 GB. avail mem=3.15 GB.
[2026-01-14 12:03:14 DP22 TP22 EP22] Capture draft extend cuda graph end. Time elapsed: 2.66 s. mem usage=0.55 GB. avail mem=2.88 GB.
[2026-01-14 12:03:14 DP25 TP25 EP25] Capture draft extend cuda graph end. Time elapsed: 2.61 s. mem usage=0.56 GB. avail mem=3.16 GB.
[2026-01-14 12:03:14 DP20 TP20 EP20] Capture draft extend cuda graph end. Time elapsed: 2.63 s. mem usage=0.56 GB. avail mem=2.86 GB.
[2026-01-14 12:03:14 DP28 TP28 EP28] Capture draft extend cuda graph end. Time elapsed: 2.63 s. mem usage=0.56 GB. avail mem=2.88 GB.
[2026-01-14 12:03:14 DP29 TP29 EP29] Capture draft extend cuda graph end. Time elapsed: 2.65 s. mem usage=0.56 GB. avail mem=3.14 GB.
[2026-01-14 12:03:14 DP17 TP17 EP17] Capture draft extend cuda graph end. Time elapsed: 2.67 s. mem usage=0.56 GB. avail mem=3.15 GB.
[2026-01-14 12:03:14 DP27 TP27 EP27] Capture draft extend cuda graph end. Time elapsed: 2.61 s. mem usage=0.56 GB. avail mem=3.15 GB.
[2026-01-14 12:03:14 DP16 TP16 EP16] Capture draft extend cuda graph end. Time elapsed: 2.65 s. mem usage=0.55 GB. avail mem=2.80 GB.
[2026-01-14 12:03:14 DP19 TP19 EP19] Capture draft extend cuda graph end. Time elapsed: 2.62 s. mem usage=0.56 GB. avail mem=3.15 GB.
[2026-01-14 12:03:14 DP18 TP18 EP18] Capture draft extend cuda graph end. Time elapsed: 2.62 s. mem usage=0.56 GB. avail mem=2.87 GB.
[2026-01-14 12:03:14 DP30 TP30 EP30] Capture draft extend cuda graph end. Time elapsed: 2.64 s. mem usage=0.56 GB. avail mem=2.87 GB.
[2026-01-14 12:03:14 DP31 TP31 EP31] Capture draft extend cuda graph end. Time elapsed: 2.63 s. mem usage=0.56 GB. avail mem=3.15 GB.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 50158), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 39490), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
[2026-01-14 12:03:14 DP24 TP24 EP24] Invalid or no transfer protocol specified, using default protocol.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 45914), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 47246), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
[2026-01-14 12:03:14 DP23 TP23 EP23] Invalid or no transfer protocol specified, using default protocol.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 44245), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 48371), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 50369), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 43994), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
[2026-01-14 12:03:14 DP21 TP21 EP21] Invalid or no transfer protocol specified, using default protocol.
[2026-01-14 12:03:14 DP26 TP26 EP26] Invalid or no transfer protocol specified, using default protocol.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 45137), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 44439), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 58086), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 36270), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
[2026-01-14 12:03:14 DP22 TP22 EP22] Invalid or no transfer protocol specified, using default protocol.
[2026-01-14 12:03:14 DP25 TP25 EP25] Invalid or no transfer protocol specified, using default protocol.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 55263), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 40632), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
[2026-01-14 12:03:14 DP20 TP20 EP20] Invalid or no transfer protocol specified, using default protocol.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 59485), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 48756), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
[2026-01-14 12:03:14 DP28 TP28 EP28] Invalid or no transfer protocol specified, using default protocol.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 54786), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 34602), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
[2026-01-14 12:03:14 DP29 TP29 EP29] Invalid or no transfer protocol specified, using default protocol.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 44869), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 52742), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
[2026-01-14 12:03:15 DP27 TP27 EP27] Invalid or no transfer protocol specified, using default protocol.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 60164), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 45327), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 55085), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
[2026-01-14 12:03:15 DP17 TP17 EP17] Invalid or no transfer protocol specified, using default protocol.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 53016), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
[2026-01-14 12:03:15 DP16 TP16 EP16] Invalid or no transfer protocol specified, using default protocol.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 51847), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 47686), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
[2026-01-14 12:03:15 DP19 TP19 EP19] Invalid or no transfer protocol specified, using default protocol.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 38828), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 38331), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 36065), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
[2026-01-14 12:03:15 DP31 TP31 EP31] Invalid or no transfer protocol specified, using default protocol.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 34159), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
[2026-01-14 12:03:15 DP30 TP30 EP30] Invalid or no transfer protocol specified, using default protocol.
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=210, family=2, type=2, proto=0, laddr=('172.22.3.244', 57945), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/utils/common.py:2698: ResourceWarning: unclosed <socket.socket fd=217, family=2, type=2, proto=0, laddr=('172.22.3.244', 48026), raddr=('8.8.8.8', 80)>
  if ip := get_local_ip_by_remote():
[2026-01-14 12:03:15 DP18 TP18 EP18] Invalid or no transfer protocol specified, using default protocol.
[2026-01-14 12:03:25] Dummy health check server started in background thread at 172.22.3.244:8000
[2026-01-14 12:09:46 DP16 TP16 EP16] Decode batch, #running-req: 17, #token: 86400, token usage: 0.69, accept len: 2.67, accept rate: 0.89, pre-allocated usage: 0.14, #prealloc-req: 0, #transfer-req: 5, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.47, #queue-req: 0, 
[2026-01-14 12:09:46 DP18 TP18 EP18] Decode batch, #running-req: 17, #token: 86528, token usage: 0.69, accept len: 2.60, accept rate: 0.87, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.33, #queue-req: 0, 
[2026-01-14 12:09:48 DP19 TP19 EP19] Decode batch, #running-req: 18, #token: 90496, token usage: 0.72, accept len: 2.66, accept rate: 0.89, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.51, #queue-req: 0, 
[2026-01-14 12:09:48 DP26 TP26 EP26] Decode batch, #running-req: 19, #token: 90112, token usage: 0.72, accept len: 2.65, accept rate: 0.88, pre-allocated usage: 0.14, #prealloc-req: 0, #transfer-req: 5, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.49, #queue-req: 0, 
[2026-01-14 12:09:48 DP25 TP25 EP25] Decode batch, #running-req: 19, #token: 90752, token usage: 0.72, accept len: 2.67, accept rate: 0.89, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.52, #queue-req: 0, 
[2026-01-14 12:09:48 DP22 TP22 EP22] Decode batch, #running-req: 17, #token: 90752, token usage: 0.72, accept len: 2.67, accept rate: 0.89, pre-allocated usage: 0.22, #prealloc-req: 0, #transfer-req: 8, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.67, #queue-req: 0, 
[2026-01-14 12:09:48 DP20 TP20 EP20] Decode batch, #running-req: 19, #token: 90240, token usage: 0.72, accept len: 2.63, accept rate: 0.88, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.43, #queue-req: 0, 
[2026-01-14 12:09:48 DP23 TP23 EP23] Decode batch, #running-req: 20, #token: 90624, token usage: 0.72, accept len: 2.69, accept rate: 0.90, pre-allocated usage: 0.14, #prealloc-req: 0, #transfer-req: 5, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.64, #queue-req: 0, 
[2026-01-14 12:09:48 DP28 TP28 EP28] Decode batch, #running-req: 17, #token: 90624, token usage: 0.72, accept len: 2.57, accept rate: 0.86, pre-allocated usage: 0.22, #prealloc-req: 0, #transfer-req: 8, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.43, #queue-req: 0, 
[2026-01-14 12:09:48 DP31 TP31 EP31] Decode batch, #running-req: 17, #token: 90752, token usage: 0.72, accept len: 2.67, accept rate: 0.89, pre-allocated usage: 0.22, #prealloc-req: 0, #transfer-req: 8, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.43, #queue-req: 0, 
[2026-01-14 12:09:48 DP27 TP27 EP27] Decode batch, #running-req: 17, #token: 90624, token usage: 0.72, accept len: 2.72, accept rate: 0.91, pre-allocated usage: 0.22, #prealloc-req: 0, #transfer-req: 8, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.38, #queue-req: 0, 
[2026-01-14 12:09:48 DP29 TP29 EP29] Decode batch, #running-req: 19, #token: 90368, token usage: 0.72, accept len: 2.66, accept rate: 0.89, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.52, #queue-req: 0, 
[2026-01-14 12:09:48 DP30 TP30 EP30] Decode batch, #running-req: 20, #token: 90624, token usage: 0.72, accept len: 2.58, accept rate: 0.86, pre-allocated usage: 0.14, #prealloc-req: 0, #transfer-req: 5, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.50, #queue-req: 0, 
[2026-01-14 12:09:48 DP17 TP17 EP17] Decode batch, #running-req: 19, #token: 90624, token usage: 0.72, accept len: 2.62, accept rate: 0.87, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.46, #queue-req: 0, 
[2026-01-14 12:09:48 DP24 TP24 EP24] Decode batch, #running-req: 19, #token: 90624, token usage: 0.72, accept len: 2.65, accept rate: 0.88, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.62, #queue-req: 0, 
[2026-01-14 12:09:49 DP21 TP21 EP21] Decode batch, #running-req: 19, #token: 90752, token usage: 0.72, accept len: 2.65, accept rate: 0.88, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 1.65, #queue-req: 0, 
[2026-01-14 12:09:52 DP16 TP16 EP16] Decode batch, #running-req: 20, #token: 95616, token usage: 0.76, accept len: 2.70, accept rate: 0.90, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 359.20, #queue-req: 0, 
[2026-01-14 12:09:52 DP18 TP18 EP18] Decode batch, #running-req: 20, #token: 95616, token usage: 0.76, accept len: 2.60, accept rate: 0.87, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 324.20, #queue-req: 0, 
[2026-01-14 12:09:52 DP25 TP25 EP25] Decode batch, #running-req: 20, #token: 95616, token usage: 0.76, accept len: 2.70, accept rate: 0.90, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 519.92, #queue-req: 0, 
[2026-01-14 12:09:52 DP22 TP22 EP22] Decode batch, #running-req: 19, #token: 95488, token usage: 0.76, accept len: 2.68, accept rate: 0.89, pre-allocated usage: 0.20, #prealloc-req: 0, #transfer-req: 7, #retracted-req: 0, npu graph: True, gen throughput (token/s): 467.77, #queue-req: 0, 
[2026-01-14 12:09:52 DP19 TP19 EP19] Decode batch, #running-req: 21, #token: 95616, token usage: 0.76, accept len: 2.70, accept rate: 0.90, pre-allocated usage: 0.14, #prealloc-req: 0, #transfer-req: 5, #retracted-req: 0, npu graph: True, gen throughput (token/s): 505.99, #queue-req: 0, 
[2026-01-14 12:09:52 DP26 TP26 EP26] Decode batch, #running-req: 21, #token: 95744, token usage: 0.76, accept len: 2.67, accept rate: 0.89, pre-allocated usage: 0.14, #prealloc-req: 0, #transfer-req: 5, #retracted-req: 0, npu graph: True, gen throughput (token/s): 527.27, #queue-req: 0, 
[2026-01-14 12:09:52 DP20 TP20 EP20] Decode batch, #running-req: 20, #token: 95616, token usage: 0.76, accept len: 2.67, accept rate: 0.89, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 514.05, #queue-req: 0, 
[2026-01-14 12:09:52 DP27 TP27 EP27] Decode batch, #running-req: 18, #token: 95488, token usage: 0.76, accept len: 2.75, accept rate: 0.92, pre-allocated usage: 0.22, #prealloc-req: 0, #transfer-req: 8, #retracted-req: 0, npu graph: True, gen throughput (token/s): 470.20, #queue-req: 0, 
[2026-01-14 12:09:52 DP30 TP30 EP30] Decode batch, #running-req: 21, #token: 95872, token usage: 0.76, accept len: 2.66, accept rate: 0.89, pre-allocated usage: 0.14, #prealloc-req: 0, #transfer-req: 5, #retracted-req: 0, npu graph: True, gen throughput (token/s): 531.58, #queue-req: 0, 
[2026-01-14 12:09:52 DP23 TP23 EP23] Decode batch, #running-req: 22, #token: 96000, token usage: 0.77, accept len: 2.78, accept rate: 0.93, pre-allocated usage: 0.11, #prealloc-req: 0, #transfer-req: 4, #retracted-req: 0, npu graph: True, gen throughput (token/s): 546.75, #queue-req: 0, 
[2026-01-14 12:09:52 DP31 TP31 EP31] Decode batch, #running-req: 19, #token: 95744, token usage: 0.76, accept len: 2.69, accept rate: 0.90, pre-allocated usage: 0.20, #prealloc-req: 0, #transfer-req: 7, #retracted-req: 0, npu graph: True, gen throughput (token/s): 469.11, #queue-req: 0, 
[2026-01-14 12:09:53 DP17 TP17 EP17] Decode batch, #running-req: 20, #token: 95744, token usage: 0.76, accept len: 2.71, accept rate: 0.90, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 516.63, #queue-req: 0, 
[2026-01-14 12:09:53 DP29 TP29 EP29] Decode batch, #running-req: 21, #token: 95872, token usage: 0.76, accept len: 2.68, accept rate: 0.89, pre-allocated usage: 0.14, #prealloc-req: 0, #transfer-req: 5, #retracted-req: 0, npu graph: True, gen throughput (token/s): 516.40, #queue-req: 0, 
[2026-01-14 12:09:53 DP28 TP28 EP28] Decode batch, #running-req: 20, #token: 95360, token usage: 0.76, accept len: 2.59, accept rate: 0.86, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 441.77, #queue-req: 0, 
[2026-01-14 12:09:53 DP24 TP24 EP24] Decode batch, #running-req: 20, #token: 95744, token usage: 0.76, accept len: 2.69, accept rate: 0.90, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 511.75, #queue-req: 0, 
[2026-01-14 12:09:53 DP21 TP21 EP21] Decode batch, #running-req: 20, #token: 96000, token usage: 0.77, accept len: 2.67, accept rate: 0.89, pre-allocated usage: 0.17, #prealloc-req: 0, #transfer-req: 6, #retracted-req: 0, npu graph: True, gen throughput (token/s): 517.40, #queue-req: 0, 
[2026-01-14 12:10:01 DP16 TP16 EP16] Decode batch, #running-req: 22, #token: 98176, token usage: 0.78, accept len: 2.66, accept rate: 0.89, pre-allocated usage: 0.11, #prealloc-req: 0, #transfer-req: 4, #retracted-req: 0, npu graph: True, gen throughput (token/s): 246.16, #queue-req: 0, 
[2026-01-14 12:10:01 DP26 TP26 EP26] Decode batch, #running-req: 21, #token: 98304, token usage: 0.78, accept len: 2.61, accept rate: 0.87, pre-allocated usage: 0.14, #prealloc-req: 0, #transfer-req: 5, #retracted-req: 0, npu graph: True, gen throughput (token/s): 238.23, #queue-req: 0, 
[2026-01-14 12:10:02 DP25 TP25 EP25] Decode batch, #running-req: 23, #token: 98176, token usage: 0.78, accept len: 2.61, accept rate: 0.87, pre-allocated usage: 0.08, #prealloc-req: 0, #transfer-req: 3, #retracted-req: 0, npu graph: True, gen throughput (token/s): 241.40, #queue-req: 0, 
[2026-01-14 12:10:02 DP18 TP18 EP18] Decode batch, #running-req: 23, #token: 97664, token usage: 0.78, accept len: 2.56, accept rate: 0.85, pre-allocated usage: 0.08, #prealloc-req: 0, #transfer-req: 3, #retracted-req: 0, npu graph: True, gen throughput (token/s): 235.41, #queue-req: 0, 
[2026-01-14 12:10:02 DP19 TP19 EP19] Decode batch, #running-req: 24, #token: 98304, token usage: 0.78, accept len: 2.70, accept rate: 0.90, pre-allocated usage: 0.03, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, npu graph: True, gen throughput (token/s): 252.25, #queue-req: 0, 
[2026-01-14 12:10:02 DP22 TP22 EP22] Decode batch, #running-req: 23, #token: 97792, token usage: 0.78, accept len: 2.65, accept rate: 0.88, pre-allocated usage: 0.06, #prealloc-req: 0, #transfer-req: 2, #retracted-req: 0, npu graph: True, gen throughput (token/s): 240.37, #queue-req: 0, 
[2026-01-14 12:10:02 DP20 TP20 EP20] Decode batch, #running-req: 23, #token: 98048, token usage: 0.78, accept len: 2.69, accept rate: 0.90, pre-allocated usage: 0.08, #prealloc-req: 0, #transfer-req: 3, #retracted-req: 0, npu graph: True, gen throughput (token/s): 241.48, #queue-req: 0, 
[2026-01-14 12:10:02 DP23 TP23 EP23] Decode batch, #running-req: 24, #token: 98688, token usage: 0.79, accept len: 2.75, accept rate: 0.92, pre-allocated usage: 0.06, #prealloc-req: 0, #transfer-req: 2, #retracted-req: 0, npu graph: True, gen throughput (token/s): 273.92, #queue-req: 0, 
[2026-01-14 12:10:02 DP28 TP28 EP28] Decode batch, #running-req: 22, #token: 97920, token usage: 0.78, accept len: 2.55, accept rate: 0.85, pre-allocated usage: 0.11, #prealloc-req: 0, #transfer-req: 4, #retracted-req: 0, npu graph: True, gen throughput (token/s): 236.05, #queue-req: 0, 
[2026-01-14 12:10:02 DP31 TP31 EP31] Decode batch, #running-req: 23, #token: 97792, token usage: 0.78, accept len: 2.67, accept rate: 0.89, pre-allocated usage: 0.08, #prealloc-req: 0, #transfer-req: 3, #retracted-req: 0, npu graph: True, gen throughput (token/s): 246.02, #queue-req: 0, 
[2026-01-14 12:10:02 DP30 TP30 EP30] Decode batch, #running-req: 24, #token: 98560, token usage: 0.79, accept len: 2.67, accept rate: 0.89, pre-allocated usage: 0.06, #prealloc-req: 0, #transfer-req: 2, #retracted-req: 0, npu graph: True, gen throughput (token/s): 251.84, #queue-req: 0, 
[2026-01-14 12:10:02 DP27 TP27 EP27] Decode batch, #running-req: 24, #token: 97664, token usage: 0.78, accept len: 2.64, accept rate: 0.88, pre-allocated usage: 0.06, #prealloc-req: 0, #transfer-req: 2, #retracted-req: 0, npu graph: True, gen throughput (token/s): 232.94, #queue-req: 0, 
[2026-01-14 12:10:02 DP29 TP29 EP29] Decode batch, #running-req: 25, #token: 98560, token usage: 0.79, accept len: 2.73, accept rate: 0.91, pre-allocated usage: 0.03, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, npu graph: True, gen throughput (token/s): 270.21, #queue-req: 0, 
[2026-01-14 12:10:02 DP24 TP24 EP24] Decode batch, #running-req: 23, #token: 98048, token usage: 0.78, accept len: 2.72, accept rate: 0.91, pre-allocated usage: 0.08, #prealloc-req: 0, #transfer-req: 3, #retracted-req: 0, npu graph: True, gen throughput (token/s): 249.79, #queue-req: 0, 
[2026-01-14 12:10:02 DP17 TP17 EP17] Decode batch, #running-req: 25, #token: 98560, token usage: 0.79, accept len: 2.70, accept rate: 0.90, pre-allocated usage: 0.03, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, npu graph: True, gen throughput (token/s): 269.48, #queue-req: 0, 
[2026-01-14 12:10:02 DP21 TP21 EP21] Decode batch, #running-req: 24, #token: 97920, token usage: 0.78, accept len: 2.65, accept rate: 0.88, pre-allocated usage: 0.06, #prealloc-req: 0, #transfer-req: 2, #retracted-req: 0, npu graph: True, gen throughput (token/s): 246.19, #queue-req: 0, 
[2026-01-14 12:10:06 DP16 TP16 EP16] Decode batch, #running-req: 25, #token: 100480, token usage: 0.80, accept len: 2.65, accept rate: 0.88, pre-allocated usage: 0.03, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, npu graph: True, gen throughput (token/s): 551.74, #queue-req: 0, 
[2026-01-14 12:10:06 DP25 TP25 EP25] Decode batch, #running-req: 24, #token: 100608, token usage: 0.80, accept len: 2.55, accept rate: 0.85, pre-allocated usage: 0.06, #prealloc-req: 0, #transfer-req: 2, #retracted-req: 0, npu graph: True, gen throughput (token/s): 547.14, #queue-req: 0, 
[2026-01-14 12:10:06 DP26 TP26 EP26] Decode batch, #running-req: 23, #token: 100224, token usage: 0.80, accept len: 2.56, accept rate: 0.85, pre-allocated usage: 0.08, #prealloc-req: 0, #transfer-req: 3, #retracted-req: 0, npu graph: True, gen throughput (token/s): 491.48, #queue-req: 0, 
[2026-01-14 12:10:06 DP18 TP18 EP18] Decode batch, #running-req: 24, #token: 100480, token usage: 0.80, accept len: 2.62, accept rate: 0.87, pre-allocated usage: 0.06, #prealloc-req: 0, #transfer-req: 2, #retracted-req: 0, npu graph: True, gen throughput (token/s): 559.86, #queue-req: 0, 
[2026-01-14 12:10:06 DP23 TP23 EP23] Decode batch, #running-req: 25, #token: 101632, token usage: 0.81, accept len: 2.70, accept rate: 0.90, pre-allocated usage: 0.03, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, npu graph: True, gen throughput (token/s): 600.52, #queue-req: 0, 
[2026-01-14 12:10:06 DP19 TP19 EP19] Decode batch, #running-req: 26, #token: 100864, token usage: 0.80, accept len: 2.67, accept rate: 0.89, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 593.30, #queue-req: 0, 
[2026-01-14 12:10:06 DP20 TP20 EP20] Decode batch, #running-req: 26, #token: 100736, token usage: 0.80, accept len: 2.61, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 537.72, #queue-req: 0, 
[2026-01-14 12:10:06 DP22 TP22 EP22] Decode batch, #running-req: 26, #token: 100736, token usage: 0.80, accept len: 2.62, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 564.64, #queue-req: 0, 
[2026-01-14 12:10:06 DP27 TP27 EP27] Decode batch, #running-req: 25, #token: 100352, token usage: 0.80, accept len: 2.64, accept rate: 0.88, pre-allocated usage: 0.03, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, npu graph: True, gen throughput (token/s): 578.57, #queue-req: 0, 
[2026-01-14 12:10:06 DP30 TP30 EP30] Decode batch, #running-req: 25, #token: 100864, token usage: 0.80, accept len: 2.68, accept rate: 0.89, pre-allocated usage: 0.03, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, npu graph: True, gen throughput (token/s): 590.43, #queue-req: 0, 
[2026-01-14 12:10:07 DP28 TP28 EP28] Decode batch, #running-req: 24, #token: 100352, token usage: 0.80, accept len: 2.55, accept rate: 0.85, pre-allocated usage: 0.06, #prealloc-req: 0, #transfer-req: 2, #retracted-req: 0, npu graph: True, gen throughput (token/s): 506.22, #queue-req: 0, 
[2026-01-14 12:10:07 DP31 TP31 EP31] Decode batch, #running-req: 25, #token: 100352, token usage: 0.80, accept len: 2.64, accept rate: 0.88, pre-allocated usage: 0.03, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, npu graph: True, gen throughput (token/s): 540.65, #queue-req: 0, 
[2026-01-14 12:10:07 DP29 TP29 EP29] Decode batch, #running-req: 26, #token: 101376, token usage: 0.81, accept len: 2.71, accept rate: 0.90, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 617.55, #queue-req: 0, 
[2026-01-14 12:10:07 DP17 TP17 EP17] Decode batch, #running-req: 26, #token: 100864, token usage: 0.80, accept len: 2.65, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 598.11, #queue-req: 0, 
[2026-01-14 12:10:07 DP21 TP21 EP21] Decode batch, #running-req: 26, #token: 100864, token usage: 0.80, accept len: 2.57, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 561.06, #queue-req: 0, 
[2026-01-14 12:10:07 DP24 TP24 EP24] Decode batch, #running-req: 26, #token: 100736, token usage: 0.80, accept len: 2.68, accept rate: 0.89, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 557.17, #queue-req: 0, 
[2026-01-14 12:10:10 DP16 TP16 EP16] Decode batch, #running-req: 26, #token: 103296, token usage: 0.82, accept len: 2.67, accept rate: 0.89, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 609.65, #queue-req: 0, 
[2026-01-14 12:10:11 DP25 TP25 EP25] Decode batch, #running-req: 26, #token: 103424, token usage: 0.82, accept len: 2.52, accept rate: 0.84, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 557.23, #queue-req: 0, 
[2026-01-14 12:10:11 DP19 TP19 EP19] Decode batch, #running-req: 26, #token: 103552, token usage: 0.83, accept len: 2.65, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 622.35, #queue-req: 0, 
[2026-01-14 12:10:11 DP18 TP18 EP18] Decode batch, #running-req: 26, #token: 102912, token usage: 0.82, accept len: 2.63, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 572.38, #queue-req: 0, 
[2026-01-14 12:10:11 DP23 TP23 EP23] Decode batch, #running-req: 25, #token: 103808, token usage: 0.83, accept len: 2.65, accept rate: 0.88, pre-allocated usage: 0.03, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, npu graph: True, gen throughput (token/s): 598.15, #queue-req: 0, 
[2026-01-14 12:10:11 DP26 TP26 EP26] Decode batch, #running-req: 26, #token: 102784, token usage: 0.82, accept len: 2.58, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 542.32, #queue-req: 0, 
[2026-01-14 12:10:11 DP30 TP30 EP30] Decode batch, #running-req: 25, #token: 103552, token usage: 0.83, accept len: 2.67, accept rate: 0.89, pre-allocated usage: 0.03, #prealloc-req: 0, #transfer-req: 1, #retracted-req: 0, npu graph: True, gen throughput (token/s): 602.17, #queue-req: 0, 
[2026-01-14 12:10:11 DP22 TP22 EP22] Decode batch, #running-req: 26, #token: 103296, token usage: 0.82, accept len: 2.59, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 608.74, #queue-req: 0, 
[2026-01-14 12:10:11 DP20 TP20 EP20] Decode batch, #running-req: 26, #token: 103424, token usage: 0.82, accept len: 2.61, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 611.65, #queue-req: 0, 
[2026-01-14 12:10:11 DP29 TP29 EP29] Decode batch, #running-req: 26, #token: 104320, token usage: 0.83, accept len: 2.70, accept rate: 0.90, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 632.61, #queue-req: 0, 
[2026-01-14 12:10:11 DP27 TP27 EP27] Decode batch, #running-req: 26, #token: 103168, token usage: 0.82, accept len: 2.63, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 597.83, #queue-req: 0, 
[2026-01-14 12:10:11 DP17 TP17 EP17] Decode batch, #running-req: 26, #token: 103552, token usage: 0.83, accept len: 2.60, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 608.31, #queue-req: 0, 
[2026-01-14 12:10:11 DP31 TP31 EP31] Decode batch, #running-req: 26, #token: 103168, token usage: 0.82, accept len: 2.62, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 590.15, #queue-req: 0, 
[2026-01-14 12:10:11 DP21 TP21 EP21] Decode batch, #running-req: 26, #token: 103680, token usage: 0.83, accept len: 2.62, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 614.94, #queue-req: 0, 
[2026-01-14 12:10:11 DP28 TP28 EP28] Decode batch, #running-req: 26, #token: 102656, token usage: 0.82, accept len: 2.58, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 558.76, #queue-req: 0, 
[2026-01-14 12:10:11 DP24 TP24 EP24] Decode batch, #running-req: 26, #token: 103808, token usage: 0.83, accept len: 2.68, accept rate: 0.89, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 627.36, #queue-req: 0, 
[2026-01-14 12:10:15 DP16 TP16 EP16] Decode batch, #running-req: 26, #token: 106496, token usage: 0.85, accept len: 2.63, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 611.08, #queue-req: 0, 
[2026-01-14 12:10:15 DP25 TP25 EP25] Decode batch, #running-req: 26, #token: 106112, token usage: 0.85, accept len: 2.55, accept rate: 0.85, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 593.17, #queue-req: 0, 
[2026-01-14 12:10:15 DP19 TP19 EP19] Decode batch, #running-req: 26, #token: 106880, token usage: 0.85, accept len: 2.70, accept rate: 0.90, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 627.77, #queue-req: 0, 
[2026-01-14 12:10:15 DP18 TP18 EP18] Decode batch, #running-req: 26, #token: 105728, token usage: 0.84, accept len: 2.61, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 606.10, #queue-req: 0, 
[2026-01-14 12:10:15 DP26 TP26 EP26] Decode batch, #running-req: 26, #token: 105984, token usage: 0.84, accept len: 2.64, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 613.95, #queue-req: 0, 
[2026-01-14 12:10:15 DP20 TP20 EP20] Decode batch, #running-req: 26, #token: 106496, token usage: 0.85, accept len: 2.59, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 600.20, #queue-req: 0, 
[2026-01-14 12:10:15 DP22 TP22 EP22] Decode batch, #running-req: 26, #token: 106368, token usage: 0.85, accept len: 2.58, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 597.74, #queue-req: 0, 
[2026-01-14 12:10:15 DP23 TP23 EP23] Decode batch, #running-req: 26, #token: 107008, token usage: 0.85, accept len: 2.71, accept rate: 0.90, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 611.47, #queue-req: 0, 
[2026-01-14 12:10:15 DP29 TP29 EP29] Decode batch, #running-req: 26, #token: 107008, token usage: 0.85, accept len: 2.71, accept rate: 0.90, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 628.89, #queue-req: 0, 
[2026-01-14 12:10:15 DP30 TP30 EP30] Decode batch, #running-req: 26, #token: 106624, token usage: 0.85, accept len: 2.71, accept rate: 0.90, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 611.91, #queue-req: 0, 
[2026-01-14 12:10:15 DP27 TP27 EP27] Decode batch, #running-req: 26, #token: 106240, token usage: 0.85, accept len: 2.62, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 609.47, #queue-req: 0, 
[2026-01-14 12:10:16 DP17 TP17 EP17] Decode batch, #running-req: 26, #token: 106752, token usage: 0.85, accept len: 2.60, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 603.02, #queue-req: 0, 
[2026-01-14 12:10:16 DP31 TP31 EP31] Decode batch, #running-req: 26, #token: 105984, token usage: 0.84, accept len: 2.57, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 597.30, #queue-req: 0, 
[2026-01-14 12:10:16 DP21 TP21 EP21] Decode batch, #running-req: 26, #token: 106880, token usage: 0.85, accept len: 2.63, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 611.44, #queue-req: 0, 
[2026-01-14 12:10:16 DP28 TP28 EP28] Decode batch, #running-req: 26, #token: 105600, token usage: 0.84, accept len: 2.54, accept rate: 0.85, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 589.12, #queue-req: 0, 
[2026-01-14 12:10:16 DP24 TP24 EP24] Decode batch, #running-req: 26, #token: 106752, token usage: 0.85, accept len: 2.63, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 609.63, #queue-req: 0, 
[2026-01-14 12:10:19 DP16 TP16 EP16] Decode batch, #running-req: 26, #token: 108928, token usage: 0.87, accept len: 2.63, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 608.81, #queue-req: 0, 
[2026-01-14 12:10:20 DP25 TP25 EP25] Decode batch, #running-req: 26, #token: 108416, token usage: 0.86, accept len: 2.52, accept rate: 0.84, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 584.88, #queue-req: 0, 
[2026-01-14 12:10:20 DP19 TP19 EP19] Decode batch, #running-req: 26, #token: 109696, token usage: 0.87, accept len: 2.68, accept rate: 0.89, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 619.93, #queue-req: 0, 
[2026-01-14 12:10:20 DP26 TP26 EP26] Decode batch, #running-req: 26, #token: 108672, token usage: 0.87, accept len: 2.64, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 612.56, #queue-req: 0, 
[2026-01-14 12:10:20 DP18 TP18 EP18] Decode batch, #running-req: 26, #token: 108672, token usage: 0.87, accept len: 2.56, accept rate: 0.85, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 592.00, #queue-req: 0, 
[2026-01-14 12:10:20 DP22 TP22 EP22] Decode batch, #running-req: 26, #token: 109056, token usage: 0.87, accept len: 2.60, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 603.42, #queue-req: 0, 
[2026-01-14 12:10:20 DP23 TP23 EP23] Decode batch, #running-req: 26, #token: 109952, token usage: 0.88, accept len: 2.69, accept rate: 0.90, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 622.83, #queue-req: 0, 
[2026-01-14 12:10:20 DP20 TP20 EP20] Decode batch, #running-req: 26, #token: 109056, token usage: 0.87, accept len: 2.60, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 602.25, #queue-req: 0, 
[2026-01-14 12:10:20 DP30 TP30 EP30] Decode batch, #running-req: 26, #token: 109440, token usage: 0.87, accept len: 2.70, accept rate: 0.90, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 625.03, #queue-req: 0, 
[2026-01-14 12:10:20 DP29 TP29 EP29] Decode batch, #running-req: 26, #token: 109312, token usage: 0.87, accept len: 2.72, accept rate: 0.91, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 629.45, #queue-req: 0, 
[2026-01-14 12:10:20 DP27 TP27 EP27] Decode batch, #running-req: 26, #token: 108416, token usage: 0.86, accept len: 2.60, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 601.63, #queue-req: 0, 
[2026-01-14 12:10:20 DP17 TP17 EP17] Decode batch, #running-req: 26, #token: 109056, token usage: 0.87, accept len: 2.55, accept rate: 0.85, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 590.45, #queue-req: 0, 
[2026-01-14 12:10:20 DP31 TP31 EP31] Decode batch, #running-req: 26, #token: 108672, token usage: 0.87, accept len: 2.61, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 604.08, #queue-req: 0, 
[2026-01-14 12:10:20 DP21 TP21 EP21] Decode batch, #running-req: 26, #token: 109312, token usage: 0.87, accept len: 2.66, accept rate: 0.89, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 615.30, #queue-req: 0, 
[2026-01-14 12:10:20 DP28 TP28 EP28] Decode batch, #running-req: 26, #token: 108160, token usage: 0.86, accept len: 2.55, accept rate: 0.85, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 589.48, #queue-req: 0, 
[2026-01-14 12:10:20 DP24 TP24 EP24] Decode batch, #running-req: 26, #token: 109312, token usage: 0.87, accept len: 2.62, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 606.17, #queue-req: 0, 
[2026-01-14 12:10:24 DP16 TP16 EP16] Decode batch, #running-req: 26, #token: 111872, token usage: 0.89, accept len: 2.61, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 602.86, #queue-req: 0, 
[2026-01-14 12:10:24 DP25 TP25 EP25] Decode batch, #running-req: 26, #token: 111232, token usage: 0.89, accept len: 2.56, accept rate: 0.85, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 591.01, #queue-req: 0, 
[2026-01-14 12:10:24 DP19 TP19 EP19] Decode batch, #running-req: 26, #token: 112384, token usage: 0.90, accept len: 2.69, accept rate: 0.90, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 619.60, #queue-req: 0, 
[2026-01-14 12:10:24 DP18 TP18 EP18] Decode batch, #running-req: 26, #token: 111104, token usage: 0.89, accept len: 2.60, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 600.38, #queue-req: 0, 
[2026-01-14 12:10:24 DP26 TP26 EP26] Decode batch, #running-req: 26, #token: 111616, token usage: 0.89, accept len: 2.63, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 605.98, #queue-req: 0, 
[2026-01-14 12:10:24 DP22 TP22 EP22] Decode batch, #running-req: 26, #token: 111488, token usage: 0.89, accept len: 2.58, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 594.22, #queue-req: 0, 
[2026-01-14 12:10:24 DP20 TP20 EP20] Decode batch, #running-req: 26, #token: 111488, token usage: 0.89, accept len: 2.62, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 604.02, #queue-req: 0, 
[2026-01-14 12:10:24 DP23 TP23 EP23] Decode batch, #running-req: 26, #token: 112384, token usage: 0.90, accept len: 2.64, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 609.98, #queue-req: 0, 
[2026-01-14 12:10:24 DP30 TP30 EP30] Decode batch, #running-req: 26, #token: 112000, token usage: 0.89, accept len: 2.65, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 612.36, #queue-req: 0, 
[2026-01-14 12:10:24 DP27 TP27 EP27] Decode batch, #running-req: 26, #token: 111104, token usage: 0.89, accept len: 2.55, accept rate: 0.85, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 588.15, #queue-req: 0, 
[2026-01-14 12:10:24 DP29 TP29 EP29] Decode batch, #running-req: 26, #token: 112128, token usage: 0.89, accept len: 2.74, accept rate: 0.91, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 630.89, #queue-req: 0, 
[2026-01-14 12:10:25 DP17 TP17 EP17] Decode batch, #running-req: 26, #token: 111744, token usage: 0.89, accept len: 2.55, accept rate: 0.85, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 586.95, #queue-req: 0, 
[2026-01-14 12:10:25 DP31 TP31 EP31] Decode batch, #running-req: 26, #token: 111232, token usage: 0.89, accept len: 2.62, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 603.37, #queue-req: 0, 
[2026-01-14 12:10:25 DP28 TP28 EP28] Decode batch, #running-req: 26, #token: 110848, token usage: 0.88, accept len: 2.57, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 592.93, #queue-req: 0, 
[2026-01-14 12:10:25 DP24 TP24 EP24] Decode batch, #running-req: 26, #token: 112128, token usage: 0.89, accept len: 2.63, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 605.60, #queue-req: 0, 
[2026-01-14 12:10:25 DP21 TP21 EP21] Decode batch, #running-req: 26, #token: 112128, token usage: 0.89, accept len: 2.62, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 605.05, #queue-req: 0, 
[2026-01-14 12:10:28 DP16 TP16 EP16] Decode batch, #running-req: 26, #token: 114304, token usage: 0.91, accept len: 2.60, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 595.94, #queue-req: 0, 
[2026-01-14 12:10:29 DP25 TP25 EP25] Decode batch, #running-req: 26, #token: 114176, token usage: 0.91, accept len: 2.53, accept rate: 0.84, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 580.60, #queue-req: 0, 
[2026-01-14 12:10:29 DP19 TP19 EP19] Decode batch, #running-req: 26, #token: 115328, token usage: 0.92, accept len: 2.67, accept rate: 0.89, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 612.72, #queue-req: 0, 
[2026-01-14 12:10:29 DP26 TP26 EP26] Decode batch, #running-req: 26, #token: 114176, token usage: 0.91, accept len: 2.64, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 604.87, #queue-req: 0, 
[2026-01-14 12:10:29 DP18 TP18 EP18] Decode batch, #running-req: 26, #token: 113920, token usage: 0.91, accept len: 2.60, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 594.63, #queue-req: 0, 
[2026-01-14 12:10:29 DP22 TP22 EP22] Decode batch, #running-req: 26, #token: 114304, token usage: 0.91, accept len: 2.55, accept rate: 0.85, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 585.36, #queue-req: 0, 
[2026-01-14 12:10:29 DP20 TP20 EP20] Decode batch, #running-req: 26, #token: 113792, token usage: 0.91, accept len: 2.52, accept rate: 0.84, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 578.48, #queue-req: 0, 
[2026-01-14 12:10:29 DP23 TP23 EP23] Decode batch, #running-req: 26, #token: 115072, token usage: 0.92, accept len: 2.68, accept rate: 0.89, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 615.00, #queue-req: 0, 
[2026-01-14 12:10:29 DP29 TP29 EP29] Decode batch, #running-req: 26, #token: 115328, token usage: 0.92, accept len: 2.70, accept rate: 0.90, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 618.11, #queue-req: 0, 
[2026-01-14 12:10:29 DP30 TP30 EP30] Decode batch, #running-req: 26, #token: 114688, token usage: 0.91, accept len: 2.70, accept rate: 0.90, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 618.00, #queue-req: 0, 
[2026-01-14 12:10:29 DP27 TP27 EP27] Decode batch, #running-req: 26, #token: 113792, token usage: 0.91, accept len: 2.60, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 594.91, #queue-req: 0, 
[2026-01-14 12:10:29 DP17 TP17 EP17] Decode batch, #running-req: 26, #token: 114816, token usage: 0.92, accept len: 2.59, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 592.96, #queue-req: 0, 
[2026-01-14 12:10:29 DP31 TP31 EP31] Decode batch, #running-req: 26, #token: 114048, token usage: 0.91, accept len: 2.61, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 597.48, #queue-req: 0, 
[2026-01-14 12:10:29 DP28 TP28 EP28] Decode batch, #running-req: 26, #token: 113024, token usage: 0.90, accept len: 2.55, accept rate: 0.85, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 584.21, #queue-req: 0, 
[2026-01-14 12:10:29 DP21 TP21 EP21] Decode batch, #running-req: 26, #token: 114560, token usage: 0.91, accept len: 2.62, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 600.32, #queue-req: 0, 
[2026-01-14 12:10:29 DP24 TP24 EP24] Decode batch, #running-req: 26, #token: 114816, token usage: 0.92, accept len: 2.61, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 597.23, #queue-req: 0, 
[2026-01-14 12:10:33 DP16 TP16 EP16] Decode batch, #running-req: 26, #token: 116864, token usage: 0.93, accept len: 2.60, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 593.53, #queue-req: 0, 
[2026-01-14 12:10:33 DP25 TP25 EP25] Decode batch, #running-req: 26, #token: 116224, token usage: 0.93, accept len: 2.55, accept rate: 0.85, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 582.57, #queue-req: 0, 
[2026-01-14 12:10:33 DP19 TP19 EP19] Decode batch, #running-req: 26, #token: 117888, token usage: 0.94, accept len: 2.65, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 606.16, #queue-req: 0, 
[2026-01-14 12:10:33 DP18 TP18 EP18] Decode batch, #running-req: 26, #token: 116480, token usage: 0.93, accept len: 2.62, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 598.54, #queue-req: 0, 
[2026-01-14 12:10:33 DP26 TP26 EP26] Decode batch, #running-req: 26, #token: 116736, token usage: 0.93, accept len: 2.66, accept rate: 0.89, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 606.86, #queue-req: 0, 
[2026-01-14 12:10:33 DP23 TP23 EP23] Decode batch, #running-req: 26, #token: 118144, token usage: 0.94, accept len: 2.67, accept rate: 0.89, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 610.85, #queue-req: 0, 
[2026-01-14 12:10:33 DP22 TP22 EP22] Decode batch, #running-req: 26, #token: 116608, token usage: 0.93, accept len: 2.60, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 594.39, #queue-req: 0, 
[2026-01-14 12:10:33 DP20 TP20 EP20] Decode batch, #running-req: 26, #token: 116736, token usage: 0.93, accept len: 2.57, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 586.29, #queue-req: 0, 
[2026-01-14 12:10:34 DP30 TP30 EP30] Decode batch, #running-req: 26, #token: 117504, token usage: 0.94, accept len: 2.67, accept rate: 0.89, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 609.54, #queue-req: 0, 
[2026-01-14 12:10:34 DP27 TP27 EP27] Decode batch, #running-req: 26, #token: 116608, token usage: 0.93, accept len: 2.59, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 590.86, #queue-req: 0, 
[2026-01-14 12:10:34 DP29 TP29 EP29] Decode batch, #running-req: 26, #token: 118144, token usage: 0.94, accept len: 2.71, accept rate: 0.90, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 618.72, #queue-req: 0, 
[2026-01-14 12:10:34 DP17 TP17 EP17] Decode batch, #running-req: 26, #token: 117504, token usage: 0.94, accept len: 2.65, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 604.76, #queue-req: 0, 
[2026-01-14 12:10:34 DP31 TP31 EP31] Decode batch, #running-req: 26, #token: 116992, token usage: 0.93, accept len: 2.55, accept rate: 0.85, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 582.41, #queue-req: 0, 
[2026-01-14 12:10:34 DP21 TP21 EP21] Decode batch, #running-req: 26, #token: 117120, token usage: 0.93, accept len: 2.58, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 588.52, #queue-req: 0, 
[2026-01-14 12:10:34 DP28 TP28 EP28] Decode batch, #running-req: 26, #token: 116224, token usage: 0.93, accept len: 2.56, accept rate: 0.85, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 585.19, #queue-req: 0, 
[2026-01-14 12:10:34 DP24 TP24 EP24] Decode batch, #running-req: 26, #token: 117376, token usage: 0.94, accept len: 2.63, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 599.90, #queue-req: 0, 
[2026-01-14 12:10:38 DP16 TP16 EP16] Decode batch, #running-req: 26, #token: 119808, token usage: 0.96, accept len: 2.60, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 592.15, #queue-req: 0, 
[2026-01-14 12:10:38 DP25 TP25 EP25] Decode batch, #running-req: 26, #token: 119168, token usage: 0.95, accept len: 2.59, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 589.46, #queue-req: 0, 
[2026-01-14 12:10:38 DP19 TP19 EP19] Decode batch, #running-req: 26, #token: 120448, token usage: 0.96, accept len: 2.63, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 597.92, #queue-req: 0, 
[2026-01-14 12:10:38 DP18 TP18 EP18] Decode batch, #running-req: 26, #token: 118784, token usage: 0.95, accept len: 2.64, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 601.64, #queue-req: 0, 
[2026-01-14 12:10:38 DP26 TP26 EP26] Decode batch, #running-req: 26, #token: 119424, token usage: 0.95, accept len: 2.65, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 603.83, #queue-req: 0, 
[2026-01-14 12:10:38 DP20 TP20 EP20] Decode batch, #running-req: 26, #token: 119424, token usage: 0.95, accept len: 2.59, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 590.09, #queue-req: 0, 
[2026-01-14 12:10:38 DP23 TP23 EP23] Decode batch, #running-req: 26, #token: 120960, token usage: 0.96, accept len: 2.70, accept rate: 0.90, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 614.02, #queue-req: 0, 
[2026-01-14 12:10:38 DP22 TP22 EP22] Decode batch, #running-req: 26, #token: 119424, token usage: 0.95, accept len: 2.58, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 586.29, #queue-req: 0, 
[2026-01-14 12:10:38 DP29 TP29 EP29] Decode batch, #running-req: 26, #token: 121088, token usage: 0.97, accept len: 2.72, accept rate: 0.91, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 619.91, #queue-req: 0, 
[2026-01-14 12:10:38 DP27 TP27 EP27] Decode batch, #running-req: 26, #token: 119424, token usage: 0.95, accept len: 2.59, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 588.17, #queue-req: 0, 
[2026-01-14 12:10:38 DP30 TP30 EP30] Decode batch, #running-req: 26, #token: 120192, token usage: 0.96, accept len: 2.65, accept rate: 0.88, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 602.53, #queue-req: 0, 
[2026-01-14 12:10:38 DP17 TP17 EP17] Decode batch, #running-req: 26, #token: 120064, token usage: 0.96, accept len: 2.60, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 591.21, #queue-req: 0, 
[2026-01-14 12:10:38 DP31 TP31 EP31] Decode batch, #running-req: 26, #token: 119680, token usage: 0.95, accept len: 2.59, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 589.70, #queue-req: 0, 
[2026-01-14 12:10:38 DP21 TP21 EP21] Decode batch, #running-req: 26, #token: 119936, token usage: 0.96, accept len: 2.62, accept rate: 0.87, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 595.99, #queue-req: 0, 
[2026-01-14 12:10:38 DP28 TP28 EP28] Decode batch, #running-req: 26, #token: 119168, token usage: 0.95, accept len: 2.55, accept rate: 0.85, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 580.47, #queue-req: 0, 
[2026-01-14 12:10:38 DP24 TP24 EP24] Decode batch, #running-req: 26, #token: 120064, token usage: 0.96, accept len: 2.59, accept rate: 0.86, pre-allocated usage: 0.00, #prealloc-req: 0, #transfer-req: 0, #retracted-req: 0, npu graph: True, gen throughput (token/s): 589.44, #queue-req: 0, 
[rank16]:[W114 12:10:44.793501754 compiler_depend.ts:59] Warning: [PID: 1452] 2026-01-14-12:02:45.144.220 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:0, dieId:0), serial number is 5, there is an exception of fftsplus aivector error, core id is 14, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35ca4, vec error info: 0xf109bd361f, mte error info: 0xd706000064, ifu error info: 0x82ec30f80a80, ccu error info: 0xfc359751718fa8a2, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c14601a080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:1, tslot:5, thread:0, ctxid:0, blk:37, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=0, stream_id=8, report_stream_id=1998, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
[rank24]:[W114 12:10:44.802648395 compiler_depend.ts:59] Warning: [PID: 1460] 2026-01-14-12:02:45.159.734 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:4, dieId:0), serial number is 7, there is an exception of fftsplus aivector error, core id is 0, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35da0, vec error info: 0x390c140721, mte error info: 0xd706000064, ifu error info: 0x539d972568480, ccu error info: 0x6cc14b846c04bfeb, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c145ff9080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:0, tslot:4, thread:0, ctxid:0, blk:12, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=8, stream_id=1624, report_stream_id=1566, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
[2026-01-14 12:10:44 DP16 TP16 EP16] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011

[2026-01-14 12:10:44 DP24 TP24 EP24] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011

[rank17]:[W114 12:10:44.806509006 compiler_depend.ts:59] Warning: [PID: 1453] 2026-01-14-12:02:45.144.870 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:0, dieId:1), serial number is 6, there is an exception of fftsplus aivector error, core id is 7, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35da0, vec error info: 0x6112a163f6, mte error info: 0xd706000064, ifu error info: 0x799fb2933c100, ccu error info: 0x9a19f8324426811f, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c14600a080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:0, tslot:4, thread:0, ctxid:0, blk:12, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=1, stream_id=904, report_stream_id=846, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
[2026-01-14 12:10:44 DP17 TP17 EP17] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011

[rank30]:[W114 12:10:44.809895975 compiler_depend.ts:59] Warning: [PID: 2222] 2026-01-14-12:02:45.145.678 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:7, dieId:0), serial number is 8, there is an exception of fftsplus aivector error, core id is 0, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35da0, vec error info: 0xe11475350e, mte error info: 0xd706000064, ifu error info: 0x3d83291ee9980, ccu error info: 0x410644ff5e67ceb7, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c14601a080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:0, tslot:6, thread:0, ctxid:0, blk:12, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=14, stream_id=1624, report_stream_id=1566, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
[rank19]:[W114 12:10:44.810453298 compiler_depend.ts:59] Warning: [PID: 1455] 2026-01-14-12:02:45.143.810 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:1, dieId:1), serial number is 9, there is an exception of fftsplus aivector error, core id is 1, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35ca4, vec error info: 0xb012b401c6, mte error info: 0xd706000064, ifu error info: 0x491315cd69040, ccu error info: 0x6d0543c2595829c0, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c146019080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:0, tslot:7, thread:0, ctxid:0, blk:37, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=3, stream_id=712, report_stream_id=654, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
terminate called after throwing an instance of 'terminate called after throwing an instance of 'c10::Errorc10::Error'
'
  what():  LaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:1460, Device:8, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 1460] 2026-01-14-12:10:44.738.859 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffe280e48c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffe2808c140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffcfd24e210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffcfd24eacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffcfd1c5a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffcfd1554c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffcfd157ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffe32449024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffe28087ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffe3288e314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffe3288e648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffffb56e7400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffffb56e74d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaad19408b0 in sglang::scheduler_DP24_TP24_EP24)

Fatal Python error: Aborted

  what():  Thread 0xLaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:1452, Device:0, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 1452] 2026-01-14-12:10:44.737.831 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffe063148c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffe062bc140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffcd924e210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffcd924eacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffcd91c5a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffcd91554c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffcd9157ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffe10679024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffe062b7ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffe10abe314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffe10abe648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffff93917400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffff939174d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaac40d08b0 in sglang::scheduler_DP16_TP16_EP16)
0000fff79ffff120
 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py", line 923 in Fatal Python error: heartbeat_checkerAborted


  File "Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py"0000fff74ffff120, line  (most recent call first):
982  File  in "run/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py
"  File ", line /usr/local/python3.11.13/lib/python3.11/threading.py"923, line  in 1045heartbeat_checker in 
_bootstrap_inner  File 
"  File /usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/threading.py", line , line 9821002 in  in run_bootstrap

  File 
"Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py0000fff7abfff120" (most recent call first):
, line   File 1045" in /usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py_bootstrap_inner"
, line   File 799" in /usr/local/python3.11.13/lib/python3.11/threading.pyrecv_multipart"
, line   File 1002" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py_bootstrap"

, line Thread 0x8930000fff75bfff120 in  (most recent call first):
decode_thread  File 
"  File /usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py""/usr/local/python3.11.13/lib/python3.11/threading.py, line "799, line  in 982recv_multipart
 in run  File 
"  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py""/usr/local/python3.11.13/lib/python3.11/threading.py, line "893, line  in 1045decode_thread in 
_bootstrap_inner  File 
"  File /usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/threading.py, line "982, line  in 1002run in 
_bootstrap  File 
"
/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x"0000fff7c3fff120, line  (most recent call first):
1045  File  in "_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py
"  File ", line /usr/local/python3.11.13/lib/python3.11/threading.py375" in , line _watchdog_once1002
 in   File _bootstrap"
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py
"Thread 0x, line 0000fff71bfef120360 (most recent call first):
 in   File _watchdog_thread"
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py  File ""/usr/local/python3.11.13/lib/python3.11/threading.py, line "375, line  in 982_watchdog_once in 
run  File 
"  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py""/usr/local/python3.11.13/lib/python3.11/threading.py", line , line 3601045 in  in _watchdog_thread_bootstrap_inner

  File   File ""/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py"", line terminate called after throwing an instance of ', line 982c10::Error1002 in '
 in _bootstrap
run

Thread 0x  File 0000fff953fff120 (most recent call first):
"  File /usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/threading.py, line "1045, line  in 327_bootstrap_inner in 
wait
  File   File ""/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/threading.py"", line , line 2311002 in  in _feed_bootstrap

  File 
"Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py0000fff947fff120" (most recent call first):
, line 982  File  in "run/usr/local/python3.11.13/lib/python3.11/threading.py
"  File , line "327/usr/local/python3.11.13/lib/python3.11/threading.py in "wait, line 
1045  File  in "_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
"  File , line "231/usr/local/python3.11.13/lib/python3.11/threading.py in "_feed, line 
1002  File  in "_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py
"
, line Thread 0x9820000fff96bfff120 in run (most recent call first):

  File "  File /usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/threading.py, line "327, line  in 1045wait in 
  File _bootstrap_inner"
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File "", line /usr/local/python3.11.13/lib/python3.11/threading.py231 in "_feed, line 
1002  File  in "_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py
"
, line Thread 0x982 in 0000fff953fff120run (most recent call first):

  File   File ""/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py[rank25]:[W114 12:10:44.812529020 compiler_depend.ts:59] Warning: [PID: 1461] 2026-01-14-12:02:45.155.815 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:4, dieId:1), serial number is 7, there is an exception of fftsplus aivector error, core id is 7, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35da0, vec error info: 0x5914e45d99, mte error info: 0xd706000064, ifu error info: 0x99e74095f480, ccu error info: 0xd5b306245bfc59fc, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c146018080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:1, tslot:7, thread:0, ctxid:0, blk:12, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=9, stream_id=1624, report_stream_id=1566, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
"", line , line 1045327 in  in _bootstrap_innerwait

  File   File ""/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py", line "1002, line  in 231_bootstrap in 
_feed

Thread 0x  File 0000fff977fff120" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py  File ""/usr/local/python3.11.13/lib/python3.11/threading.py", line , line 982327 in  in runwait

  File   File ""/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"", line , line 1045231 in  in _bootstrap_inner_feed

  File   File ""/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py"", line , line 1002982  what():   in  in LaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:1453, Device:1, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 1453] 2026-01-14-12:10:44.742.840 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffe10ce48c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffe10c8c140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffce524e210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffce524eacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffce51c5a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffce51554c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffce5157ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffe1b049024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffe10c87ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffe1b48e314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffe1b48e648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffff9e2e7400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffff9e2e74d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaabba708b0 in sglang::scheduler_DP17_TP17_EP17)
run_bootstrap


  File 
"Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py"0000fff95ffff120, line  (most recent call first):
1045Fatal Python error:   File  in "Aborted/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner

"
Thread 0x, line   File 3270000fff7abfff120" in  (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.pywait  File 
""  File , line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py"1002"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in ", line _bootstrap, line 923231
 in 
 in heartbeat_checkerThread 0x_feed

0000fff983fff120  File   File " (most recent call first):
"/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py  File , line "982", line  in /usr/local/python3.11.13/lib/python3.11/threading.py982run in "
run, line   File 
327"  File  in /usr/local/python3.11.13/lib/python3.11/threading.py"wait"/usr/local/python3.11.13/lib/python3.11/threading.py
, line "1045  File  in , line "_bootstrap_inner1045/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
 in   File _bootstrap_inner""
, line /usr/local/python3.11.13/lib/python3.11/threading.py  File ""231, line /usr/local/python3.11.13/lib/python3.11/threading.py in "1002_feed in , line 
_bootstrap1002  File 
 in 
"_bootstrapThread 0x
/usr/local/python3.11.13/lib/python3.11/threading.py0000fff96bfff120
" (most recent call first):
Thread 0x, line 0000fff7b7fff120  File 982 (most recent call first):
" in   File /usr/local/python3.11.13/lib/python3.11/threading.py[2026-01-14 12:10:44 DP30 TP30 EP30] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011

run""
/usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py, line   File "327" in /usr/local/python3.11.13/lib/python3.11/threading.py, line wait"799
, line  in   File 1045recv_multipart" in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
  File _bootstrap_inner""
, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py  File 231"" in , line _feed/usr/local/python3.11.13/lib/python3.11/threading.py893
" in   File , line decode_thread1002"
 in /usr/local/python3.11.13/lib/python3.11/threading.py  File "_bootstrap", line 
/usr/local/python3.11.13/lib/python3.11/threading.py982
Thread 0x" in 0000fff98ffff120, line run (most recent call first):
982
  File  in   File run""
/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py"  File "", line , line 1045/usr/local/python3.11.13/lib/python3.11/threading.py in 327_bootstrap_inner"
 in   File , line wait1045" in 
/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner  File "
  File ", line "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py1002/usr/local/python3.11.13/lib/python3.11/threading.py"" in , line , line _bootstrap1002231
 in 
 in _bootstrap_feedThread 0x


0000fff977fff120Thread 0x  File  (most recent call first):
0000fff763fff120"  File  (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py"  File ""/usr/local/python3.11.13/lib/python3.11/threading.py, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py"982, line " in 327, line  in 375runwait in 

_watchdog_once  File   File 
"  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py""", line , line , line 3602311045 in  in _bootstrap_inner[2026-01-14 12:10:44 DP19 TP19 EP19] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011

 in _feed

_watchdog_thread  File   File 
""  File /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/threading.py", line ", line 1002, line 982 in  in 982_bootstraprun in 

run
  File 
"Thread 0x  File /usr/local/python3.11.13/lib/python3.11/threading.py"0000fff99bfff120"/usr/local/python3.11.13/lib/python3.11/threading.py, line  (most recent call first):
1045  File " in ", line _bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.py1045 in 
"_bootstrap_inner  File , line 
"327  File /usr/local/python3.11.13/lib/python3.11/threading.py in "", line /usr/local/python3.11.13/lib/python3.11/threading.pywait1002"
, line  in   File 1002_bootstrap" in 
_bootstrap

Thread 0x/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py0000fff983fff120
 (most recent call first):
"Thread 0x  File , line 0000fff947fff120"231 (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py in "  File _feed, line "
/usr/local/python3.11.13/lib/python3.11/threading.py327  File " in ", line wait/usr/local/python3.11.13/lib/python3.11/threading.py327
 in "  File wait, line 
"982  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in "", line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py231run" in 
_feed, line   File 
231"  File  in "_feed/usr/local/python3.11.13/lib/python3.11/threading.py
/usr/local/python3.11.13/lib/python3.11/threading.py""  File , line , line 1045"982 in /usr/local/python3.11.13/lib/python3.11/threading.py in _bootstrap_innerrun"
, line   File 
"982  File /usr/local/python3.11.13/lib/python3.11/threading.py in ""run/usr/local/python3.11.13/lib/python3.11/threading.py, line 
"1045  File , line  in "_bootstrap_inner1002/usr/local/python3.11.13/lib/python3.11/threading.py
" in   File , line _bootstrap
"1045
 in /usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x_bootstrap_inner"
0000fff9a7fff120, line   File  (most recent call first):
1002"  File  in /usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap""
/usr/local/python3.11.13/lib/python3.11/threading.py, line 
1002"Thread 0x in , line 0000fff98ffff120_bootstrap (most recent call first):
327
  File  in 
"waitThread 0x/usr/local/python3.11.13/lib/python3.11/threading.py
0000fff953fff120" (most recent call first):
  File , line   File "327"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in /usr/local/python3.11.13/lib/python3.11/threading.py"wait"
, line 327, line   File 231 in "wait in 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py_feed"  File 
", line   File 231/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py" in "/usr/local/python3.11.13/lib/python3.11/threading.py_feed, line ", line 231
982 in   File  in _feed"run
/usr/local/python3.11.13/lib/python3.11/threading.py  File 
""  File , line "/usr/local/python3.11.13/lib/python3.11/threading.py982/usr/local/python3.11.13/lib/python3.11/threading.py in ""run, line , line 
9821045  File  in  in _bootstrap_inner"run

/usr/local/python3.11.13/lib/python3.11/threading.py  File   File """, line /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py1045" in ", line _bootstrap_inner1045
 in [rank22]:[W114 12:10:44.814148809 compiler_depend.ts:59] Warning: [PID: 1458] 2026-01-14-12:02:45.146.903 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:3, dieId:0), serial number is 7, there is an exception of fftsplus aivector error, core id is 0, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35da0, vec error info: 0xab0230d945, mte error info: 0xd706000064, ifu error info: 0x6686fe8b8ad80, ccu error info: 0x29fcc8247147c000, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c146017080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:1, tslot:3, thread:0, ctxid:0, blk:12, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=6, stream_id=2000, report_stream_id=1942, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
, line _bootstrap_inner  File 1002"
 in   File /usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap""
, line 
/usr/local/python3.11.13/lib/python3.11/threading.py1002Thread 0x" in 0000fff9b3fff120, line _bootstrap1002 (most recent call first):

 in   File 
_bootstrap"
Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py0000fff99bfff120
" (most recent call first):
Thread 0x  File 0000fff95ffff120", line  (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py327 in "  File , line wait"
327/usr/local/python3.11.13/lib/python3.11/threading.py in "  File "wait, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
327  File "" in , line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pywait231 in "
_feed, line   File 231
" in   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py_feed""
/usr/local/python3.11.13/lib/python3.11/threading.py  File , line ""231, line /usr/local/python3.11.13/lib/python3.11/threading.py in 982"_feed, line  in 
982run  File  in 
"run/usr/local/python3.11.13/lib/python3.11/threading.py
  File ""  File /usr/local/python3.11.13/lib/python3.11/threading.py, line ""982/usr/local/python3.11.13/lib/python3.11/threading.py, line  in "1045run, line  in 1045_bootstrap_inner

 in   File   File "_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.py
""  File , line /usr/local/python3.11.13/lib/python3.11/threading.py"1045/usr/local/python3.11.13/lib/python3.11/threading.py" in ", line _bootstrap_inner, line 10021002
 in   File  in _bootstrap"_bootstrap

/usr/local/python3.11.13/lib/python3.11/threading.py

"Thread 0x, line Thread 0x0000fff95ffff12010020000fff84bfff120 in  (most recent call first):
 (most recent call first):
_bootstrap
  File 
  File "Thread 0x"0000fff96bfff120/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py" (most recent call first):
"  File , line , line 395"395 in /usr/local/python3.11.13/lib/python3.11/threading.py" in , line _recv_recv327
 in   File 
wait"  File 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py"  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"430", line  in , line 430231_recv_bytes in 
 in _recv_bytes  File _feed
"
  File   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py"""/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py/usr/local/python3.11.13/lib/python3.11/threading.py, line ""250, line  in , line 250982recv in  in 
recvrun  File 
"
  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py  File """/usr/local/python3.11.13/lib/python3.11/threading.py, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py"822" in , line _callmethod1045
, line  in   File 822_bootstrap_inner" in 
<string>_callmethod  File "
", line   File /usr/local/python3.11.13/lib/python3.11/threading.py2"" in <string>, line get1002
" in   File , line _bootstrap"2
/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py in "
get, line Thread 0x68
0000fff977fff120 in  (most recent call first):
run  File   File 
""/usr/local/python3.11.13/lib/python3.11/threading.py  File /usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py""", line , line /usr/local/python3.11.13/lib/python3.11/threading.py327" in , line 68wait1045 in 
 in run_bootstrap_inner  File 

"  File   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py, line ""231, line  in , line 10021045_feed in  in 
_bootstrap_bootstrap_inner  File 

"
  File /usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x""0000fff9a7fff120/usr/local/python3.11.13/lib/python3.11/threading.py, line  (most recent call first):
"982 in   File , line run"1002
/usr/local/python3.11.13/lib/python3.11/threading.py  File " in ", line _bootstrap331/usr/local/python3.11.13/lib/python3.11/threading.py
 in "wait
, line 
Thread 0x1045  File 0000fff9cbfff120 in " (most recent call first):
_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.py"
, line   File   File 629"" in /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.pywait""
, line   File , line 3311002" in /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py in "_bootstrapwait[2026-01-14 12:10:44 DP25 TP25 EP25] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011



, line   File 
60"Thread 0x in 0000fff983fff120/usr/local/python3.11.13/lib/python3.11/threading.py"run (most recent call first):
, line 
  File 629  File " in "/usr/local/python3.11.13/lib/python3.11/threading.pywait"/usr/local/python3.11.13/lib/python3.11/threading.py
, line "  File 327, line "1045 in  in /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.pywait_bootstrap_inner
"
  File , line   File ""60/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/threading.py in "", line , line run1002231
 in  in   File _bootstrap_feed"

/usr/local/python3.11.13/lib/python3.11/threading.py
  File ""Thread 0x, line 0000fffcd4b6f120/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
1045"  File  in ", line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py982_bootstrap_inner" in 
, line   File run61"
 in /usr/local/python3.11.13/lib/python3.11/threading.py_recv_msg  File 
""/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line 1002, line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py in "1045_bootstrap in , line 
_bootstrap_inner195

 in   File Thread 0x_read_thread"0000fffcf694f120
/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
  File "  File ", line "/usr/local/python3.11.13/lib/python3.11/threading.py1002/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py in ""_bootstrap, line , line 
98261
 in  in runThread 0x
0000fff98ffff120_recv_msg  File  (most recent call first):

"  File   File /usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line , line 1045"327 in , line _bootstrap_inner in 
wait  File 
195 in "  File _read_thread/usr/local/python3.11.13/lib/python3.11/threading.py"
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"", line , line 1002  File 231 in "_bootstrap in 
/usr/local/python3.11.13/lib/python3.11/threading.py_feed
"Current thread 0x
, line 0000ffff9409f060  File  (most recent call first):
982  File " in /usr/local/python3.11.13/lib/python3.11/threading.py"run/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py"
", line   File 982, line  in "2981run in /usr/local/python3.11.13/lib/python3.11/threading.py
run_scheduler_process"  File 
"  File , line /usr/local/python3.11.13/lib/python3.11/threading.py"1045"/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py in ", line _bootstrap_inner1045, line 
 in 108  File _bootstrap_inner in "
run/usr/local/python3.11.13/lib/python3.11/threading.py  File 
""  File , line /usr/local/python3.11.13/lib/python3.11/threading.py"1002/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py"" in , line , line _bootstrap3141002
 in  in 
_bootstrap_bootstrap


  File Current thread 0xThread 0x"0000ffffb5e740600000fff99bfff120/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py (most recent call first):
 (most recent call first):
"  File   File , line ""135/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py/usr/local/python3.11.13/lib/python3.11/threading.py in "_main, line "
327  File  in , line "wait2981
/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py" in   File , line run_scheduler_process122"
 in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File spawn_main""
, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py  File 231" in "_feed<string>, line 
"108  File , line  in "1run in /usr/local/python3.11.13/lib/python3.11/threading.py
"<module>  File 
, line "982/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py in "run, line 
314 in   File _bootstrap"
/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py1045" in terminate called after throwing an instance of ', line _bootstrap_innerc10::Error135
'
 in   File _main"
/usr/local/python3.11.13/lib/python3.11/threading.py  File "", line /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py1002" in , line _bootstrap122
 in 
spawn_mainThread 0x
  File 0000fff787fff120" (most recent call first):
<string>  File ", line 1 in <module>
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 395 in 
Extension modules: numpy._core._multiarray_umath_recv
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 430 in _recv_bytes
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py, "numpy.linalg._umath_linalg, line 250 in recv
terminate called after throwing an instance of '  File c10::Error"'
/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py", line 822 in _callmethod
  File "<string>", line 2 in get
  File , "pybase64._pybase64/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py", line 68 in run
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045 in _bootstrap_inner, 
charset_normalizer.md  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000fff9b3fff120 (most recent call first):
  File , "requests.packages.charset_normalizer.md/usr/local/python3.11.13/lib/python3.11/threading.py", line 331 in wait, 
requests.packages.chardet.md  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 629 in wait
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py
Extension modules: "numpy._core._multiarray_umath, line 60 in run
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045,  in numpy.linalg._umath_linalg_bootstrap_inner
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1002 in _bootstrap

Thread 0x0000fffcdf52f120 (most recent call first):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 61 in _recv_msg
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 195 in _read_thread
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 982,  in multidict._multidictrun
  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line 1045 in _bootstrap_inner, 
, yarl._quoting_c  File pybase64._pybase64", /usr/local/python3.11.13/lib/python3.11/threading.pypropcache._helpers_c", line 1002 in _bootstrap

Current thread 0x0000ffff9ea77060 (most recent call first):
, ,   File aiohttp._http_writercharset_normalizer.md"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", aiohttp._http_parser, line , 2981, requests.packages.charset_normalizer.md in aiohttp._websocket.maskrun_scheduler_process
  File , ", requests.packages.chardet.md/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.pyaiohttp._websocket.reader_c", line 108 in run
  File , "frozenlist._frozenlist/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py", line 314 in _bootstrap
,   File torch._C"/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py", line 135,  in torch._C._dynamo.autograd_compiler_main
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py", torch._C._dynamo.eval_frame, line 122 in , spawn_maintorch._C._dynamo.guards
  File "<string>, ", , line torch._C._dynamo.utils1multidict._multidict in , torch._C._fft<module>
, , torch._C._linalgyarl._quoting_c, , torch._C._nestedpropcache._helpers_c, torch._C._nn, aiohttp._http_writer, torch._C._sparse, aiohttp._http_parser, torch._C._special, aiohttp._websocket.mask, aiohttp._websocket.reader_c, frozenlist._frozenlist, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards  what():  LaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:1455, Device:3, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 1455] 2026-01-14-12:10:44.747.054 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffe2b2448c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffe2b1ec140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffcfd24e210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffcfd24eacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffcfd1c5a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffcfd1554c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffcfd157ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffe355a9024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffe2b1e7ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffe359ee314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffe359ee648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffffb8847400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffffb88474d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaab84e08b0 in sglang::scheduler_DP19_TP19_EP19)
, 
torch._C._dynamo.utils, torch._C._fft
Extension modules: , Fatal Python error: torch._C._linalgAbortednumpy._core._multiarray_umath

, torch._C._nestedThread 0x0000fff7b7fff120, ,  (most recent call first):
numpy.linalg._umath_linalgtorch._C._nn  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py", line , 923torch._C._sparse in heartbeat_checker, , torch._C._special
numpy.random._common  File "/usr/local/python3.11.13/lib/python3.11/threading.py", line , 982numpy.random.bit_generator in run
  File , , "pybase64._pybase64numpy.random._bounded_integers/usr/local/python3.11.13/lib/python3.11/threading.py  what():  "LaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:2222, Device:14, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 2222] 2026-01-14-12:10:44.746.684 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffdf65c48c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffdf656c140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffcc924e210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffcc924eacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffcc91c5a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffcc91554c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffcc9157ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffe00929024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffdf6567ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffe00d6e314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffe00d6e648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffff83bc7400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffff83bc74d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaab77508b0 in sglang::scheduler_DP30_TP30_EP30)
, , numpy.random._pcg64, line 
charset_normalizer.md1045,  in numpy.random._generator_bootstrap_inner, 
requests.packages.charset_normalizer.md, Fatal Python error:   File , numpy.random._mt19937, Aborted"requests.packages.chardet.mdnumpy.random._common

, /usr/local/python3.11.13/lib/python3.11/threading.py, numpy.random._philoxThread 0x"numpy.random.bit_generator0000fff723ffe120, , line  (most recent call first):
numpy.random._sfc64  File , 1002numpy.random._bounded_integers"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py, " in numpy.random.mtrand, , line numpy.random._pcg64_bootstrap, 923
 in , , multidict._multidict
heartbeat_checkeracl
numpy.random._generatorThread 0x  File , 0000fff7cbfff120, "numpy.random._mt19937yarl._quoting_c (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py, , , propcache._helpers_c  File "numpy.random._philoxtorch_npu._C, ", line 982aiohttp._http_writer, /usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py in numpy.random._sfc64", , line runaiohttp._http_parser, 799
numpy.random.mtrand in ,   File recv_multipartaiohttp._websocket.mask, , markupsafe._speedups"
[2026-01-14 12:10:44 DP22 TP22 EP22] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011

acl, /usr/local/python3.11.13/lib/python3.11/threading.py  File , aiohttp._websocket.reader_c""yaml._yaml, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py, , "1045, line frozenlist._frozenlist893torch_npu._C in  in [rank26]:[W114 12:10:44.817062865 compiler_depend.ts:59] Warning: [PID: 1462] 2026-01-14-12:02:45.145.265 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:5, dieId:0), serial number is 7, there is an exception of fftsplus aivector error, core id is 17, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35da0, vec error info: 0x621097e0a5, mte error info: 0xd706000064, ifu error info: 0x35bb2c59a6400, ccu error info: 0xf6a884a87571038e, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c146009080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:1, tslot:4, thread:0, ctxid:0, blk:12, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=10, stream_id=1624, report_stream_id=1566, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
_bootstrap_inner, 
torch._Cdecode_thread, psutil._psutil_linux  File 
, , markupsafe._speedups"  File , torch._C._dynamo.autograd_compiler[rank20]:[W114 12:10:44.817128346 compiler_depend.ts:59] Warning: [PID: 1456] 2026-01-14-12:02:45.146.469 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:2, dieId:0), serial number is 6, there is an exception of fftsplus aivector error, core id is 4, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35da0, vec error info: 0xda14f413cc, mte error info: 0xd706000064, ifu error info: 0x20533ee9a40c0, ccu error info: 0x6c36016c034f7e, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c146009080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:0, tslot:0, thread:0, ctxid:0, blk:12, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=4, stream_id=2000, report_stream_id=1942, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
/usr/local/python3.11.13/lib/python3.11/threading.py""zmq.backend.cython._zmq, line , , /usr/local/python3.11.13/lib/python3.11/threading.py1002yaml._yamltorch._C._dynamo.eval_frame",  in , line , PIL._imaging_bootstrap
982torch._C._dynamo.guards, 
 in psutil._psutil_linux, Thread 0xrun0000fff747fff120, torch._C._dynamo.utils
 (most recent call first):
zmq.backend.cython._zmq,   File   File , torch._C._fft"/usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py, ", sentencepiece._sentencepiece"torch._C._linalg[rank31]:[W114 12:10:44.817269506 compiler_depend.ts:59] Warning: [PID: 2223] 2026-01-14-12:02:45.143.491 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:7, dieId:1), serial number is 8, there is an exception of fftsplus aivector error, core id is 12, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35ca4, vec error info: 0x6309f80ea8, mte error info: 0xd706000064, ifu error info: 0x6339b78b3880, ccu error info: 0x7262c0c602371b89, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c146009080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:1, tslot:7, thread:0, ctxid:0, blk:37, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=15, stream_id=1624, report_stream_id=1566, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
/usr/local/python3.11.13/lib/python3.11/threading.pyPIL._imaging, line ", , 799, line torch._C._nestedregex._regex in 1045, recv_multipart in torch._C._nn
_bootstrap_inner, ,   File 
, sentencepiece._sentencepiecenpu_utils"  File torch._C._sparse, /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py, "PIL._imagingft"regex._regex, /usr/local/python3.11.13/lib/python3.11/threading.py, line torch._C._special"893, , line ,  in npu_utils1002_cffi_backenddecode_thread in , 
_bootstrapPIL._imagingft  File , 
"cython.cimports.libc.math/usr/local/python3.11.13/lib/python3.11/threading.py, _cffi_backend
, "Thread 0xscipy._lib._ccallback_c, , line 0000fff79ffff120cython.cimports.libc.math982,  (most recent call first):
 in scipy.linalg._fblas,   File run"scipy._lib._ccallback_c, 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py  File scipy.linalg._flapack, "scipy.linalg._fblas", line [rank23]:[W114 12:10:44.817551088 compiler_depend.ts:59] Warning: [PID: 1459] 2026-01-14-12:02:45.144.234 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:3, dieId:1), serial number is 6, there is an exception of fftsplus aivector error, core id is 26, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35da0, vec error info: 0x3718633e2c, mte error info: 0xd706000064, ifu error info: 0x1d5891ffb2180, ccu error info: 0x1679c805880006b, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c145ff9080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:0, tslot:3, thread:0, ctxid:0, blk:12, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=7, stream_id=2000, report_stream_id=1942, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
, /usr/local/python3.11.13/lib/python3.11/threading.py, 375, scipy.linalg.cython_lapack" in scipy.linalg._flapacknumpy.random._common, , line 1045_watchdog_oncescipy.linalg._cythonized_array_utils, , scipy.linalg.cython_lapack in 
numpy.random.bit_generator_bootstrap_inner, ,   File 
, scipy.linalg._solve_toeplitzscipy.linalg._cythonized_array_utils"terminate called after throwing an instance of '  File numpy.random._bounded_integers/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py, , scipy.linalg._decomp_lu_cythonnumpy.random._pcg64c10::Error, ""scipy.linalg._solve_toeplitz'
, , numpy.random._generatorscipy.linalg._matfuncs_sqrtm_triu/usr/local/python3.11.13/lib/python3.11/threading.py, line , , ", 360scipy.linalg._decomp_lu_cythonnumpy.random._mt19937, line scipy.linalg._matfuncs_expm in , 1002, , _watchdog_threadscipy.linalg._matfuncs_sqrtm_triu
 in scipy.linalg._linalg_pythrannumpy.random._philox  File , _bootstrap"scipy.linalg._matfuncs_expm, , 
/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.linalg.cython_blasnumpy.random._sfc64, 
"Thread 0xscipy.linalg._linalg_pythran, , , line 0000fff783fff120 (most recent call first):
numpy.random.mtrandscipy.linalg._decomp_update, 982  File  in scipy.linalg.cython_blas, , "runscipy.sparse._sparsetoolsacl, /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py
  File , "scipy.linalg._decomp_update"_csparsetools/usr/local/python3.11.13/lib/python3.11/threading.py, line , , , "scipy.sparse._csparsetools375scipy.sparse._sparsetoolstorch_npu._C, line  in , , _csparsetools1045_watchdog_oncescipy.sparse.linalg._dsolve._superlu in _bootstrap_inner
, , 
  File scipy.sparse._csparsetoolsscipy.sparse.linalg._eigen.arpack._arpack  File "", , /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._propack._spropack""markupsafe._speedups, , line , , line scipy.sparse.linalg._eigen.arpack._arpack360scipy.sparse.linalg._propack._dpropack1002, yaml._yaml,  in scipy.sparse.linalg._propack._spropack in , _watchdog_thread_bootstrap, scipy.sparse.linalg._propack._cpropack

scipy.sparse.linalg._propack._dpropack  File 
", , , Thread 0xscipy.sparse.linalg._propack._cpropackscipy.sparse.linalg._propack._zpropack/usr/local/python3.11.13/lib/python3.11/threading.pypsutil._psutil_linux0000fff96bfff120, ",  (most recent call first):
, scipy.sparse.linalg._propack._zpropack, line scipy.sparse.csgraph._tools  File zmq.backend.cython._zmq, 982, "scipy.sparse.csgraph._shortest_path in scipy.sparse.csgraph._tools/usr/local/python3.11.13/lib/python3.11/threading.py"run, , scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._shortest_path, line , 
scipy.sparse.csgraph._traversalPIL._imaging, 327  File scipy.sparse.csgraph._min_spanning_tree in , "waitscipy.sparse.csgraph._min_spanning_tree
, /usr/local/python3.11.13/lib/python3.11/threading.py  File , scipy.sparse.csgraph._flowscipy.sparse.csgraph._flow"", line , , scipy.sparse.csgraph._matching  what():  /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyLaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:1461, Device:9, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 1461] 2026-01-14-12:10:44.748.657 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffdef6548c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffdef5fc140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffcc124e210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffcc124eacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffcc11c5a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffcc11554c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffcc1157ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffdf99b9024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffdef5f7ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffdf9dfe314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffdf9dfe648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffff7cc57400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffff7cc574d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaad0e308b0 in sglang::scheduler_DP25_TP25_EP25)
, 
1045sentencepiece._sentencepiecescipy.sparse.csgraph._matching",  in , line , scipy.sparse.csgraph._reordering, Fatal Python error: _bootstrap_inner231scipy.sparse.csgraph._reorderingregex._regexAborted


 in   File Thread 0x, , , _feed"scipy.optimize._group_columns0000fff73ffff120npu_utilsscipy.optimize._group_columns
, /usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
  File , , scipy._lib.messagestreamscipy._lib.messagestream"  File , line "PIL._imagingft, , "scipy.optimize._trlib._trlib1002/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.optimize._trlib._trlib/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py in , , _bootstrap"
"scipy.optimize._lbfgsb, _cffi_backendscipy.optimize._lbfgsb, line 
, line , 982Thread 0x, 923, _moduleTNCcython.cimports.libc.math in 0000fff937fff120_moduleTNC in , run,  (most recent call first):
, heartbeat_checkerscipy.optimize._moduleTNC
scipy.optimize._moduleTNCscipy._lib._ccallback_c
  File   File ,   File scipy.optimize._cobyla, , """scipy.linalg._fblas/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.optimize._cobyla, /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py", scipy.optimize._slsqpscipy.linalg._flapack", ", line , , , line scipy.optimize._minpackscipy.optimize._slsqp, line 982scipy.linalg.cython_lapack3271045,  in scipy.optimize._lsq.givens_elimination,  in ,  in runscipy.optimize._minpack, waitscipy.linalg._cythonized_array_utils_bootstrap_inner
  File scipy.optimize._zeros, 
scipy.optimize._lsq.givens_elimination
"  File , , ,   File /usr/local/python3.11.13/lib/python3.11/threading.py"scipy.linalg._solve_toeplitzscipy.optimize._zerosscipy.optimize._cython_nnls""/usr/local/python3.11.13/lib/python3.11/threading.py, , , , line scipy._lib._uarray._uarray/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"scipy.linalg._decomp_lu_cythonscipy.optimize._cython_nnls1045" in , , line , , line , _bootstrap_innerscipy.special._ufuncs_cxx1002scipy.linalg._matfuncs_sqrtm_triu231scipy._lib._uarray._uarray
 in ,  in scipy.special._ufuncs,   File "_bootstrap, _feedscipy.linalg._matfuncs_expm, /usr/local/python3.11.13/lib/python3.11/threading.py
scipy.special._ufuncs_cxx
scipy.special._specfun", , 
  File , line scipy.linalg._linalg_pythranscipy.special._ufuncs, Thread 0x, "1002scipy.special._comb in 0000fff977fff120, scipy.special._specfun/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap (most recent call first):
, , scipy.linalg.cython_blas"
  File 
scipy.special._ellip_harm_2Thread 0xscipy.special._comb, line , , ", 0000fff74bfff120982 (most recent call first):
scipy.linalg._decomp_updatescipy.linalg._decomp_interpolative/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.special._ellip_harm_2 in ,   File ", , runscipy.optimize._bglu_dense", line scipy.linalg._decomp_interpolativescipy.sparse._sparsetools
/usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py, 327  File "scipy.optimize._lsap, ,  in ", line _csparsetoolsscipy.optimize._bglu_dense, wait/usr/local/python3.11.13/lib/python3.11/threading.py, "799, scipy.spatial._ckdtreescipy.sparse._csparsetools
scipy.optimize._lsap  File , , line  in 1045, "scipy.spatial._qhull, recv_multipart in scipy.sparse.linalg._dsolve._superlu/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyscipy.spatial._ckdtree, _bootstrap_inner
, "scipy.sparse.linalg._eigen.arpack._arpack
  File scipy.spatial._voronoi, , line ,   File "scipy.spatial._qhull, 231scipy.sparse.linalg._propack._spropack/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py" in scipy.spatial._distance_wrap_feed, ", , line /usr/local/python3.11.13/lib/python3.11/threading.py
, scipy.spatial._voronoiscipy.sparse.linalg._propack._dpropack893"  File , scipy.spatial._hausdorff in , line , "scipy.sparse.linalg._propack._cpropackdecode_thread1002, scipy.spatial._distance_wrap/usr/local/python3.11.13/lib/python3.11/threading.py
 in , scipy.spatial.transform._rotation", , line   File _bootstrapscipy.sparse.linalg._propack._zpropackscipy.spatial._hausdorff, 982"
, scipy.optimize._direct,  in /usr/local/python3.11.13/lib/python3.11/threading.py
scipy.spatial.transform._rotationscipy.sparse.csgraph._toolsrun"Thread 0x, 
, , , line 0000fff943fff120setproctitle._setproctitle  File scipy.sparse.csgraph._shortest_pathscipy.optimize._direct982 (most recent call first):
 in   File ", run, 
Cython.Utils"/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.sparse.csgraph._traversal  File , /usr/local/python3.11.13/lib/python3.11/threading.py", "Cython.Plex.Actions/usr/local/python3.11.13/lib/python3.11/threading.py, ", line setproctitle._setproctitle", scipy.sparse.csgraph._min_spanning_tree, line 1045, line Cython.Plex.Transitions327,  in 1045, ,  in scipy.sparse.csgraph._flow_bootstrap_inner in Cython.Utils_bootstrap_innerCython.Plex.Machineswait

,   File 
, ,   File Cython.Plex.DFAscipy.sparse.csgraph._matching"  File Cython.Plex.Actions", /usr/local/python3.11.13/lib/python3.11/threading.py", /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, Cython.Plex.Scanners"/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.sparse.csgraph._reordering"Cython.Plex.Transitions, line , ", line 1002Cython.Compiler.Scanning, , , line , 231 in scipy.optimize._group_columnsCython.Plex.Machines_bootstrap1002Cython.StringIOTree
 in  in , , scipy._lib.messagestream
_bootstrap, _feedCython.Plex.DFAThread 0x
Cython.Compiler.Code, 
scipy.optimize._trlib._trlib0000fff983fff120, , 
, scipy.optimize._lbfgsb  File  (most recent call first):
Cython.Plex.Scannersgoogle._upb._messageThread 0x"  File /usr/local/python3.11.13/lib/python3.11/threading.py, 0000fff7d3fff120, ""_moduleTNC (most recent call first):
Cython.Compiler.Scanning/usr/local/python3.11.13/lib/python3.11/threading.py, line ,   File ", "982scipy.optimize._moduleTNC, line , , Cython.StringIOTree/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py in 327msgspec._corescipy.optimize._cobyla"run,  in Cython.Compiler.Code, line 
, , wait375terminate called after throwing an instance of '  File c10::Error'
scipy.optimize._slsqppyarrow.lib
,  in google._upb._message"_watchdog_once  File , , /usr/local/python3.11.13/lib/python3.11/threading.py
"scipy.optimize._minpackpandas._libs.tslibs.ccalendar"  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line ", /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py, "1045pandas._libs.tslibs.np_datetime"scipy.optimize._lsq.givens_elimination, line  in , , line pandas._libs.tslibs.dtypes231_bootstrap_inner, 360 in , 
scipy.optimize._zeros in _feed_watchdog_threadpandas._libs.tslibs.base  File 
, 
", ,   File scipy.optimize._cython_nnls  File /usr/local/python3.11.13/lib/python3.11/threading.pypandas._libs.tslibs.nattypemsgspec._core", ""[2026-01-14 12:10:44 DP26 TP26 EP26] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011

, /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.pypandas._libs.tslibs.timezones"[2026-01-14 12:10:44 DP20 TP20 EP20] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011

, line scipy._lib._uarray._uarray", line , 982, 1002, line pandas._libs.tslibs.fields,  in , pyarrow.lib in 982scipy.special._ufuncs_cxxrunpandas._libs.tslibs.timedeltas, _bootstrapscipy.special._ufuncs in , 
, , 
pandas._libs.tslibs.tzconversionrunpandas._libs.tslibs.ccalendar  File scipy.special._specfun"/usr/local/python3.11.13/lib/python3.11/threading.py
, 
scipy.special._comb, , "Thread 0x  File pandas._libs.tslibs.timestamps"pandas._libs.tslibs.np_datetime, , line 0000fff94ffff120/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.special._ellip_harm_2, , 1045 (most recent call first):
 in , "scipy.linalg._decomp_interpolativepandas._libs.propertiespandas._libs.tslibs.dtypes_bootstrap_inner,   File 
", line 1045scipy.optimize._bglu_dense, ,   File /usr/local/python3.11.13/lib/python3.11/threading.py in ", line pandas._libs.tslibs.offsetspandas._libs.tslibs.base", _bootstrap_inner327/usr/local/python3.11.13/lib/python3.11/threading.py, ", scipy.optimize._lsappandas._libs.tslibs.nattype
 in pandas._libs.tslibs.strptime, line   File , , wait, 1002"pandas._libs.tslibs.parsingscipy.spatial._ckdtree
pandas._libs.tslibs.timezones in /usr/local/python3.11.13/lib/python3.11/threading.py,   File , _bootstrap, "pandas._libs.tslibs.conversion"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyscipy.spatial._qhull
pandas._libs.tslibs.fields, line ", 
, , pandas._libs.tslibs.timedeltasscipy.spatial._voronoi1002, line  in , pandas._libs.tslibs.periodThread 0x[2026-01-14 12:10:44 DP23 TP23 EP23] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011

, 231_bootstrapscipy.spatial._distance_wrap0000fff923fff120, pandas._libs.tslibs.tzconversion in 
 (most recent call first):
pandas._libs.tslibs.vectorized, _feed, 

  File scipy.spatial._hausdorff, pandas._libs.tslibs.timestamps  File Thread 0x"  what():  /usr/local/python3.11.13/lib/python3.11/threading.py"pandas._libs.ops_dispatch, line , , 327"pandas._libs.properties0000fff98ffff120LaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:1458, Device:6, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 1458] 2026-01-14-12:10:44.750.597 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffe051748c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffe0511c140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffcd924e210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffcd924eacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffcd91c5a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffcd91554c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffcd9157ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffe0f4d9024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffe05117ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffe0f91e314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffe0f91e648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffff92777400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffff927774d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaab9ba08b0 in sglang::scheduler_DP22_TP22_EP22)
[2026-01-14 12:10:44 DP31 TP31 EP31] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011

scipy.spatial.transform._rotation,  in /usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
"
, line , waitpandas._libs.missing,   File 982pandas._libs.tslibs.offsets
scipy.optimize._direct, pandas._libs.hashtable, " in Fatal Python error:   File pandas._libs.tslibs.strptime, /usr/local/python3.11.13/lib/python3.11/threading.pyrunAborted
"pandas._libs.algos, pandas._libs.tslibs.parsing, "

  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, setproctitle._setproctitle, , line "Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.pypandas._libs.interval"pandas._libs.tslibs.conversion, line 327"0000fff787fff120 (most recent call first):
, , 231 in , , line   File Cython.Utils"pandas._libs.lib in waitpandas._libs.tslibs.period1045_feed/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py, "
,  in , 
Cython.Plex.Actions, line   File pyarrow._compute_bootstrap_innerpandas._libs.tslibs.vectorized
  File , 923" in , "Cython.Plex.Transitions  File pandas._libs.ops, "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyheartbeat_checker/usr/local/python3.11.13/lib/python3.11/threading.pypandas._libs.ops_dispatch, /usr/local/python3.11.13/lib/python3.11/threading.py, "
"Cython.Plex.Machines"pandas._libs.hashing, , line   File , line , line pandas._libs.missing1002, , 231"982/usr/local/python3.11.13/lib/python3.11/threading.py in Cython.Plex.DFA, pandas._libs.arrays in  in "_bootstrappandas._libs.hashtable, _feed, line 982run, 
pandas._libs.tslibCython.Plex.Scanners
,  in 

Thread 0x,   File pandas._libs.algos, run  File 0000fff95bfff120pandas._libs.sparse (most recent call first):
"Cython.Compiler.Scanning
, "  File /usr/local/python3.11.13/lib/python3.11/threading.py,   File , pandas._libs.interval/usr/local/python3.11.13/lib/python3.11/threading.py""pandas._libs.internals"Cython.StringIOTree"/usr/local/python3.11.13/lib/python3.11/threading.py, line , , line /usr/local/python3.11.13/lib/python3.11/threading.py, , "1045pandas._libs.lib982" in pandas._libs.indexingCython.Compiler.Code, line , line  in , run1045, , pandas._libs.index327_bootstrap_inner in pyarrow._compute
  File  in google._upb._message_bootstrap_inner
, wait"
, 
  File pandas._libs.writers  File /usr/local/python3.11.13/lib/python3.11/threading.py"pandas._libs.ops,   File ""/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pypandas._libs.join/usr/local/python3.11.13/lib/python3.11/threading.py, ", line ""pandas._libs.hashing, , line 10451002, line , line pandas._libs.window.aggregations,  in  in 2311002_bootstrappandas._libs.arrays, _bootstrap_inner,  in  in 
_feedpandas._libs.window.indexers

, msgspec._core_bootstrap
  File Thread 0x"  File /usr/local/python3.11.13/lib/python3.11/threading.py, "pandas._libs.tslib, line 982
0000fff79ffff120,  (most recent call first):
"pandas._libs.reshape  File /usr/local/python3.11.13/lib/python3.11/threading.py in , 
pyarrow.lib"", runpandas._libs.sparseThread 0x/usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py, line , pandas._libs.groupby
0000fff92ffff120  File ", "1002, line pandas._libs.tslibs.ccalendar (most recent call first):
, /usr/local/python3.11.13/lib/python3.11/threading.pypandas._libs.internals in 799  File  in pandas._libs.json", , , line _bootstrap"recv_multipartpandas._libs.indexingpandas._libs.tslibs.np_datetime, 1045
/usr/local/python3.11.13/lib/python3.11/threading.py
  File , pandas._libs.parsers in , _bootstrap_innerpandas._libs.tslibs.dtypes
"", pandas._libs.index, 
Thread 0x, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.pypandas._libs.tslibs.base, pandas._libs.testing  File 0000fff99bfff120327, "pandas._libs.writers, " (most recent call first):
 in pyarrow._parquet  File , line pandas._libs.tslibs.nattype/usr/local/python3.11.13/lib/python3.11/threading.py, wait", 893" in pandas._libs.join
, /usr/local/python3.11.13/lib/python3.11/threading.pypyarrow._fs, line decode_thread  File pandas._libs.tslibs.timezones, "1002
, "pandas._libs.window.aggregations, , line  in   File _bootstrappyarrow._azurefs/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
pandas._libs.tslibs.fields327, , pandas._libs.window.indexers""
 in pyarrow._hdfs, /usr/local/python3.11.13/lib/python3.11/threading.py, line Thread 0x", waitpandas._libs.tslibs.timedeltas, 2310000fff967fff120, line pandas._libs.reshape982
pyarrow._gcsfs in ,  (most recent call first):
 in   File , _feedpandas._libs.groupbypandas._libs.tslibs.tzconversion,   File "run"

pyarrow._s3fs  File , , /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File "pandas._libs.jsonpandas._libs.tslibs.timestamps, "xxhash._xxhash""/usr/local/python3.11.13/lib/python3.11/threading.py, , line , , , line /usr/local/python3.11.13/lib/python3.11/threading.py"pyarrow._acero327 in pandas._libs.propertiespandas._libs.parsers231", line , wait
 in   File , , pandas._libs.tslibs.offsets, line pyarrow._csv982_feed"
pandas._libs.testing in 1045, , /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File "run in pandas._libs.tslibs.strptimepyarrow._json, , "/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner
pyarrow._parquet  File , pandas._libs.tslibs.parsing, line "
"pyarrow._substrait, , 231, line   File /usr/local/python3.11.13/lib/python3.11/threading.pypyarrow._fspandas._libs.tslibs.conversion",  in 982" in /usr/local/python3.11.13/lib/python3.11/threading.pypyarrow._dataset, line , , pyarrow._azurefs_feedrun"1045, line  in _bootstrap_innerpandas._libs.tslibs.period, 
, 
1002
pyarrow._dataset_orc  File , pyarrow._hdfspandas._libs.tslibs.vectorized  File  in "  File "", , , _bootstrappyarrow._gcsfs/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.pypyarrow._parquet_encryptionpandas._libs.ops_dispatch
", 
"Thread 0x"0000fff7b7fff120,  (most recent call first):
, pandas._libs.missing, line pyarrow._s3fs, line , line pyarrow._dataset_parquet_encryption982  File 1045, , 1002,  in "run in pandas._libs.hashtable in pyarrow._dataset_parquetxxhash._xxhash/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py
"_bootstrap_inner, line _bootstrap375, , pandas._libs.algos  File 

  File  in pyarrow._acero", /usr/local/python3.11.13/lib/python3.11/threading.py
, "_watchdog_once/usr/local/python3.11.13/lib/python3.11/threading.pypandas._libs.interval"Thread 0xpyarrow._csv
", line 0000fff93bfff120,  (most recent call first):
  File , terminate called after throwing an instance of 'pyarrow._json, line 1045, terminate called after throwing an instance of 'pandas._libs.lib  File "c10::Error1002'
,  in pyarrow._computepyarrow._substraitc10::Error"'
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py in _bootstrap_inner
, , /usr/local/python3.11.13/lib/python3.11/threading.py""_bootstrap  File pandas._libs.opspyarrow._dataset, line , line 
"/usr/local/python3.11.13/lib/python3.11/threading.py360, , 327
" in , line pandas._libs.hashing_watchdog_threadpyarrow._dataset_orc in Thread 0xwait, 
1002
 in , _bootstrap0000fff9a7fff120

, Thread 0x__triton_launcher  File   File "pandas._libs.arrays (most recent call first):
0000fff973fff120pyarrow._parquet_encryption (total: "174/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File , " (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py"), pandas._libs.tslib/usr/local/python3.11.13/lib/python3.11/threading.py  File ", line 
pyarrow._dataset_parquet_encryption", "/usr/local/python3.11.13/lib/python3.11/threading.py, line 231, line , pandas._libs.sparse"982 in  in 327pyarrow._dataset_parquet, line , run_feed in terminate called after throwing an instance of '327pandas._libs.internals

waitc10::Error in   File   File 
, '
wait""/usr/local/python3.11.13/lib/python3.11/threading.py"  File pandas._libs.indexing
/usr/local/python3.11.13/lib/python3.11/threading.py, line "  File ", 1045[rank29]:[W114 12:10:44.822263484 compiler_depend.ts:59] Warning: [PID: 2221] 2026-01-14-12:02:45.145.435 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:6, dieId:1), serial number is 6, there is an exception of fftsplus aivector error, core id is 15, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35da0, vec error info: 0x6210c0a234, mte error info: 0xd706000064, ifu error info: 0x40b6f4d808c0, ccu error info: 0x5c39a408151dc83c, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c146009080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:1, tslot:5, thread:0, ctxid:0, blk:12, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=13, stream_id=1624, report_stream_id=1566, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py", line pandas._libs.index982 in [rank21]:[W114 12:10:44.822288824 compiler_depend.ts:59] Warning: [PID: 1457] 2026-01-14-12:02:45.143.063 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:2, dieId:1), serial number is 9, there is an exception of fftsplus aivector error, core id is 16, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35da0, vec error info: 0xf3045091b0, mte error info: 0xd706000064, ifu error info: 0x1a89f06c5e740, ccu error info: 0x1b4823910c100c95, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c146019080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:1, tslot:1, thread:0, ctxid:0, blk:12, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=5, stream_id=2000, report_stream_id=1942, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in , _bootstrap_innerpandas._libs.writers
, line "231run  File , , line  in 231
" in pandas._libs.join_feed_feedterminate called after throwing an instance of '/usr/local/python3.11.13/lib/python3.11/threading.py, "  File 
, line 
c10::Errorpandas._libs.window.aggregations"  File /usr/local/python3.11.13/lib/python3.11/threading.py1002  File  in _bootstrap'
", ", "

/usr/local/python3.11.13/lib/python3.11/threading.pypandas._libs.window.indexers, line __triton_launcher/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x (total: "1045, "0000fff93bfff120174, line  in 982pandas._libs.reshape_bootstrap_inner, line  (most recent call first):
)  File " in /usr/local/python3.11.13/lib/python3.11/threading.py
, 982  File 
run"pandas._libs.groupby in "
, line   what():  runLaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:1462, Device:10, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 1462] 2026-01-14-12:10:44.753.445 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffdee1648c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffdee10c140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffcc124e210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffcc124eacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffcc11c5a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffcc11554c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffcc1157ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffdf84c9024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffdee107ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffdf890e314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffdf890e648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffff7b767400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffff7b7674d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaab23508b0 in sglang::scheduler_DP26_TP26_EP26)
/usr/local/python3.11.13/lib/python3.11/threading.py,   File 327

"pandas._libs.json  what():  " in   File , wait", line /usr/local/python3.11.13/lib/python3.11/threading.pyLaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:1456, Device:4, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 1456] 2026-01-14-12:10:44.753.447 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffe029648c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffe0290c140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffcd524e210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffcd524eacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffcd51c5a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffcd51554c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffcd5157ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffe0ccc9024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffe02907ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffe0d10e314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffe0d10e648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffff8ff67400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffff8ff674d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaacbc908b0 in sglang::scheduler_DP20_TP20_EP20)
Fatal Python error: 
pandas._libs.parsers
/usr/local/python3.11.13/lib/python3.11/threading.py  File 1002""Aborted",  in pandas._libs.testing, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyFatal Python error: 

, line _bootstrap10451045" in Aborted, line , Thread 0x
 in _bootstrap_inner

231pyarrow._parquetThread 0x0000fff76ffff120
 (most recent call first):
0000fff777fff120Thread 0x  File _bootstrap_inner"
 in ,  (most recent call first):
0000fff947fff120
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py  File _feed
pyarrow._fs  File  (most recent call first):
  File ", "  File "  File ", line /usr/local/python3.11.13/lib/python3.11/threading.pypyarrow._azurefs923/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py/usr/local/python3.11.13/lib/python3.11/threading.py"" in , heartbeat_checker"
"  File "/usr/local/python3.11.13/lib/python3.11/threading.py, line , line pyarrow._hdfs, line 1002, line  in ""  what():  982, line 1002, 923/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrapLaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:1459, Device:7, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 1459] 2026-01-14-12:10:44.753.755 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffe060748c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffe0601c140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffcd924e210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffcd924eacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffcd91c5a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffcd91554c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffcd9157ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffe103d9024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffe06017ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffe1081e314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffe1081e648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffff93677400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffff936774d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaab13808b0 in sglang::scheduler_DP23_TP23_EP23)
 in 327 in pyarrow._gcsfs in "
, line 
run982
 in   File _bootstrap", /usr/local/python3.11.13/lib/python3.11/threading.pyheartbeat_checker
 in wait
Fatal Python error: 
pyarrow._s3fs"
Thread 0xrun
AbortedThread 0x, line   File "0000fff97ffff120, 
  File 

0000fff9b3fff1201045Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
xxhash._xxhash  File   File "" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py in 0000fff77bfff120"", line "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  what():  ",   File _bootstrap_inner (most recent call first):
, line 1045/usr/local/python3.11.13/lib/python3.11/threading.pyLaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:2223, Device:15, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 2223] 2026-01-14-12:10:44.753.894 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffe255b48c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffe2555c140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffcf924e210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffcf924eacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffcf91c5a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffcf91554c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffcf9157ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffe2f919024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffe25557ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffe2fd5e314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffe2fd5e648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffffb2bb7400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffffb2bb74d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaacf1208b0 in sglang::scheduler_DP31_TP31_EP31)
", line pyarrow._acero"
  File /usr/local/python3.11.13/lib/python3.11/threading.py982 in 
, line 231,  in "  File " in _bootstrap_inner327pyarrow._csv_feed/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py"Fatal Python error: , line run
 in   File [rank28]:[W114 12:10:44.823057679 compiler_depend.ts:59] Warning: [PID: 2220] 2026-01-14-12:02:45.145.996 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:6, dieId:0), serial number is 9, there is an exception of fftsplus aivector error, core id is 4, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35ca4, vec error info: 0x310112181e, mte error info: 0xd706000064, ifu error info: 0x4c0cf6b9f9800, ccu error info: 0x84c9f9f9221f6e6b, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c146018080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:1, tslot:7, thread:0, ctxid:0, blk:37, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=12, stream_id=1624, report_stream_id=1566, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
"
/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py, "Aborted327
wait  File "", line , line /usr/local/python3.11.13/lib/python3.11/threading.pypyarrow._json, line 1002

 in  in Thread 0x  File 
1002  File 923 in "", /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"_bootstrap
wait"
0000fff76ffff120 in _bootstrap, line 
pyarrow._substrait, line 
Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py  File " (most recent call first):
heartbeat_checker982
231, 0000fff947fff120", line 1045  File  in run
Thread 0x  File  in "pyarrow._dataset (most recent call first):
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in "
0000fff787fff120_feed/usr/local/python3.11.13/lib/python3.11/threading.py  File """, _bootstrap_inner/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.pypyarrow._dataset_orc"  File  (most recent call first):

, /usr/local/python3.11.13/lib/python3.11/threading.py, line , line [rank18]:[W114 12:10:44.823305120 compiler_depend.ts:59] Warning: [PID: 1454] 2026-01-14-12:02:45.145.747 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:1, dieId:0), serial number is 6, there is an exception of fftsplus aivector error, core id is 8, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35da0, vec error info: 0xb51698d12e, mte error info: 0xd706000064, ifu error info: 0x572d7ae8c0100, ccu error info: 0x8ef20edc1101073d, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c14601a080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:0, tslot:2, thread:0, ctxid:0, blk:12, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=2, stream_id=712, report_stream_id=654, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
231
, line "  File   File pyarrow._parquet_encryption"982 in   File _feed923/usr/local/python3.11.13/lib/python3.11/threading.py in """/usr/local/python3.11.13/lib/python3.11/threading.py, line  in , "
heartbeat_checker/usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py, line "327runpyarrow._dataset_parquet_encryption/usr/local/python3.11.13/lib/python3.11/threading.py  File 
"1045, line 
 in   File ", pyarrow._dataset_parquet"  File , line  in 982_bootstrap_inner"wait/usr/local/python3.11.13/lib/python3.11/threading.py, line /usr/local/python3.11.13/lib/python3.11/threading.py"799 in 

"1002"/usr/local/python3.11.13/lib/python3.11/threading.py in runrecv_multipart  File 
"  File , line  in , line "
  File   File /usr/local/python3.11.13/lib/python3.11/threading.py1045"_bootstrap982, line ""/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py" in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py_bootstrap_inner
 in 982/usr/local/python3.11.13/lib/python3.11/threading.py in "run, line 
"
runThread 0x"0000fff78ffff120, line 
1002  File , line 
[rank27]:[W114 12:10:44.823590682 compiler_depend.ts:59] Warning: [PID: 1463] 2026-01-14-12:02:45.145.060 Invalid_Argument(EE1001): The argument is invalid.Reason: Invalid stream attribute ID: 4, Supported stream attribute IDs: [1, 4).
        Solution: 1.Check the input parameter range of the function. 2.Check the function invocation relationship.
        TraceBack (most recent call last):
        The argument is invalid.Reason: rtsStreamSetAttribute execute failed, reason=[invalid value]
        call rtsStreamSetAttribute failed, runtime result = 107000[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        rtMemcpy execute failed, reason=[the current capture mode does not support this operation][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronized memcpy failed, kind = 1, runtime result = 107030[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
        The error from device(chipId:5, dieId:1), serial number is 7, there is an exception of fftsplus aivector error, core id is 14, error code = 0x800000, dump info: pc start: 0x12c0c3b31ca4, current: 0x12c0c3b35da0, vec error info: 0x4f118675aa, mte error info: 0xd706000064, ifu error info: 0x120309c7001c0, ccu error info: 0x4c06eca47c51268f, cube error info: 0, biu error info: 0, aic error mask: 0x6500020bd00028c, para base: 0x12c145ff8080.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:333]
        The extend info: errcode:(0x800000, 0, 0) errorStr: The DDR address of the MTE instruction is out of range. fixp_error0 info: 0x6000064, fixp_error1 info: 0xd7, fsmId:0, tslot:1, thread:0, ctxid:0, blk:12, sublk:0, subErrType:4.[FUNC:ProcessStarsCoreErrorInfo][FILE:device_error_core_proc.cc][LINE:353]
        [AIC_INFO] after execute:args print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        [AIC_INFO] after execute:mixCtx print end[FUNC:GetError][FILE:stream.cc][LINE:1191]
        Aicore kernel execute failed, device_id=11, stream_id=1624, report_stream_id=1566, task_id=45, flip_num=0, fault kernel_name=MoeDistributeDispatchV2_ba45fbab40242269e8d51354bcf25161_10002, fault kernel info ext=none, program id=70, hash=13040224529444704133.[FUNC:GetError][FILE:stream.cc][LINE:1191]
        rtStreamSynchronize execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
        synchronize stream failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]
 (function copy_between_host_and_device_opapi)
, line  (most recent call first):
893  File  in "231  File 1045  File  in  in /usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap"/usr/local/python3.11.13/lib/python3.11/threading.py" in "decode_thread/usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py_feed", 
"/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner

"
, line __triton_launcher
, line  (total: "  File   File , line 1002  File Thread 0x1045174 in , line ""/usr/local/python3.11.13/lib/python3.11/threading.py799 in "0000fff953fff120)_bootstrap_inner1045"/usr/local/python3.11.13/lib/python3.11/threading.py in , line _bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py
" (most recent call first):


 in "recv_multipart, line 1002
, line   File   File _bootstrap_inner"
982  File  in Thread 0x9820000fff793fff120 in "
/usr/local/python3.11.13/lib/python3.11/threading.py in "_bootstrap (most recent call first):
run/usr/local/python3.11.13/lib/python3.11/threading.py  File "run/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py


  File "", line "  File 
  File "/usr/local/python3.11.13/lib/python3.11/threading.py, line 1002, line "Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py/usr/local/python3.11.13/lib/python3.11/threading.py"327 in 893 in 0000fff98bfff120""", line _bootstrap in wait
 (most recent call first):
, line   File , line , line 7991002decode_thread

  File 1045""1045 in  in recv_multipart in 
Thread 0x in 0000fff77bfff120/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/threading.py"_bootstrap_inner
, line _bootstrap  File _bootstrap_inner (most recent call first):
"  File 
327
"

  File , line   File " in /usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x  File "231"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.pywait"0000fff9bffff120"/usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py in /usr/local/python3.11.13/lib/python3.11/threading.py""
, line , line  (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py"_feed, line   File 1002982 in "  File 
, line 893" in run, line "  File /usr/local/python3.11.13/lib/python3.11/threading.py799" in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pydecode_thread_bootstrap
1002" in , line "

  File  in /usr/local/python3.11.13/lib/python3.11/threading.py"recv_multipart327, line 
  File "_bootstrap, line 
 in 231Thread 0x"0000fff953fff120/usr/local/python3.11.13/lib/python3.11/threading.py
982  File  in wait in /usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
"
"run
_feed"  File , line Thread 0x1045/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py
  File ", line 
0000fff7e7fff120 in "  File "/usr/local/python3.11.13/lib/python3.11/threading.py, line 982  File  (most recent call first):
_bootstrap_inner"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"893 in , line "  File 
/usr/local/python3.11.13/lib/python3.11/threading.py" in , line run327/usr/local/python3.11.13/lib/python3.11/threading.py"  File "decode_thread231 in 
wait"  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py", line 
 in 
, line ""/usr/local/python3.11.13/lib/python3.11/threading.py1045  File  in _feed  File 982"/usr/local/python3.11.13/lib/python3.11/threading.py, line ""_bootstrap_inner
 in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"375, line /usr/local/python3.11.13/lib/python3.11/threading.py
  File run", line  in 1002"  File "
, line   File 1045_watchdog_once in , line "/usr/local/python3.11.13/lib/python3.11/threading.py231" in /usr/local/python3.11.13/lib/python3.11/threading.py
_bootstrap982/usr/local/python3.11.13/lib/python3.11/threading.py" in _bootstrap_inner"  File 
, line  in "run, line _feed

  File ""
1045, line 
982  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py/usr/local/python3.11.13/lib/python3.11/threading.py"Thread 0x in 1002  File  in "", line 0000fff7ebfff120_bootstrap_inner in "run/usr/local/python3.11.13/lib/python3.11/threading.py, line 360 (most recent call first):

_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py
"1002 in   File   File 
"  File , line  in _watchdog_thread""
, line "1045982_bootstrap
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x/usr/local/python3.11.13/lib/python3.11/threading.py in 
 in 
runThread 0x  File ""0000fff95ffff120"_bootstrap_inner
[2026-01-14 12:10:44 DP21 TP21 EP21] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011

0000fff7a7fff120", line , line  (most recent call first):
, line 
  File  (most recent call first):
"/usr/local/python3.11.13/lib/python3.11/threading.py3751002  File 1045  File   File /usr/local/python3.11.13/lib/python3.11/threading.py" in  in " in /usr/local/python3.11.13/lib/python3.11/threading.py""", line _watchdog_once_bootstrap_bootstrap_inner"/usr/local/python3.11.13/lib/python3.11/threading.py, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py1045"982


, line " in , line  in   File 
  File 327, line _bootstrap_inner375run"Thread 0x" in 1002
 in 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py0000fff717fff120/usr/local/python3.11.13/lib/python3.11/threading.pywait in   File _watchdog_once  File " (most recent call first):
"
_bootstrap"/usr/local/python3.11.13/lib/python3.11/threading.py
", line 360  File , line   File 
""  File /usr/local/python3.11.13/lib/python3.11/threading.py in ""1002
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line "_watchdog_thread, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py in Thread 0x"1002/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py, line 
1045"_bootstrap0000fff7a3fff120 in "231  File  in , line 
 (most recent call first):
_bootstrap, line 
" in _bootstrap_inner395
  File 360
/usr/local/python3.11.13/lib/python3.11/threading.py_feed
 in   File Thread 0x"Thread 0x in "
_recv"0000fff8cffff120/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py0000fff95ffff120_watchdog_thread", line   File 
 (most recent call first):
" (most recent call first):

  File , line 982" in   File /usr/local/python3.11.13/lib/python3.11/threading.py, line   File "[2026-01-14 12:10:44 DP29 TP29 EP29] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011

  File "375run""1002, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py982"/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py in 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py in " in , line ""_watchdog_once  File "_bootstraprun395, line , line 
", line 

 in 982327 in _recv  File /usr/local/python3.11.13/lib/python3.11/threading.py430""
  File  in run
 in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py, line Thread 0x"
wait"_recv_bytes  File 10450000fff923fff120/usr/local/python3.11.13/lib/python3.11/threading.py
  File 
, line " in  (most recent call first):
"  File "  File 360/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py_bootstrap_inner  File 
  File , line "/usr/local/python3.11.13/lib/python3.11/threading.py in ""_watchdog_thread", line "1045/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py
/usr/local/python3.11.13/lib/python3.11/threading.py430/usr/local/python3.11.13/lib/python3.11/threading.py in "", line   File "" in _bootstrap_inner, line 
, line 1045231 in _bootstrap_inner", line , line _recv_bytes1002  File  in "
/usr/local/python3.11.13/lib/python3.11/threading.py250/usr/local/python3.11.13/lib/python3.11/threading.py327
 in _feed  File " in " in [2026-01-14 12:10:44 DP28 TP28 EP28] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011

  File _bootstrap
", line , line recvwait"
/usr/local/python3.11.13/lib/python3.11/threading.py  File 
1002
982
/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py  File ""Thread 0x in 0000fff937fff120  File  in ", line /usr/local/python3.11.13/lib/python3.11/threading.py"_bootstrap (most recent call first):
run"
, line 1002"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py  File ""/usr/local/python3.11.13/lib/python3.11/threading.py250 in , line "
", line " in 982_bootstrap, line Thread 0x231 in /usr/local/python3.11.13/lib/python3.11/threading.py_feed822, line recv
 in 0000fff96bfff120"
 in 327
 in 
run (most recent call first):
, line   File _callmethod  File 
wait
Thread 0x  File 1045"/usr/local/python3.11.13/lib/python3.11/threading.py"  File 
  File 0000fff93bfff120" in "/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py, line "  File " (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py  File _bootstrap_inner"982<string>"/usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/threading.py
, line  in "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py", line "  File 822run, line "2, line 327, line " in 
_callmethod, line  in 1045 in 327/usr/local/python3.11.13/lib/python3.11/threading.py  File 
231get in wait in 
"", line   File  in "
_bootstrap_innerwait  File /usr/local/python3.11.13/lib/python3.11/threading.py1002_feed<string>  File 

"  File " in 
""  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py", line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py_bootstrap[2026-01-14 12:10:44 DP18 TP18 EP18] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011

  File , line /usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py""1045"
"2"/usr/local/python3.11.13/lib/python3.11/threading.py, line " in , line 
/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x in , line 231, line  in _bootstrap_inner_feed
231  File "0000fff95bfff120get68 in 1002
 in   File ", line  (most recent call first):

run in _feed"
/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py982  File   File 
_bootstrap  File "" in , line ""  File 
"
, line run1002/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py""/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x"0000fff96bfff120, line 982
 in "/usr/local/python3.11.13/lib/python3.11/threading.py, line  (most recent call first):
982 in  in run  File _bootstrap, line "327, line  in 1045wait in 
_bootstrap_inner68[2026-01-14 12:10:44 DP27 TP27 EP27] Scheduler hit an exception: Traceback (most recent call last):
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2974, in run_scheduler_process
    scheduler.event_loop_overlap_disagg_decode()
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/decode.py", line 872, in event_loop_overlap_disagg_decode
    batch_result = self.run_batch(batch)
                   ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py", line 2241, in run_batch
    batch_result = self.model_worker.forward_batch_generation(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 641, in forward_batch_generation
    batch_output = self.verify(model_worker_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/speculative/eagle_worker_v2.py", line 699, in verify
    forward_batch_output = self.target_worker.forward_batch_generation(
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/tp_worker.py", line 421, in forward_batch_generation
    out = self.model_runner.forward(
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2902, in forward
    output = self._forward_raw(
             ^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/model_executor/model_runner.py", line 2943, in _forward_raw
    ret = self.graph_runner.replay(
          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/hardware_backend/npu/graph_runner/npu_graph_runner.py", line 186, in replay
    seq_lens_cpu = forward_batch.seq_lens.cpu() + self.num_tokens_per_bs
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: ACL stream synchronize failed, error code:507011

  File run
"
  File 
 in "
  File /usr/local/python3.11.13/lib/python3.11/threading.py"
"  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyrun/usr/local/python3.11.13/lib/python3.11/threading.py  File ", line "Thread 0x"
""/usr/local/python3.11.13/lib/python3.11/threading.py1045/usr/local/python3.11.13/lib/python3.11/threading.py in 0000fff92ffff120, line   File 231, line /usr/local/python3.11.13/lib/python3.11/threading.py""_bootstrap_inner (most recent call first):
" in 327", line , line 
  File /usr/local/python3.11.13/lib/python3.11/threading.py in _feed, line 10451002 in   File ""/usr/local/python3.11.13/lib/python3.11/threading.py"wait

1045 in _bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.py", line   File  in   File _bootstrap_inner_bootstrap
", line 10021045""
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
  File , line " in  in /usr/local/python3.11.13/lib/python3.11/threading.py  File "
, line 327/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_bootstrap_inner""Thread 0x2310000fff997fff120 in  in "

, line /usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
wait_feed, line 
  File 982"  File 

1002Thread 0x in " in /usr/local/python3.11.13/lib/python3.11/threading.py, line "  File   File "0000fff94ffff120_bootstraprun"1002/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py (most recent call first):


, line   File  in "/usr/local/python3.11.13/lib/python3.11/threading.py", line   File 
1002" in _bootstrap", line 331"Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap
, line 
231 in /usr/local/python3.11.13/lib/python3.11/threading.pywait0000fff977fff120 (most recent call first):
"
982Thread 0x in "
  File , line 
 in 0000fff947fff120_feed, line 
  File ""1045Thread 0xrun (most recent call first):

327  File /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py in 0000fff9cbfff120  File   File " in ""wait"_bootstrap_inner (most recent call first):
"/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py, line 
, line 
  File /usr/local/python3.11.13/lib/python3.11/threading.py""327, line   File 629  File """, line  in 982wait" in /usr/local/python3.11.13/lib/python3.11/threading.pywait/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/threading.py1045, line  in 
"
""327 in run  File 
  File , line , line , line  in _bootstrap_inner  File "1002"231331wait
 in   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py in  in 
wait""_bootstrap", line , line _feed  File 
/usr/local/python3.11.13/lib/python3.11/threading.py, line 
231
60 in 
"  File "1045 in Thread 0xrun_feed  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py", line  in 0000fff967fff120
 (most recent call first):
"  File 
"/usr/local/python3.11.13/lib/python3.11/threading.py1002"_bootstrap_inner  File /usr/local/python3.11.13/lib/python3.11/threading.py"  File , line  in 231, line 
"  File "/usr/local/python3.11.13/lib/python3.11/threading.py"_bootstrap in 
_feed

629/usr/local/python3.11.13/lib/python3.11/threading.py"", line "/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x  File 0000fff977fff120 in /usr/local/python3.11.13/lib/python3.11/threading.py, line 9821045, line "" (most recent call first):
wait" in  in 327, line /usr/local/python3.11.13/lib/python3.11/threading.py  File "
, line run in _bootstrap_inner982", line /usr/local/python3.11.13/lib/python3.11/threading.py982  File 1002

wait in 
" in , line  in "  File   File run  File run327 in _bootstrap/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py
"""
"
wait  File 
, line /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
"Thread 0x60""", line terminate called after throwing an instance of '  File /usr/local/python3.11.13/lib/python3.11/threading.py0000fff93bfff120 in , line , line /usr/local/python3.11.13/lib/python3.11/threading.py1002c10::Error""" (most recent call first):
run  File 1045231 in '
, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line 
" in  in _bootstrap1045"1045  File /usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner_feed
 in , line  in ""


_bootstrap_inner231_bootstrap_inner

/usr/local/python3.11.13/lib/python3.11/threading.py  File , line   File Thread 0x  File  in terminate called after throwing an instance of '  File """/usr/local/python3.11.13/lib/python3.11/threading.py327"/usr/local/python3.11.13/lib/python3.11/threading.py"0000fffcc4daf120_feedc10::Error, line /usr/local/python3.11.13/lib/python3.11/threading.py" in ", line /usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):

  File '
1045", line wait10021002"  File "" in , line 
1002 in  in , line /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner  File  in _bootstrap_bootstrap982""
"_bootstrap


, line  in   File , line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py982
 in 

run61
 in ""Thread 0x, line Thread 0xrunThread 0x  File _recv_msg"0000fff95bfff120/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
0000fff757fff120231 (most recent call first):
0000fff953fff120

/usr/local/python3.11.13/lib/python3.11/threading.py"  File  in   File  (most recent call first):
  File   File ", line "_feed"
  File "", line 1002/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py  File "/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py1045 in """""" in _bootstrap, line , line 327/usr/local/python3.11.13/lib/python3.11/threading.py, line , line 1045327 in  in _bootstrap_innerwait_bootstrap_inner, line 
395 in "


195
 in wait, line   File   File   File  in Thread 0x_recv
982""/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py_read_thread"terminate called after throwing an instance of '0000fffcf9a4f120
  File  in /usr/local/python3.11.13/lib/python3.11/threading.py"", line , line 2311002 in 
/usr/local/python3.11.13/lib/python3.11/threading.pyc10::Error (most recent call first):
  File "run in _feed  File "'
  File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py

_bootstrap, line ""/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py"  File 
  File 1002/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line ""
  what():  " in LaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:1457, Device:5, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 1457] 2026-01-14-12:10:44.758.379 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffe034348c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffe033dc140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffcd524e210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffcd524eacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffcd51c5a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffcd51554c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffcd5157ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffe0d799024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffe033d7ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffe0dbde314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffe0dbde648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffff90a37400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffff90a374d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaab9ae08b0 in sglang::scheduler_DP21_TP21_EP21)
", line 231/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x"_bootstrap, line , line 
1045, line 430 in _feed"0000fff983fff120982
 in  in 61 in 
Fatal Python error: , line Aborted (most recent call first):

run_bootstrap_inner in _recv_bytes  File 
"982

  File Thread 0x

_recv_msg  File /usr/local/python3.11.13/lib/python3.11/threading.py" in "0000fff973fff120  File Thread 0x  File 
", line /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.pyrun/usr/local/python3.11.13/lib/python3.11/threading.py" (most recent call first):
0000fff777fff120"  File 982" in 
"run  File /usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
  File /usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py", line   what():  250  File , line 
""  File /usr/local/python3.11.13/lib/python3.11/threading.py"""/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.pyLaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:2220, Device:12, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 2220] 2026-01-14-12:10:44.759.147 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffe0fa148c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffe0f9bc140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffce4d4e210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffce4d4eacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffce4cc5a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffce4c554c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffce4c57ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffe19d79024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffe0f9b7ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffe1a1be314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffe1a1be648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffff9d017400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffff9d0174d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaada5e08b0 in sglang::scheduler_DP28_TP28_EP28)

 in "327/usr/local/python3.11.13/lib/python3.11/threading.py in , line "/usr/local/python3.11.13/lib/python3.11/threading.py, line , line Fatal Python error: "Abortedrecv"wait, line 1045"1002923, line  in 


, line 
 in 327, line  in 195heartbeat_checker  File 
1045Thread 0x  File  in _bootstrap_inner1045 in _bootstrap in "  File  in "0000fff73ffff120"wait
_bootstrap_inner

_read_thread/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File   File 

"Thread 0x  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py0000fff947fff120
"
"", line   File "982" in /usr/local/python3.11.13/lib/python3.11/threading.py" (most recent call first):
  File , line "  File , line /usr/local/python3.11.13/lib/python3.11/threading.py"run", line 
  File 822/usr/local/python3.11.13/lib/python3.11/threading.py"terminate called after throwing an instance of '231c10::Error"'
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line   File 1002923 in " in "/usr/local/python3.11.13/lib/python3.11/threading.py in , line "" in _bootstrap/usr/local/python3.11.13/lib/python3.11/threading.pyheartbeat_checker
_callmethod
, line "_feed1002, line /usr/local/python3.11.13/lib/python3.11/threading.py"

Thread 0x9820000fff967fff120, line 
 in 231"  what():  , line , line   File 327  File " in  (most recent call first):
1002  File   File "_bootstrap in LaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:2221, Device:13, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 2221] 2026-01-14-12:10:44.758.879 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffe22a648c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffe22a0c140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffcf524e210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffcf524eacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffcf51c5a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffcf51554c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffcf5157ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffe2cdc9024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffe22a07ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffe2d20e314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffe2d20e648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffffb0067400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffffb00674d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaaae5808b0 in sglang::scheduler_DP29_TP29_EP29)
1045"/usr/local/python3.11.13/lib/python3.11/threading.py<string> in run in "/usr/local/python3.11.13/lib/python3.11/threading.py
_feed" in 
""wait
_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py

_bootstrap_inner, line , line , line 
  File "
/usr/local/python3.11.13/lib/python3.11/threading.py"Fatal Python error:   File Current thread 0x
3279822  File  in 
"Thread 0x, line 0000fff95ffff120Aborted (most recent call first):
0000ffff8434f060"  File  in  in ""runget
  File , line 982

/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
  File Thread 0xwait/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py0000fff76bfff120
 (most recent call first):
"1045/usr/local/python3.11.13/lib/python3.11/threading.py in   File """", line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py
982terminate called after throwing an instance of '""  File   File  in run, line /usr/local/python3.11.13/lib/python3.11/threading.py1045"  File  in c10::Error, line , line , line ""_bootstrap_inner
" in "run'

29811002231/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py
  File , line _bootstrap_inner/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in   File  in  in "", line   File 68327"
"run_scheduler_process"_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py_feed, line " in /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py in "  File , line 

"
923, line run"
wait, line "231  File 
  File Thread 0x in 1045, line   File 1002
1045/usr/local/python3.11.13/lib/python3.11/threading.py in ""0000fff783fff120heartbeat_checker (most recent call first):
 in " in _bootstrap_inner in   File "_feed
/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py/usr/local/python3.11.13/lib/python3.11/threading.py
  File /usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap

"_bootstrap_inner  what():  
, line   File ""  File ", line "982  File 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyLaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:1454, Device:2, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 1454] 2026-01-14-12:10:44.759.607 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffdef9f48c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffdef99c140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffcc4cde210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffcc4cdeacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffcc4c55a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffcc4be54c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffcc4be7ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffdf9d59024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffdef997ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffdfa19e314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffdfa19e648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffff7cff7400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffff7cff74d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaae7fe08b0 in sglang::scheduler_DP18_TP18_EP18)
  File 1002"", line "/usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py, line  in "Current thread 0x"
 in /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py108/usr/local/python3.11.13/lib/python3.11/threading.py"1045run/usr/local/python3.11.13/lib/python3.11/threading.py0000ffffb8fd8060, line _bootstrap"" in "runFatal Python error:  in , line 
" (most recent call first):
, line 231
, line , line , line 
982Aborted_bootstrap_inner799 in   File   File 1002 in  in 
1002982  File  in 


recv_multipart"
  File "_feed_bootstrapThread 0x in 0000fff74bfff120 in "run  File Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py0000fff763fff120"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py

_bootstrap
 (most recent call first):
run/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py
"" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py""  File 
Thread 0x  File 
""  File /usr/local/python3.11.13/lib/python3.11/threading.py, line , line   File , line ", line 
0000fff97ffff120  File /usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py"314" in 1045"893/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py/usr/local/python3.11.13/lib/python3.11/threading.py2981Thread 0x (most recent call first):
""  File /usr/local/python3.11.13/lib/python3.11/threading.py, line "", line _bootstrap in 
 in   File "  what():  " in 0000fff98ffff120/usr/local/python3.11.13/lib/python3.11/threading.py799/usr/local/python3.11.13/lib/python3.11/threading.py, line "1002_bootstrap_innerdecode_thread", line LaunchRecordTask:build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 NPU function error: aclrtRecordEvent(eventParam_.event, npuStream), error code is 507011
[ERROR] 2026-01-14-12:10:44 (PID:1463, Device:11, RankID:-1) ERR00100 PTA call acl api failed
[Error]: Model execution failed. 
        Rectify the fault based on the error information in the ascend log.
EE9999: Inner Error!
EE9999[PID: 1463] 2026-01-14-12:10:44.759.868 (EE9999):  Failed to submit record task, retCode=0x7150050.[FUNC:Record][FILE:event.cc][LINE:425]
        TraceBack (most recent call last):
       rtEventRecord execute failed, reason=[the model stream execute failed][FUNC:FuncErrorReason][FILE:error_message_manage.cc][LINE:53]
       record event failed, runtime result = 507011[FUNC:ReportCallError][FILE:log_inner.cpp][LINE:162]

Exception raised from LaunchRecordTask at build/CMakeFiles/torch_npu.dir/compiler_depend.ts:204 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xfffe014e48c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xfffe0148c140 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #2: <unknown function> + 0xa9e210 (0xfffcd524e210 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #3: <unknown function> + 0xa9eacc (0xfffcd524eacc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #4: c10_npu::NPUEvent::record(c10_npu::NPUStream const&) + 0xa0 (0xfffcd51c5a34 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #5: <unknown function> + 0x9a54c0 (0xfffcd51554c0 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #6: <unknown function> + 0x9a7ccc (0xfffcd5157ccc in /usr/local/python3.11.13/lib/python3.11/site-packages/torch_npu/lib/libtorch_npu.so)
frame #7: <unknown function> + 0x599024 (0xfffe0b849024 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x14 (0xfffe01487ee4 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x9de314 (0xfffe0bc8e314 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
frame #10: <unknown function> + 0x9de648 (0xfffe0bc8e648 in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #30: <unknown function> + 0x27400 (0xffff8eae7400 in /lib/aarch64-linux-gnu/libc.so.6)
frame #31: __libc_start_main + 0x98 (0xffff8eae74d8 in /lib/aarch64-linux-gnu/libc.so.6)
frame #32: _start + 0x30 (0xaaaacace08b0 in sglang::scheduler_DP27_TP27_EP27)
, line run_scheduler_process982 (most recent call first):
" in 1045, line  in 
_bootstrap
/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py923

 in   File , line recv_multipart in 1045327  File 
 in   File "" in   File run"_bootstrap_inner
 in Fatal Python error: "_bootstrap_inner
wait, line Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py"heartbeat_checker/usr/local/python3.11.13/lib/python3.11/threading.py

  File Aborted/usr/local/python3.11.13/lib/python3.11/threading.py

1350000fff98ffff120" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py
"  File "  File   File "

"  File   File  in , line   File 982, line "108/usr/local/python3.11.13/lib/python3.11/threading.py in "run, line 
982  File  in ", line "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py", line Thread 0x"0000fff78bfff120"_main" in /usr/local/python3.11.13/lib/python3.11/threading.pyrun/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py""/usr/local/python3.11.13/lib/python3.11/threading.py327, line  in "/usr/local/python3.11.13/lib/python3.11/threading.py1002/usr/local/python3.11.13/lib/python3.11/threading.py in  (most recent call first):
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
run

, line "314wait", line "  File _bootstrap  File "  File   File 331, line  in 
893, line  in , line 
"", line "" in /usr/local/python3.11.13/lib/python3.11/threading.py1045_bootstrap in   File _bootstrap_inner1002decode_thread1002
/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py231/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py/usr/local/python3.11.13/lib/python3.11/threading.pywait"
"
 in 
 in Thread 0x in """
, line   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File _bootstrap  File _bootstrap0000fff953fff120_feed, line , line , line   File 1045 in """
"
 (most recent call first):
122
923  File  in heartbeat_checker
1045"_bootstrap_inner
/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py/usr/local/python3.11.13/lib/python3.11/threading.py, line "
/usr/local/python3.11.13/lib/python3.11/threading.py
  File  in "  File spawn_main in /usr/local/python3.11.13/lib/python3.11/threading.py  File "231, line Thread 0x"Thread 0x"/usr/local/python3.11.13/lib/python3.11/threading.py"
_bootstrap_inner"", line , line 1002 in , line 0000fff777fff1200000fff973fff120/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py  File "
/usr/local/python3.11.13/lib/python3.11/threading.py629135 in _feed982 (most recent call first):
 (most recent call first):
", line ", line   File 982" in  in  in _bootstrap

  File 
 in   File   File , line <string>982", line runwait
_main"Thread 0x"run"/usr/local/python3.11.13/lib/python3.11/threading.py327 in " in , line /usr/local/python3.11.13/lib/python3.11/threading.py1002
  File 
/usr/local/python3.11.13/lib/python3.11/threading.py0000fff96bfff120
/usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py"", line runwait1
" in   File ""  File /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py" (most recent call first):
  File , line "799327
 in   File , line _bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py"", line   File /usr/local/python3.11.13/lib/python3.11/threading.py in  in   File <module>"1002
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py, line 98260" in recv_multipart"
wait"
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in 
, line " in /usr/local/python3.11.13/lib/python3.11/threading.pyrun  File , line 
/usr/local/python3.11.13/lib/python3.11/threading.py"_bootstrapThread 0x1045, line run"
1045"  File ", line 
0000fff7d7fff120 in  (most recent call first):
122, line 
327  File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py in ", line 231
_bootstrap_innerThread 0x  File  in  in   File ""_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py1045 in 
0000fff77bfff120"spawn_mainwait"/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py, line 
" in _feed  File  (most recent call first):
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py
"
"  File "", line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py893  File , line _bootstrap_inner
"  File   File , line , line "1045 in "
Extension modules: 231
 in /usr/local/python3.11.13/lib/python3.11/threading.py  File """"3751045, line  in  in _bootstrap_innerdecode_thread
/usr/local/python3.11.13/lib/python3.11/threading.pynumpy._core._multiarray_umath  File _feed, line /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py<string> in 231_bootstrap_inner
  File ""
1002"""_watchdog_once in 
_feed  File ,   File ", line /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py"  File  in , line , line , line 

"numpy.linalg._umath_linalg"1002", line "_bootstrap982 in 1799  File   File /usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/threading.py in ", line 1002/usr/local/python3.11.13/lib/python3.11/threading.py
run in  in <module>"/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py_bootstrap, line 1002 in "

recv_multipart

", line , "
982 in _bootstrap, line 
Thread 0x  File 0000fff7a3fff120"  File , line 1002pybase64._pybase64, line 
 in Thread 0x_bootstrap982
 (most recent call first):
Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py"982 in 360run0000fff757fff120
 (most recent call first):

  File  in ,   File 0000fffcbdedf120"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py in _bootstrap in   File 
""/usr/local/python3.11.13/lib/python3.11/threading.pyruncharset_normalizer.md
"  File  (most recent call first):
, line "run


  File Thread 0x_watchdog_threadThread 0x/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py"/usr/local/python3.11.13/lib/python3.11/site-packages/zmq/sugar/socket.py, line 
Extension modules: "  File 1045, , line "0000fff76ffff120893
 in 0000fff98bfff120""1045numpy._core._multiarray_umath/usr/local/python3.11.13/lib/python3.11/threading.py" in requests.packages.charset_normalizer.md (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py  File decode_thread (most recent call first):
, line , line  in 375799 in "/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py_bootstrap_inner,   File ", "
  File _bootstrap_inner in _watchdog_once, line "
numpy.linalg._umath_linalg  File ", line requests.packages.chardet.md1045/usr/local/python3.11.13/lib/python3.11/threading.py  File ""
recv_multipart

1045, line "61/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py in  in "_bootstrap_inner, line /usr/local/python3.11.13/lib/python3.11/threading.py  File   File   File " in /usr/local/python3.11.13/lib/python3.11/threading.py"_recv_msg
/usr/local/python3.11.13/lib/python3.11/threading.py
982", ""/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py_bootstrap_inner"", line   File 395"  File  in , line pybase64._pybase64/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/disaggregation/mooncake/conn.py
,   File , line , line " in , line , "run327
"", line multidict._multidict"3601002/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py_recv, 982charset_normalizer.md in /usr/local/python3.11.13/lib/python3.11/threading.py in   File , requests.packages.charset_normalizer.md, line 1002/usr/local/python3.11.13/lib/python3.11/threading.py in ,  in "
yarl._quoting_crun"wait"893 in "_watchdog_thread, line requests.packages.chardet.md_bootstrap, line 
  File 
, line   File , 
/usr/local/python3.11.13/lib/python3.11/threading.py in _bootstrap
1002195
"1002"propcache._helpers_c  File /usr/local/python3.11.13/lib/python3.11/threading.py""decode_thread  File 
 in  in _bootstrapThread 0x_read_thread/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py in "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line ", 

"
0000fff95ffff120
 (most recent call first):
"_bootstrap, line 1045, line aiohttp._http_writer  File , /usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x
  File Thread 0x  File 
, line 1045 in 231" in , multidict._multidictaiohttp._http_parser0000fff78ffff120""0000fff97ffff120"430
 in _bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.py_feed (most recent call first):
, line , , /usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
  File /usr/local/python3.11.13/lib/python3.11/threading.py in Thread 0x_bootstrap_inner
"
982  File aiohttp._websocket.mask"yarl._quoting_c"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py"/usr/local/python3.11.13/lib/python3.11/threading.py"0000fff977fff120_recv_bytes
  File , line   File  in , , line ", ", line , line  (most recent call first):

  File   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py", line 250 in recv
  File "982/usr/local/python3.11.13/lib/python3.11/threading.py"runaiohttp._websocket.reader_c982, line propcache._helpers_c in run327327"  File " in "/usr/local/python3.11.13/lib/python3.11/threading.py
375, 
  File  in ,  in /usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.pyrun, line "  File  in "_watchdog_oncefrozenlist._frozenlist"waitaiohttp._http_writerwait"/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py
"
1002, line 
/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py
, , line ",   File aiohttp._http_parser, line   File  in 982"  File , line "1045"  File torch._C327, line "1002", _bootstrap in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py in , line "1045 in 822, /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in "/usr/local/python3.11.13/lib/python3.11/threading.pyaiohttp._websocket.mask
run"_bootstrap_inner, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in wait in torch._C._dynamo.autograd_compiler_bootstrap, line ", 

, 
360"_bootstrap_inner, line 
_callmethod
231, line torch._C._dynamo.eval_frameThread 0x  File aiohttp._websocket.reader_c in   File 231

  File 
 in 10450000fff937fff120 in ", "_watchdog_thread in /usr/local/python3.11.13/lib/python3.11/threading.py  File _feed  File ", Thread 0x_feed (most recent call first):
_bootstrap_innertorch._C._dynamo.guards/usr/local/python3.11.13/lib/python3.11/threading.py
""
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyfrozenlist._frozenlist0000fff78ffff120
  File 
"  File , line , /usr/local/python3.11.13/lib/python3.11/threading.py  File <string>" (most recent call first):
  File "  File , , line "1002torch._C._dynamo.utils"", line ", line /usr/local/python3.11.13/lib/python3.11/threading.py  File ""torch._C1045/usr/local/python3.11.13/lib/python3.11/threading.py in /usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap1002, , line 231""/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py in , ""
 in torch._C._fft in 2, line /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py""_bootstrap_innertorch._C._dynamo.autograd_compiler, line 
982, line 
_bootstrap_feed in 327, "torch._C._linalg, line , line   File  in 982, 
Thread 0x
get in , line 9821002, "run in torch._C._dynamo.eval_frame
0000fff94ffff120
  File wait375 in  in torch._C._nested/usr/local/python3.11.13/lib/python3.11/threading.py
runCurrent thread 0x (most recent call first):
,   File "
 in run_bootstrap"
  File 
, 0000ffff7d3dc060  File  (most recent call first):
torch._C._dynamo.guards"/usr/local/python3.11.13/lib/python3.11/threading.py  File _watchdog_once
  File , line 
"  File torch._C._nn"  File "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py, line , "
"1002Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py", "982torch._C._dynamo.utils/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File /usr/local/python3.11.13/lib/python3.11/threading.py in , "0000fff7c7fff120"/usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.pytorch._C._sparse, line  in ""_bootstrap/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.pytorch._C._fft", line  (most recent call first):
, line , line , line 1045" in 68run in 
, , line 
, line 1045360,   File 1045327"_bootstrap_inner, line   File runtorch._C._special231
 in  in torch._C._linalg in  in 
/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py2981"
" in Thread 0x_bootstrap_inner_watchdog_threadwait_bootstrap_inner,   File  in ", line run_scheduler_process  File /usr/local/python3.11.13/lib/python3.11/threading.py_feed0000fff997fff120



torch._C._nested375/usr/local/python3.11.13/lib/python3.11/threading.py
""
 (most recent call first):
  File   File   File   File  in ""  File , , line /usr/local/python3.11.13/lib/python3.11/threading.py  File   File ""/usr/local/python3.11.13/lib/python3.11/threading.py"_watchdog_once/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line "torch._C._nn1045"""/usr/local/python3.11.13/lib/python3.11/threading.py"
""  File 1002/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py in , line , /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py"", line , line , line " in "1045_bootstrap_inner, line torch._C._sparse", line , line 1002, 1002231 in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler_runtime_checker_mixin.py_bootstrap
 in 108, , line 982982 in numpy.random._common_bootstrap in "
  File _bootstrap_inner in torch._C._special327 in  in run_bootstrap_feed
, line 
360, "
run in 
waitrun



Thread 0x in 0000fff96bfff120numpy.random.bit_generator  File /usr/local/python3.11.13/lib/python3.11/threading.py  File 

  File 
  File Thread 0x_watchdog_thread (most recent call first):
""/usr/local/python3.11.13/lib/python3.11/threading.py,   File "  File "Thread 0x0000fff957fff120" (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py  File 
  File , line "numpy.random._bounded_integers"/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py""/usr/local/python3.11.13/lib/python3.11/threading.py0000fff98bfff120, line "", line   File ""/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py, line 1002/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py", /usr/local/python3.11.13/lib/python3.11/threading.py" (most recent call first):
314/usr/local/python3.11.13/lib/python3.11/threading.py982 in "", line 1002 in , line numpy.random._pcg64", , line   File " in _bootstrap, line 982327 in  in  in _bootstrap231, line numpy.random._common, "1045, line run327

waitrun  File 
_bootstrap in 1045numpy.random._generator in  in /usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner,  in   File 

"

_feed_bootstrap_inner"
, numpy.random.bit_generator
numpy.random._mt19937  File wait"  File   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py
Thread 0x
, line   File 327", 
/usr/local/python3.11.13/lib/python3.11/threading.py, """Thread 0x0000fff983fff120 (most recent call first):
  File  in "wait/usr/local/python3.11.13/lib/python3.11/threading.pynumpy.random._bounded_integers"  File "numpy.random._philox/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py0000fff9a7fff120, line   File  (most recent call first):
"135/usr/local/python3.11.13/lib/python3.11/threading.py
, line ", , line "", "  File /usr/local/python3.11.13/lib/python3.11/threading.py in "  File 1002/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pynumpy.random._pcg641045", line , line numpy.random._sfc64, /usr/local/python3.11.13/lib/python3.11/threading.py""_main, line "
 in  in , line 1045231numpy.random._generator"/usr/local/python3.11.13/lib/python3.11/threading.py, , line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py1002  File _bootstrap_bootstrap_inner231 in  in ", line 982numpy.random.mtrand, " in "

 in   File _feed_feed_bootstrap_inner, line 327 in runnumpy.random._mt19937, line _bootstrap/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py, 
"
/usr/local/python3.11.13/lib/python3.11/threading.py

  File 331 in 

231, "aclThread 0x  File ""  File  in wait
  File 
 in numpy.random._philox, line 0000fff92ffff120", line /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py", wait  File "Thread 0x_feed122 (most recent call first):
, 1002""/usr/local/python3.11.13/lib/python3.11/threading.py, line torch_npu._C
"/usr/local/python3.11.13/lib/python3.11/threading.py
0000fff943fff120 in   File numpy.random._sfc64spawn_main in , line "982, line   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"  File  (most recent call first):
""
, _bootstrap  File numpy.random.mtrand9821002 in run"", line   File , /usr/local/python3.11.13/lib/python3.11/threading.pyacl/usr/local/python3.11.13/lib/python3.11/threading.py"
, line " in  in 
, line /usr/local/python3.11.13/lib/python3.11/threading.py1045"", 
982<string>run_bootstrap  File 
231" in /usr/local/python3.11.13/lib/python3.11/threading.py, line markupsafe._speedupsThread 0x,  in "

, line " in , line _bootstrap_inner"3270000fff95bfff120torch_npu._Crun  File Thread 0x1/usr/local/python3.11.13/lib/python3.11/threading.py_feed629, 
, line 327 in  (most recent call first):

wait"0000fff93ffff120 in " in 
  File yaml._yaml in   File   File 
/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
<module>, line   File wait"wait"/usr/local/python3.11.13/lib/python3.11/threading.py"  File "  File 
"1045/usr/local/python3.11.13/lib/python3.11/threading.py in ""
, 
/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.py", ", line _bootstrap_inner, line /usr/local/python3.11.13/lib/python3.11/threading.py  File markupsafe._speedups  File ", line , line 1045/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pypsutil._psutil_linux1045
327, "", line /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py982"", line 1002 in " in  in   File , yaml._yaml in , line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py327 in _bootstrap_inner, line _bootstrap_inner"wait/usr/local/python3.11.13/lib/python3.11/threading.pyzmq.backend.cython._zmqrun60" in _bootstrap
231

"
 in , line wait
  File ,  in 
Extension modules:   File ,   File , line   File run231

"Thread 0xpsutil._psutil_linux_feednumpy._core._multiarray_umath"PIL._imaging1002"
" in   File /usr/local/python3.11.13/lib/python3.11/threading.py0000fff9a3fff120
 (most recent call first):
  File /usr/local/python3.11.13/lib/python3.11/threading.py  File ,  in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py_bootstrap"
, line   File /usr/local/python3.11.13/lib/python3.11/threading.py_feed", """"zmq.backend.cython._zmq/usr/local/python3.11.13/lib/python3.11/threading.py
231""
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pynumpy.linalg._umath_linalg, line , /usr/local/python3.11.13/lib/python3.11/threading.py, line Thread 0x1002 in "/usr/local/python3.11.13/lib/python3.11/threading.py, line   File "1002sentencepiece._sentencepiece, "0000fff977fff120 in _feed, line , 327"1045", line /usr/local/python3.11.13/lib/python3.11/threading.py in PIL._imaging, line  (most recent call first):
_bootstrap
regex._regex in , line  in , 231_bootstrap"982  File 
  File wait
1045_bootstrap_innerpybase64._pybase64 in 
, line 
 in ", 
"  File 
 in "_feed982Thread 0x in run/usr/local/python3.11.13/lib/python3.11/threading.pynpu_utils, , Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.py  File _bootstrap_inner/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
0000fff997fff120run
"charset_normalizer.mdsentencepiece._sentencepiece0000fff963fff120", 
"  File "  File  (most recent call first):

  File , line  (most recent call first):
, line PIL._imagingft982, /usr/local/python3.11.13/lib/python3.11/threading.py", , line "231  File /usr/local/python3.11.13/lib/python3.11/threading.py  File "327  File  in requests.packages.charset_normalizer.md"/usr/local/python3.11.13/lib/python3.11/threading.pyregex._regex in ""/usr/local/python3.11.13/lib/python3.11/threading.py"", /usr/local/python3.11.13/lib/python3.11/threading.py in "waitrun", line , _feed, line /usr/local/python3.11.13/lib/python3.11/threading.py, line _cffi_backend, "/usr/local/python3.11.13/lib/python3.11/threading.py

, line 1002requests.packages.chardet.md
982  File "327npu_utils, line "  File   File , line 1002 in ,  in "run, line  in 1045""327 in , _bootstrapcython.cimports.libc.math/usr/local/python3.11.13/lib/python3.11/threading.py
1045wait in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/threading.py" in , wait_bootstrapPIL._imagingft
"  File 
 in , "_bootstrap_inner, line multidict._multidict231


, line "_bootstrap_inner  File scipy._lib._ccallback_c, line 
,  in   File 
Thread 0x, 982/usr/local/python3.11.13/lib/python3.11/threading.py
"1045  File _cffi_backend, _feedscipy.linalg._fblas
"Thread 0x0000fff98ffff120yarl._quoting_c in "  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in ", /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py",   File 0000fffcd39ff120 (most recent call first):
run, line 
", "_bootstrap_inner
cython.cimports.libc.math", line 1002scipy.linalg._flapack"  File  (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py1045  File   File  in /usr/local/python3.11.13/lib/python3.11/threading.pypropcache._helpers_c", line   File , line ,  in _bootstrap", /usr/local/python3.11.13/lib/python3.11/threading.py"""_bootstrap_inner, line 2311002 in  in "231, scipy._lib._ccallback_c
scipy.linalg.cython_lapack
", line /usr/local/python3.11.13/lib/python3.11/threading.py982/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py in 
_bootstrap_feed/usr/local/python3.11.13/lib/python3.11/threading.py in aiohttp._http_writer, Thread 0x, , line ""run  File 

_feed"
scipy.linalg._fblas0000fff93bfff120scipy.linalg._cythonized_array_utils, 327, line , line 
"
  File , line   File 1002 (most recent call first):
, aiohttp._http_parser in 1045, 61, /usr/local/python3.11.13/lib/python3.11/threading.py  File Thread 0x"" in   File scipy.linalg._flapack"wait in scipy.linalg._solve_toeplitz_bootstrap_inner in aiohttp._websocket.mask_recv_msg""0000fff94ffff120/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py, "

, 
  File , , line /usr/local/python3.11.13/lib/python3.11/threading.py" (most recent call first):
, line "
scipy.linalg.cython_lapack, line   File scipy.linalg._decomp_lu_cython  File , "aiohttp._websocket.reader_c1002" in 982  File  in "run, line 
327""scipy.linalg._cythonized_array_utils/usr/local/python3.11.13/lib/python3.11/threading.py, /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py, line _bootstrap, /usr/local/python3.11.13/lib/python3.11/threading.py
982Thread 0x in  in /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyscipy.linalg._matfuncs_sqrtm_triu"", 1045
frozenlist._frozenlist  File "0000fff94bfff120runwait", , line , line , scipy.linalg._solve_toeplitz in 
_bootstrap_inner", line  (most recent call first):


, line torch._C1002195scipy.linalg._matfuncs_expm, Thread 0x, 0000fff967fff120
/usr/local/python3.11.13/lib/python3.11/threading.py327  File   File   File "231 in  in torch._C._dynamo.autograd_compiler, scipy.linalg._decomp_lu_cython (most recent call first):
  File  in """/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py in _bootstrap_read_thread, scipy.linalg._linalg_pythran  File ", /usr/local/python3.11.13/lib/python3.11/threading.pywait, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py""_feed


torch._C._dynamo.eval_frame", scipy.linalg._matfuncs_sqrtm_triu"
1045  File "", line , line 
  File Thread 0x/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.linalg.cython_blas, , line torch._C._dynamo.guards,  in , line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py327 in 1045  File "0000fff9affff120"1002 (most recent call first):
, scipy.linalg._matfuncs_expm, _bootstrap_innertorch._C._dynamo.utils231, "wait in /usr/local/python3.11.13/lib/python3.11/threading.py""/usr/local/python3.11.13/lib/python3.11/threading.py, line  in   File scipy.linalg._decomp_update
scipy.linalg._linalg_pythran in , 
, line 231_bootstrap_inner, line "327_bootstrap"  File , _feed, torch._C._fft  File  in 
982, line  in 
/usr/local/python3.11.13/lib/python3.11/threading.py"scipy.sparse._sparsetools/usr/local/python3.11.13/lib/python3.11/threading.py
scipy.linalg.cython_blas"_feed,   File ,  in 982runwait
"", line   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
, torch._C._linalg"scipy.linalg._decomp_update in 
run
Thread 0x, line 327""  File _csparsetools"/usr/local/python3.11.13/lib/python3.11/threading.py,   File 
,   File 0000fff71bfff120"1002 in /usr/local/python3.11.13/lib/python3.11/threading.py, line /usr/local/python3.11.13/lib/python3.11/threading.py231""", torch._C._nested  File scipy.sparse._sparsetools (most recent call first):
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in wait", line  in , line 982 in /usr/local/python3.11.13/lib/python3.11/threading.pyscipy.sparse._csparsetools",   File "_bootstrap, 
, line 1002_feedrun
"/usr/local/python3.11.13/lib/python3.11/threading.pytorch._C._nn", line , , 
_csparsetools
  File 982" in  in 
  File , line ""/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py231"scipy.sparse.linalg._dsolve._superlutorch._C._sparseThread 0x, /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyrun_bootstrap  File 1045, line /usr/local/python3.11.13/lib/python3.11/threading.py in , line 0000fff913fff120395, , scipy.sparse._csparsetools"

"1045 in "_feed (most recent call first):
 in scipy.sparse.linalg._eigen.arpack._arpacktorch._C._special, line   File 
/usr/local/python3.11.13/lib/python3.11/threading.py,  in _bootstrap_inner, line 
  File _recv231, "scipy.sparse.linalg._propack._spropackThread 0x"scipy.sparse.linalg._dsolve._superlu
_bootstrap_inner1045  File "
 in /usr/local/python3.11.13/lib/python3.11/threading.py0000fff96ffff120, line ,   File 
 in ", /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py  File "_feed" (most recent call first):
982scipy.sparse.linalg._propack._dpropack"  File /usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_innerscipy.sparse.linalg._eigen.arpack._arpack
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py
, line   File  in   File run"/usr/local/python3.11.13/lib/python3.11/threading.py", "  File , line ", "1045, line "
/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.sparse.linalg._propack._cpropack, line /usr/local/python3.11.13/lib/python3.11/threading.py395982scipy.sparse.linalg._propack._spropack,  in 430/usr/local/python3.11.13/lib/python3.11/threading.py  File ", line " in ",  in numpy.random._common_bootstrap_inner,  in "", , line numpy.random.bit_generator, line 1002, line _recvscipy.sparse.linalg._propack._zpropackrun
scipy.sparse.linalg._propack._dpropack  File _recv_bytes, line /usr/local/python3.11.13/lib/python3.11/threading.py982327 in 1002, 
1002  File 
"  File 
, , " in  in _bootstrap in numpy.random._bounded_integers in "_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py"  File scipy.sparse.csgraph._tools"scipy.sparse.linalg._propack._cpropack, line run, 
wait
_bootstrap
/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py
", /usr/local/python3.11.13/lib/python3.11/threading.pynumpy.random._pcg64/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py1045,   File scipy.sparse.csgraph._shortest_path"

  File , "
, line " in ", scipy.sparse.linalg._propack._zpropack/usr/local/python3.11.13/lib/python3.11/threading.py
Current thread 0xThread 0x"scipy.sparse.csgraph._traversal, line Thread 0x1002, , line _bootstrap_inner, line numpy.random._generator"0000ffff92f08060, 0000fff99bfff120/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py4300000fff967fff120 in  (most recent call first):
 in scipy.sparse.csgraph._min_spanning_tree1045250
, line ,   File  (most recent call first):
numpy.random._mt19937scipy.sparse.csgraph._tools (most recent call first):
"_recv_bytes  File , _bootstrap in ,  in 1045"  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py"/usr/local/python3.11.13/lib/python3.11/threading.py,   File , line "
231scipy.sparse.csgraph._shortest_path
 in 
_bootstrap_innerscipy.sparse.csgraph._flowrecv in , line , "numpy.random._philox"  File /usr/local/python3.11.13/lib/python3.11/threading.py", _feedThread 0x, 


_bootstrap_inner2981scipy.sparse.csgraph._matching, line "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.pynumpy.random._sfc64, "0000fff947fff120scipy.sparse.csgraph._traversalscipy.sparse.csgraph._reordering  File   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py"  File 
 in 1002, line , line  (most recent call first):
, , "scipy.sparse.csgraph._min_spanning_tree, "/usr/local/python3.11.13/lib/python3.11/threading.py, line ""  File run_scheduler_process in 327395  File numpy.random.mtrand/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.optimize._group_columns, 250/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py", 
acl_bootstrap in  in , line ""scipy.sparse.csgraph._flow in , "/usr/local/python3.11.13/lib/python3.11/threading.py  File 
wait_recv982
/usr/local/python3.11.13/lib/python3.11/threading.py, line recv1002scipy._lib.messagestream, "scipy.sparse.csgraph._matching, line , "822

Thread 0x, 0000fff957fff120 in   File run"
 in , line , scipy.optimize._trlib._trlib/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py in   File _callmethodtorch_npu._C (most recent call first):
"
, line   File 327_bootstrap1002 in scipy.sparse.csgraph._reordering", "
  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py  File " in 
_bootstrapwait
, line , /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyscipy.optimize._lbfgsb  File """/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py, 

  File 108scipy.optimize._group_columns""/usr/local/python3.11.13/lib/python3.11/threading.py, line ", 430, line /usr/local/python3.11.13/lib/python3.11/threading.py"markupsafe._speedupsThread 0x
"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in , line run<string>, 
_moduleTNC in   File 327", , line 0000fff973fff120Thread 0x0000fff88ffff120", 231yaml._yaml"scipy._lib.messagestream_recv_bytes" in , line /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.pyscipy.optimize._moduleTNC822 (most recent call first):
 (most recent call first):
  File , , line  in , line , 
scipy.optimize._trlib._trlibwait  File 1045" in  in ,   File "/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.pypsutil._psutil_linux2312 in _feed
_feed", , line _callmethod/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.pyscipy.optimize._lbfgsb_bootstrap_innerscipy.optimize._cobyla""",  in , getzmq.backend.cython._zmq
  File 
314  File 
"
, , /usr/local/python3.11.13/lib/python3.11/threading.py, line , line scipy.optimize._slsqp
  File "" in   File _bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py  File PIL._imaging_moduleTNC"250395  File , /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/threading.py""
, line "", line , /usr/local/python3.11.13/lib/python3.11/threading.py in scipy.optimize._moduleTNC in "scipy.optimize._minpack"<string>  File 982, line 327982, "recv, _recv
scipy.optimize._cobyla/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py
, line ", " in  in  in sentencepiece._sentencepiece, line   File ",   File 231, line scipy.optimize._lsq.givens_elimination2run/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.pywaitrun1002", line , scipy.optimize._slsqpregex._regex" in  in 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py, "

 in /usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py68, _feedget  File "
, scipy.optimize._zeros, line 135  File   File _bootstrap"" in scipy.optimize._minpack
run", line npu_utils  File ,  in "/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
", line /usr/local/python3.11.13/lib/python3.11/threading.py  File 
", /usr/local/python3.11.13/lib/python3.11/threading.py430""scipy.optimize._cython_nnls, line _main, PIL._imagingft
, line 822"  File /usr/local/python3.11.13/lib/python3.11/threading.pyscipy.optimize._lsq.givens_elimination in /usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py1045, 
_cffi_backend, Thread 0x231 in , line , """_recv_bytes,  in   File scipy._lib._uarray._uarray0000fff97bfff120 in _callmethod
1045cython.cimports.libc.math/usr/local/python3.11.13/lib/python3.11/threading.py, line ", line 
scipy.optimize._zeros_bootstrap_inner" (most recent call first):
_feed,   File  in 982, line , 68scipy._lib._ccallback_c  File 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py", /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py  File 
scipy.special._ufuncs_cxx"_bootstrap_inner in 1045 in   File , "scipy.optimize._cython_nnls""  File <string>, 
run in run"scipy.linalg._fblas, line , line /usr/local/python3.11.13/lib/python3.11/threading.py", "scipy.special._ufuncs  File 
_bootstrap_inner
/usr/local/python3.11.13/lib/python3.11/threading.py122, 250scipy.linalg._flapack"/usr/local/python3.11.13/lib/python3.11/threading.pyscipy._lib._uarray._uarray, line "  File , "
  File /usr/local/python3.11.13/lib/python3.11/threading.py", line  in  in ", line , 2, /usr/local/python3.11.13/lib/python3.11/threading.pyscipy.special._specfun  File ""/usr/local/python3.11.13/lib/python3.11/threading.py1002"spawn_mainrecv, line 327scipy.linalg.cython_lapack in "scipy.special._ufuncs_cxx", , line  in , line 

982 in get, , line /usr/local/python3.11.13/lib/python3.11/threading.py, scipy.special._comb_bootstrap10451045
  File   File  in wait

scipy.linalg._cythonized_array_utils1002"scipy.special._ufuncs in  in 
_bootstrap_inner, 
""  File <string>run  File   File " in , line _bootstrap_inner, , Thread 0xscipy.special._ellip_harm_2/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py"0000fff973fff120
"", line _bootstrap11002
scipy.linalg._solve_toeplitzscipy.special._specfun  File ", /usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
"  File /usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
 in  in ", , line ,   File scipy.linalg._decomp_interpolative, line """"
<module>_bootstrapThread 0x/usr/local/python3.11.13/lib/python3.11/threading.py
scipy.linalg._decomp_lu_cython822scipy.special._comb1002, , /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py, line , line 
0000fff953fff120"
 in  in scipy.linalg._matfuncs_sqrtm_triu, scipy.optimize._bglu_dense""68231 (most recent call first):
 in , line Thread 0x_feed
_callmethod_bootstrapscipy.special._ellip_harm_2, , line , line ,  in   File 10020000fff98ffff120  File 

scipy.linalg._matfuncs_expm1045, 327scipy.optimize._lsap in run" in  (most recent call first):
"  File 
 in , scipy.linalg._decomp_interpolativewait, 

/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap  File /usr/local/python3.11.13/lib/python3.11/threading.py"
Extension modules: "numpy._core._multiarray_umathThread 0x_bootstrap_innerscipy.linalg._linalg_pythran, scipy.spatial._ckdtree  File   File "
"/usr/local/python3.11.13/lib/python3.11/threading.py<string>0000fff9a3fff120
, scipy.optimize._bglu_dense, ""scipy.linalg.cython_blas, , 
, line , line "" (most recent call first):
, line   File numpy.linalg._umath_linalg/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyscipy.optimize._lsap"scipy.spatial._qhull, Thread 0x327982, line   File 2"", line , 0000fff963fff120scipy.linalg._decomp_update (most recent call first):
,  in  in 331" in /usr/local/python3.11.13/lib/python3.11/threading.py, , line 231scipy.spatial._ckdtree1045 in   File scipy.spatial._voronoiwait, run in /usr/local/python3.11.13/lib/python3.11/threading.pyget"pybase64._pybase64 in , "_feed
scipy.sparse._sparsetools, 
wait"
, , line _bootstrap_inner, scipy.spatial._qhull/usr/local/python3.11.13/lib/python3.11/threading.py
  File scipy.spatial._distance_wrap  File 
, line   File 331_csparsetools1002
charset_normalizer.md  File "  File , ""/usr/local/python3.11.13/lib/python3.11/threading.py",   File " in  in , , scipy.sparse._csparsetoolsrequests.packages.charset_normalizer.md", line , scipy.spatial._voronoi/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyrequests.packages.chardet.md"scipy.spatial._hausdorff/usr/local/python3.11.13/lib/python3.11/threading.py"/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.pywait"_bootstrap, , line /usr/local/python3.11.13/lib/python3.11/threading.py327, ", line , /usr/local/python3.11.13/lib/python3.11/threading.pyscipy.spatial.transform._rotation"

scipy.sparse.linalg._dsolve._superlu1045" in scipy.spatial._distance_wrap, line 982", line , , 68  File scipy.optimize._direct
 in , , line wait231 in ,  in , line multidict._multidict in ", runThread 0x_bootstrap_innerscipy.sparse.linalg._eigen.arpack._arpack1002
_feedscipy.spatial._hausdorffrun  File 629 in , setproctitle._setproctitle/usr/local/python3.11.13/lib/python3.11/threading.py
0000fff97ffff120
 in   File , 

", wait/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyyarl._quoting_c"  File  (most recent call first):
_bootstrap, "  File scipy.sparse.linalg._propack._spropack  File /usr/local/python3.11.13/lib/python3.11/threading.py  File scipy.spatial.transform._rotation, ""
, line /usr/local/python3.11.13/lib/python3.11/threading.py, "
Cython.Utils"""scipy.sparse.linalg._propack._dpropack, line , 231,   File scipy.sparse.linalg._propack._cpropack629" in , propcache._helpers_c/usr/local/python3.11.13/lib/python3.11/threading.py
/usr/local/python3.11.13/lib/python3.11/threading.py, , line /usr/local/python3.11.13/lib/python3.11/threading.pyscipy.optimize._direct in ""_feed, line waitscipy.sparse.linalg._propack._zpropack", Thread 0x"Cython.Plex.Actions1002, line , line /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py
, 9821045
, line Cython.Plex.Transitionsaiohttp._http_writer in , 10450000fff9a7fff120, , aiohttp._http_parser in 327"  File  in   File _bootstrap_inner, scipy.sparse.csgraph._tools in  (most recent call first):
setproctitle._setproctitle_bootstrap,  in , line "run"
Cython.Plex.Machines_bootstrap_inner,   File scipy.sparse.csgraph._shortest_path

aiohttp._websocket.maskwait60, /usr/local/python3.11.13/lib/python3.11/threading.py
/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py  File ", 
", Thread 0x in 
, Cython.Utils"  File ", line   File Cython.Plex.DFA/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.sparse.csgraph._traversal0000fff987fff120run, aiohttp._websocket.reader_c  File , line ", /usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py"60"",  (most recent call first):

scipy.sparse.csgraph._min_spanning_tree"982, Cython.Plex.Actions", line /usr/local/python3.11.13/lib/python3.11/threading.py in , line Cython.Plex.Scanners  File   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in , frozenlist._frozenlist, line , 1045" in run331"", /usr/local/python3.11.13/lib/python3.11/threading.pyrun"scipy.sparse.csgraph._flow"1002Cython.Plex.Transitions, line , , line _bootstrap_inner
 in /usr/local/python3.11.13/lib/python3.11/threading.pyCython.Compiler.Scanning
, line  in , 231, torch._C1002
  File wait"  File 327, _bootstrapscipy.sparse.csgraph._matching in Cython.Plex.Machines in ,   File "_bootstraptorch._C._dynamo.autograd_compiler
/usr/local/python3.11.13/lib/python3.11/threading.py", line  in Cython.StringIOTree/usr/local/python3.11.13/lib/python3.11/threading.py
_feed, , "
",   File 1045wait in "
_bootstrap_inner, 

scipy.sparse.csgraph._reorderingCython.Plex.DFA/usr/local/python3.11.13/lib/python3.11/threading.py
, line torch._C._dynamo.eval_frame"
, line Thread 0xCython.Compiler.Code1045  File   File , ", "Thread 0x1045/usr/local/python3.11.13/lib/python3.11/threading.py,   File 0000fff97ffff120" in Cython.Plex.Scanners_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.optimize._group_columns, , line 0000fff9c7fff120 in "torch._C._dynamo.guards, line ",  (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py
  File ", , line "google._upb._message1002, _bootstrap_inner (most recent call first):

629/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pytorch._C._dynamo.utils  File "Cython.Compiler.Scanning1002, , line  in scipy._lib.messagestream_bootstrap  File   File  in """/usr/local/python3.11.13/lib/python3.11/threading.py in torch._C._fft, 982
, "wait/usr/local/python3.11.13/lib/python3.11/threading.py, line /usr/local/python3.11.13/lib/python3.11/threading.py, "_bootstrapCython.StringIOTree,  in 
scipy.optimize._trlib._trlib/usr/local/python3.11.13/lib/python3.11/threading.py
"231"msgspec._core in , line 
torch._C._linalg, runThread 0xCython.Compiler.Code"0000fff95ffff120,   File , line , , line ", line _feed327
, 
 (most recent call first):
scipy.optimize._lbfgsb, 331pyarrow.lib1002 in /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py in wait1002
 in Thread 0xtorch._C._nested  File 0000fffcbc96f120  File google._upb._message, _moduleTNC, "_bootstrap
, line  in   File 60wait_bootstrap" (most recent call first):
, "pandas._libs.tslibs.ccalendar, 
  File , " in 

/usr/local/python3.11.13/lib/python3.11/threading.py  File torch._C._nn/usr/local/python3.11.13/lib/python3.11/threading.py"scipy.optimize._moduleTNC
"pandas._libs.tslibs.np_datetimeThread 0x/usr/local/python3.11.13/lib/python3.11/threading.pyrun0000fffcd116f120  File 
"", /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py, torch._C._sparse/usr/local/python3.11.13/lib/python3.11/threading.py, , "
pandas._libs.tslibs.dtypes (most recent call first):
"Thread 0x, line   File /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py0000fff96ffff120, line "msgspec._core", , line scipy.optimize._cobyla, line 629, line  in   File , wait1045"" (most recent call first):
327  File torch._C._special61, 982pandas._libs.tslibs.base",  in 
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py, line  in " in scipy.optimize._slsqp in _recv_msg/usr/local/python3.11.13/lib/python3.11/threading.py, pyarrow.lib_bootstrap_inner  File "231wait/usr/local/python3.11.13/lib/python3.11/threading.py"run
, "pandas._libs.tslibs.nattype
, ", , line pandas._libs.tslibs.timezones in 
_feed, line 
  File scipy.optimize._minpack, line   File pandas._libs.tslibs.ccalendar/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py61,   File 
327  File "1045, "", ,  in pandas._libs.tslibs.fields" in   File , ""pandas._libs.tslibs.timedeltas/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py" in scipy.optimize._lsq.givens_elimination/usr/local/python3.11.13/lib/python3.11/threading.py, line numpy.random._commonpandas._libs.tslibs.np_datetime60_recv_msg/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pywait/usr/local/python3.11.13/lib/python3.11/threading.py
/usr/local/python3.11.13/lib/python3.11/threading.py, , line _bootstrap_inner", scipy.optimize._zeros in , 
, "  File "  File "pandas._libs.tslibs.tzconversion195
 in , line run, numpy.random.bit_generatorpandas._libs.tslibs.dtypes, line ", line ", line   File 1045, _read_thread1002
scipy.optimize._cython_nnls231/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py, ", 982/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py" in 
pandas._libs.tslibs.timestamps in   File ,  in , numpy.random._bounded_integersscipy._lib._uarray._uarray, line pandas._libs.tslibs.base in "/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner"  File _bootstrap"pandas._libs.properties_feed195, , runnumpy.random._pcg64, line , 
, line "
/usr/local/python3.11.13/lib/python3.11/threading.py
,  in scipy.special._ufuncs_cxx
231, , pandas._libs.tslibs.nattype  File 1002/usr/local/python3.11.13/lib/python3.11/threading.py
"  File pandas._libs.tslibs.offsets_read_thread  File 
 in , numpy.random._generatorscipy.special._ufuncs",  in "Thread 0x, line "0000fff98bfff120"  File _feedpandas._libs.tslibs.strptime, /usr/local/python3.11.13/lib/python3.11/threading.pypandas._libs.tslibs.timezones, _bootstrap, line 1045/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
/usr/local/python3.11.13/lib/python3.11/threading.py"  File "
, numpy.random._mt19937"scipy.special._specfun
, 982
 in pandas._libs.tslibs.fields"/usr/local/python3.11.13/lib/python3.11/threading.py", line   File pandas._libs.tslibs.parsing, line , ,  in Thread 0xnumpy.random._philox_bootstrap_innerrun, line ", /usr/local/python3.11.13/lib/python3.11/threading.py, line 1045" in , 1002scipy.special._comb0000fffcd48af120

, 982pandas._libs.tslibs.timedeltas" in 982/usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner in pandas._libs.tslibs.conversion in run (most recent call first):
,   File   File numpy.random._sfc64run, , line 
"
_bootstrap
  File 
,   File scipy.special._ellip_harm_2""pandas._libs.tslibs.tzconversion/usr/local/python3.11.13/lib/python3.11/threading.py, 327  File numpy.random.mtrand, line   File "
pandas._libs.tslibs.period"/usr/local/python3.11.13/lib/python3.11/threading.py, "scipy.linalg._decomp_interpolative,  in ", 982scipy.optimize._bglu_dense"/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x, , , /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line pandas._libs.tslibs.timestampswait/usr/local/python3.11.13/lib/python3.11/threading.py in ""run0000fff993fff120scipy.optimize._lsapaclpandas._libs.tslibs.vectorized", line 1045
",   File , line , line 
 (most recent call first):
, , line , 1002 in pandas._libs.ops_dispatchpandas._libs.properties, line "10021045  File ,   File scipy.spatial._ckdtree61 in _bootstrap_inner, 1045/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in ,  in "torch_npu._C/usr/local/python3.11.13/lib/python3.11/threading.py" in /usr/local/python3.11.13/lib/python3.11/threading.py, _bootstrap
pandas._libs.missing
 in "_bootstrappandas._libs.tslibs.offsets
_bootstrap_inner"", _recv_msgscipy.spatial._qhull  File 
, , _bootstrap_inner, line 

, line , line pandas._libs.tslibs.strptime
"Thread 0x, pandas._libs.hashtablescipy.spatial._voronoimarkupsafe._speedups
231Thread 0x  File 10450000fff98bfff120 in 327,   File /usr/local/python3.11.13/lib/python3.11/threading.pyyaml._yaml", 0000fffcf3d5f120, , pandas._libs.algos  File  in "/usr/local/python3.11.13/lib/python3.11/threading.py (most recent call first):
"_bootstrap_inner in ", line pandas._libs.tslibs.parsing (most recent call first):
scipy.spatial._distance_wrap", _feed,   File , line 
wait, /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py1002,   File /usr/local/python3.11.13/lib/python3.11/threading.pypandas._libs.interval
scipy.spatial._hausdorff"1002  File 
psutil._psutil_linux"  File  in pandas._libs.tslibs.conversion""  File , /usr/local/python3.11.13/lib/python3.11/threading.py in , "/usr/local/python3.11.13/lib/python3.11/threading.py, line "_bootstrap, /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py, , line "pandas._libs.lib"_bootstrapscipy.spatial.transform._rotation", line 195/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py in 
zmq.backend.cython._zmq"pandas._libs.tslibs.period1002/usr/local/python3.11.13/lib/python3.11/threading.py
, line , , 1002"_read_thread
, line  in ", 
327Current thread 0xpyarrow._compute, scipy.optimize._direct in , line 
231Current thread 0x_bootstrap61, line pandas._libs.tslibs.vectorized in 0000ffff906fa060PIL._imaging, _bootstrap  File  in _feed0000ffff7bef7060
 in , 982wait in ,  (most recent call first):
pandas._libs.ops
"
,  (most recent call first):

_recv_msgsetproctitle._setproctitle
run  File pandas._libs.ops_dispatch"  File 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/threading.py,   File pandas._libs.hashing"/usr/local/python3.11.13/lib/python3.11/threading.py,   File Thread 0x

", , Thread 0x"sentencepiece._sentencepiece"", line pandas._libs.arrays"0000fff96bfff120  File   File /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.pypandas._libs.missingCython.Utils0000fff97bfff120, line , line , 231, pandas._libs.hashtable/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py,  (most recent call first):
""" (most recent call first):
982, 982 in regex._regex", pandas._libs.tslib  File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py/usr/local/python3.11.13/lib/python3.11/threading.py  File , line  in Cython.Plex.Actions in _feed, line 
pandas._libs.algos, , """"2981runrun, 2981Cython.Plex.Transitions  File pandas._libs.sparse", npu_utils/usr/local/python3.11.13/lib/python3.11/threading.py, line , line /usr/local/python3.11.13/lib/python3.11/threading.py195 in 
run_scheduler_process
 in , /usr/local/python3.11.13/lib/python3.11/threading.py, pandas._libs.interval"1045, line , 327" in   File 
  File run_scheduler_processCython.Plex.Machines""pandas._libs.internals in , PIL._imagingftpandas._libs.lib in , line _read_thread"  File 
/usr/local/python3.11.13/lib/python3.11/threading.py, , line _bootstrap_inner, wait327
, /usr/local/python3.11.13/lib/python3.11/threading.py  File ", ""/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.pyCython.Plex.DFA982
  File pandas._libs.indexing
 in   File pyarrow._compute"_cffi_backend, line ", line  in , Cython.Plex.Scanners"  File , , wait"/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py, "1045, line 1045run, /usr/local/python3.11.13/lib/python3.11/threading.py"pandas._libs.indexCython.Compiler.Scanning
/usr/local/python3.11.13/lib/python3.11/threading.pypandas._libs.ops, , line  in 108 in 
 in cython.cimports.libc.mathrun"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py  File ", pandas._libs.writers108, _bootstrap_inner_bootstrap_inner  File 
, line ", "", line Cython.StringIOTree in , 982, pandas._libs.hashing

  File 1002/usr/local/python3.11.13/lib/python3.11/threading.pyscipy._lib._ccallback_c, line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pyrunpandas._libs.join in Cython.Compiler.Code,   File   File " in "231" in , _feed
run, pandas._libs.arrays"", /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py_bootstrap, line , line scipy.linalg._fblas
  File 
pandas._libs.window.aggregations/usr/local/python3.11.13/lib/python3.11/threading.py, /usr/local/python3.11.13/lib/python3.11/threading.py"google._upb._message", line 
1045231  File ,   File ", pandas._libs.tslibpandas._libs.window.indexers", line 1002
 in Thread 0x in "scipy.linalg._flapack"/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py, line , , 314 in , _bootstrap_inner0000fff997fff120_feed/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/threading.py, "scipy.linalg.cython_lapack1002pandas._libs.sparsepandas._libs.reshape in _bootstrapmsgspec._core_bootstrap
 (most recent call first):

"", line  in , , , , 
  File 
  File   File , line , line 314_bootstrapscipy.linalg._cythonized_array_utilspyarrow.libpandas._libs.internalspandas._libs.groupby
  File """9821045 in 
, , , Current thread 0xpandas._libs.tslibs.ccalendar"/usr/local/python3.11.13/lib/python3.11/threading.py, /usr/local/python3.11.13/lib/python3.11/threading.py, /usr/local/python3.11.13/lib/python3.11/threading.py in  in _bootstrap
pandas._libs.indexingscipy.linalg._solve_toeplitz0000ffff93dfd060/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py"pandas._libs.json"pandas._libs.tslibs.np_datetime"run_bootstrap_inner
Thread 0x
, ,  (most recent call first):
, line ", line , line 327, 
 in ,   File 0000fff99ffff120  File pandas._libs.indexscipy.linalg._decomp_lu_cython  File 1002, line 982135pandas._libs.parsers in   File waitpandas._libs.tslibs.dtypes" (most recent call first):
", "pandas._libs.tslibs.base, ,  in  in _main, 
", 
/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py  File scipy.linalg._matfuncs_sqrtm_triu"/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py, pandas._libs.writers"_bootstraprunpandas._libs.testing  File /usr/local/python3.11.13/lib/python3.11/threading.py"pandas._libs.tslibs.nattype  File "/usr/local/python3.11.13/lib/python3.11/threading.py"""scipy.linalg._matfuncs_expm
, , line 

", /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py, , line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py, line , line , pandas._libs.join2981Thread 0x  File  in , line pyarrow._parquet"pandas._libs.tslibs.timezones135"327 in 1002scipy.linalg._linalg_pythran in , _bootstrap0000fff997fff120run_scheduler_process"1045, line  in , _main, line , 231waitpandas._libs.tslibs.fields, pandas._libs.window.aggregations, 
 (most recent call first):

/usr/local/python3.11.13/lib/python3.11/threading.py in "122pyarrow._fs
 in 
_feedscipy.linalg.cython_blaspandas._libs.tslibs.timedeltas
,   File , scipy.linalg._decomp_update  File _bootstrap_inner, line " in   File ,   File 
Current thread 0x, "pandas._libs.window.indexerspandas._libs.tslibs.tzconversion
, , 1045/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.pyspawn_main"pyarrow._azurefs"  File 0000ffffb3340060/usr/local/python3.11.13/lib/python3.11/threading.py,   File  (most recent call first):
, scipy.sparse._sparsetoolspandas._libs.reshape in "
/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py""pyarrow._hdfs"  File pandas._libs.tslibs.timestamps, , line _csparsetools_bootstrap_inner,   File "/usr/local/python3.11.13/lib/python3.11/threading.py"", line /usr/local/python3.11.13/lib/python3.11/threading.py, "pyarrow._gcsfs, 108pandas._libs.properties
, pandas._libs.groupbyscipy.sparse._csparsetools, line "<string>, line 231327"/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py in ,   File run, , , pandas._libs.tslibs.offsets, line ", 122 in pandas._libs.tslibs.strptime in wait in 
, , line "pyarrow._s3fs"
pandas._libs.json  File scipy.sparse.linalg._dsolve._superlu982, line spawn_main_feed
  File pandas._libs.tslibs.parsing1002, line /usr/local/python3.11.13/lib/python3.11/threading.py, ",  in 1pandas._libs.parsers, 
,   File " in , 2981"pandas._libs.tslibs.conversionxxhash._xxhash/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.pyrun in "scipy.sparse.linalg._eigen.arpack._arpack  File , line pandas._libs.testing"/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py_bootstrap in , line , 
<module>, "314, <string>, ", line 
231run_scheduler_process in 1002pandas._libs.tslibs.period  File 
pyarrow._acero/usr/local/python3.11.13/lib/python3.11/threading.py in scipy.sparse.linalg._propack._spropack"pyarrow._parquet

_feed, line 1 in ", ", _bootstrap, Thread 0x,   File 
 in "_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.pypandas._libs.tslibs.vectorized, line pyarrow._csv
scipy.sparse.linalg._propack._dpropack0000fff977fff120pyarrow._fs  File <module>/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py

"982  File , ,  (most recent call first):
, "scipy.sparse.linalg._propack._cpropack, "
, , line  in scipy.sparse.linalg._propack._zpropack, line "runpandas._libs.ops_dispatchpyarrow._json  File 
Extension modules: /usr/local/python3.11.13/lib/python3.11/threading.pypyarrow._azurefsThread 0x1081045, /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py in 
", pandas._libs.missing", numpy._core._multiarray_umath"0000fff987fff120 in , runscipy.sparse.csgraph._tools_bootstrap_inner  File , line , /usr/local/python3.11.13/lib/python3.11/threading.pypandas._libs.hashtablepyarrow._substrait, line  (most recent call first):
, pyarrow._hdfs
"
  File ,   File 
Extension modules: 135"982,   File , numpy.linalg._umath_linalgpyarrow._dataset, /usr/local/python3.11.13/lib/python3.11/threading.py"scipy.sparse.csgraph._shortest_path"numpy._core._multiarray_umath in , line  in pandas._libs.algos_main
"  File pyarrow._gcsfs, "/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.pypyarrow._dataset_orc, line /usr/local/python3.11.13/lib/python3.11/threading.py1045, 327scipy.sparse.csgraph._traversalrun, , , "/usr/local/python3.11.13/lib/python3.11/threading.py, ", pyarrow._s3fs" in  in 
numpy.linalg._umath_linalg, pandas._libs.intervalpybase64._pybase64"/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.pypyarrow._parquet_encryption, line , , line _bootstrap_inner, wait  File xxhash._xxhashscipy.sparse.csgraph._min_spanning_tree", line "314, , pandas._libs.lib1002

/usr/local/python3.11.13/lib/python3.11/threading.py, , 327,  in , line  in 122charset_normalizer.mdpyarrow._dataset_parquet_encryption in , _bootstrap  File   File pyarrow._compute"scipy.sparse.csgraph._flow, pyarrow._aceropybase64._pybase64wait, _bootstrap in , 
, "
"/usr/local/python3.11.13/lib/python3.11/threading.pyThread 0x, line pandas._libs.ops
, scipy.sparse.csgraph._matching
, spawn_mainpyarrow._dataset_parquet, requests.packages.charset_normalizer.md/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py"0000fff9a3fff1201045,   File pyarrow._csv  File pandas._libs.hashing, 
charset_normalizer.md", line  (most recent call first):
requests.packages.chardet.md in , ", "scipy.sparse.csgraph._reordering  File , , line 1002  File ,  in "_bootstrap_innerrequests.packages.charset_normalizer.md/usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pypyarrow._json/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py"pandas._libs.arrays231scipy.optimize._group_columns_bootstrap/usr/local/python3.11.13/lib/python3.11/threading.py
"", , "<string> in , , pandas._libs.tslib
, 
  File Thread 0x, line , line requests.packages.chardet.mdpyarrow._substrait, line "_feedmultidict._multidict, scipy._lib.messagestream"3270000fff9abfff120, 231135__triton_launcher, , line 
pandas._libs.sparse/usr/local/python3.11.13/lib/python3.11/threading.py,  in , " (most recent call first):
,  in  in pyarrow._dataset,  (total: 1  File yarl._quoting_cwaitpandas._libs.internals, line scipy.optimize._trlib._trlib  File "_feed_mainmultidict._multidict, 174 in "
, 1002, , /usr/local/python3.11.13/lib/python3.11/threading.py"

pyarrow._dataset_orc), <module>/usr/local/python3.11.13/lib/python3.11/threading.pypropcache._helpers_c  File  in pandas._libs.indexingscipy.optimize._lbfgsb, line   File   File 
, yarl._quoting_c
""_bootstrap, , aiohttp._http_writer327", "pyarrow._parquet_encryption, , line /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py982
pandas._libs.index in 
/usr/local/python3.11.13/lib/python3.11/threading.py, _moduleTNC/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.pypropcache._helpers_c, " in waitThread 0x, "aiohttp._http_parserpandas._libs.writers, "pyarrow._dataset_parquet_encryption, , line run
0000fff8e3fff120, line , scipy.optimize._moduleTNC, , line aiohttp._http_writer, 231
  File 
Extension modules:  (most recent call first):
  File 982pandas._libs.joinaiohttp._websocket.mask122, , , pyarrow._dataset_parquet,  in   File aiohttp._http_parser"numpy._core._multiarray_umath" in  in scipy.optimize._cobylapandas._libs.window.aggregationsaiohttp._websocket.reader_c_feed", /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.pyrun, spawn_main, , 
/usr/local/python3.11.13/lib/python3.11/threading.py, aiohttp._websocket.maskfrozenlist._frozenlist""
,   File numpy.linalg._umath_linalg"
pandas._libs.window.indexersscipy.optimize._slsqp  File ", line , line , aiohttp._websocket.reader_c/usr/local/python3.11.13/lib/python3.11/threading.py  File 395, , ", line 231"torch._C, line ",  in , pandas._libs.reshapescipy.optimize._minpack/usr/local/python3.11.13/lib/python3.11/threading.py1045 in  in 1045, <string>torch._C._dynamo.autograd_compilerpybase64._pybase64frozenlist._frozenlist_recv, , ", pandas._libs.groupby, _bootstrap_inner in _feed"torch._C._dynamo.eval_frame
, , , line scipy.optimize._lsq.givens_elimination__triton_launcher
, _bootstrap_inner
pandas._libs.json, line   File , torch._Ccharset_normalizer.md982  File  (total: , "
  File 1", torch._C._dynamo.guards,  in 174, scipy.optimize._zeros/usr/local/python3.11.13/lib/python3.11/threading.py  File " in /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.pypandas._libs.parserstorch._C._dynamo.autograd_compiler, run)requests.packages.charset_normalizer.md", ", line /usr/local/python3.11.13/lib/python3.11/threading.py<module>"torch._C._dynamo.utils, 
, 
, scipy.optimize._cython_nnls/usr/local/python3.11.13/lib/python3.11/threading.py1002"
, line pandas._libs.testing  File , torch._C._dynamo.eval_framerequests.packages.chardet.md, " in , line , 430"torch._C._fftpyarrow._parquet, , line _bootstrap982, scipy._lib._uarray._uarray in /usr/local/python3.11.13/lib/python3.11/threading.pytorch._C._dynamo.guards, 1002
pyarrow._fs in , _recv_bytes, "torch._C._linalg,  in torch._C._dynamo.utils
run, , multidict._multidict
scipy.special._ufuncs_cxx, line _bootstrap, torch._C._nestedThread 0x
pyarrow._azurefstorch._C._fft  File , 1045, 

Extension modules: 0000fff983fff120,   File ", yarl._quoting_c,  in scipy.special._ufuncs, 
numpy._core._multiarray_umath (most recent call first):
torch._C._nn"/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.pypyarrow._hdfstorch._C._linalg, , _bootstrap_inner, propcache._helpers_cThread 0x  File /usr/local/python3.11.13/lib/python3.11/threading.py", , numpy.linalg._umath_linalgtorch._C._nested
scipy.special._specfun0000fff993fff120  File ", ", line aiohttp._http_writertorch._C._sparsepyarrow._gcsfs,  (most recent call first):
, , , "/usr/local/python3.11.13/lib/python3.11/threading.py, line 250torch._C._nn, ,   File pyarrow._s3fsscipy.special._combpybase64._pybase64/usr/local/python3.11.13/lib/python3.11/threading.py"1045 in , line aiohttp._http_parsertorch._C._special, ", , " in recv, 327torch._C._sparse, /usr/local/python3.11.13/lib/python3.11/threading.pyxxhash._xxhashscipy.special._ellip_harm_2, line _bootstrap_inner
charset_normalizer.md in aiohttp._websocket.mask, ", , 1002
,   File   File wait"torch._C._special, line , pyarrow._acerorequests.packages.charset_normalizer.mdaiohttp._websocket.reader_c in scipy.linalg._decomp_interpolative", 
/usr/local/python3.11.13/lib/python3.11/threading.py327, , requests.packages.chardet.md_bootstrap/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.pyfrozenlist._frozenlist",   File scipy.optimize._bglu_dense"" in pyarrow._csv
, , line , , line , /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.pywait, 
pyarrow._jsonnumpy.random._common822torch._C1002scipy.optimize._lsap"
Thread 0x,  in ,  in , , line , ,   File 0000fff91ffff120pyarrow._substrait, _callmethodnumpy.random.bit_generator_bootstraptorch._C._dynamo.autograd_compiler
, 231scipy.spatial._ckdtree in _feednumpy.random._common" (most recent call first):
multidict._multidict
, 
numpy.random._bounded_integers, , /usr/local/python3.11.13/lib/python3.11/multiprocessing/queues.py
  File ,   File pyarrow._dataset  File Thread 0x", torch._C._dynamo.eval_framescipy.spatial._qhull, ""numpy.random.bit_generator"0000fff93ffff120, /usr/local/python3.11.13/lib/python3.11/threading.pyyarl._quoting_cnumpy.random._pcg64, , , line /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py<string> (most recent call first):
pyarrow._dataset_orc, "numpy.random._bounded_integersscipy.spatial._voronoitorch._C._dynamo.guards, , 231""  File , , line , propcache._helpers_c, , numpy.random._generator in , line , line pyarrow._parquet_encryption"982numpy.random._pcg64torch._C._dynamo.utilsscipy.spatial._distance_wrap, _feed, 3952numpy.random._mt19937/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py, ,  in , , , torch._C._fftaiohttp._http_writer
 in  in pyarrow._dataset_parquet_encryption"numpy.random._philoxrunnumpy.random._generatorscipy.spatial._hausdorff,   File _recv, , pyarrow._dataset_parquetget, line 

, , torch._C._linalg", 
aiohttp._http_parserscipy.spatial.transform._rotation395  File   File   File  in numpy.random._sfc64numpy.random._mt19937/usr/local/python3.11.13/lib/python3.11/threading.py, ", , ""_recv, 
, "torch._C._nested/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.pyaiohttp._websocket.maskscipy.optimize._direct/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py/usr/local/python3.11.13/lib/python3.11/threading.py  File numpy.random.mtrandnumpy.random._philox, line , ", , """982, torch._C._nn, line , aclaiohttp._websocket.reader_c, line , line /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py in numpy.random._sfc6468, setproctitle._setproctitle4301045, " in run,  in torch._C._sparsenumpy.random.mtrand, ,  in _recv_bytesfrozenlist._frozenlist
, , line _bootstrap_inner
run, torch_npu._C__triton_launcher,   File Cython.Utils430
,   File   File 
torch._C._special (total: acl" in , torch._C"",   File 174/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py_recv_bytes", line Cython.Plex.Actions/usr/local/python3.11.13/lib/python3.11/threading.py, markupsafe._speedups", torch._C._dynamo.autograd_compiler)"
1002", /usr/local/python3.11.13/lib/python3.11/threading.pytorch_npu._C
, , line   File ,  in , line , Cython.Plex.Transitions1045"torch._C._dynamo.eval_frame250"_bootstrapyaml._yamlnumpy.random._common in , , line ,  in /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py, 
, _bootstrap_innerCython.Plex.Machines1045numpy.random.bit_generatorrecv"torch._C._dynamo.guards, 
markupsafe._speedups
Thread 0x,  in 
, , line numpy.random._bounded_integers,   File 0000fff893fff120psutil._psutil_linux (most recent call first):
, _bootstrap_inner
  File Cython.Plex.DFA250, torch._C._dynamo.utils"  File yaml._yaml,   File " in , numpy.random._pcg64/usr/local/python3.11.13/lib/python3.11/threading.py, "zmq.backend.cython._zmq, , "/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.pyrecvCython.Plex.Scanners"torch._C._fft/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.pynumpy.random._generatorpsutil._psutil_linux, /usr/local/python3.11.13/lib/python3.11/threading.py, torch._C._linalg", 
, , line "", numpy.random._mt19937, PIL._imaging, line   File Cython.Compiler.Scanning8221002, line , line zmq.backend.cython._zmq, torch._C._nested" in /usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py, _callmethod" in 
, line 3951002numpy.random._philox,  in , torch._C._nnCython.StringIOTree_bootstrap  File 822,  in  in , _bootstrapnumpy.random._sfc64PIL._imaging
, ", , sentencepiece._sentencepiecenumpy.random.mtrand_callmethod_recv
, 
torch._C._sparse<string>Cython.Compiler.Code
", 
, line , 
2acl, Thread 0xThread 0x  File torch._C._special,   File regex._regex in "sentencepiece._sentencepiece0000fff9a3fff1200000fff77ffff120"google._upb._message, get/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py (most recent call first):
 (most recent call first):
,   File , "<string>npu_utilstorch_npu._C
"  File regex._regex/usr/local/python3.11.13/lib/python3.11/threading.py",   File , line ", "npu_utils, line PIL._imagingft2"430/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py, line ,  in , /usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py in , "331, markupsafe._speedups_cffi_backendget"PIL._imagingft_recv_bytesmsgspec._core, , line  in 395
, line   File , , 
yaml._yamlwait,  in 68_cffi_backend, "cython.cimports.libc.mathnumpy.random._common  File 
_recv in pyarrow.librun/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py, , , scipy._lib._ccallback_c, "  File , 
"
", cython.cimports.libc.mathpsutil._psutil_linuxnumpy.random.bit_generator/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.pyscipy.linalg._fblas  File   File "/usr/local/python3.11.13/lib/python3.11/threading.py", line pandas._libs.tslibs.ccalendar, , ", , /usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py"scipy.linalg._flapack/usr/local/python3.11.13/lib/python3.11/threading.py68scipy._lib._ccallback_c, zmq.backend.cython._zmq, line , numpy.random._bounded_integers", line  in ", , pandas._libs.tslibs.np_datetime250scipy.linalg._fblas, line 629, run, line scipy.linalg.cython_lapack
PIL._imaging,  in 430,  in numpy.random._pcg641045  File ,  in pandas._libs.tslibs.dtypesrecv in scipy.linalg._flapackwait"/usr/local/python3.11.13/lib/python3.11/threading.py, scipy.linalg._cythonized_array_utils_bootstrap_inner, , 
_recv_bytes  File 
, scipy.linalg.cython_lapack"numpy.random._generator
, line sentencepiece._sentencepiecepandas._libs.tslibs.base, 
"  File ,   File 1045, scipy.linalg._solve_toeplitz,   File , "/usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py"scipy.linalg._cythonized_array_utils" in _bootstrap_innernumpy.random._mt19937pandas._libs.tslibs.nattype, regex._regex/usr/local/python3.11.13/lib/python3.11/multiprocessing/connection.py"/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py/usr/local/python3.11.13/lib/python3.11/threading.py, 
", , scipy.linalg._decomp_lu_cython", line ", line scipy.linalg._solve_toeplitz,   File , line "1002/usr/local/python3.11.13/lib/python3.11/threading.pynumpy.random._philoxpandas._libs.tslibs.timezones822, , line 250npu_utils,  in ", , , scipy.linalg._matfuncs_sqrtm_triu in 60 in scipy.linalg._decomp_lu_cythonrecv_bootstrap, line numpy.random._sfc64pandas._libs.tslibs.fieldsPIL._imagingft_callmethod in , 
1002
, , , , 
runscipy.linalg._matfuncs_expm  File  in 
_cffi_backendscipy.linalg._matfuncs_sqrtm_triunumpy.random.mtrandpandas._libs.tslibs.timedeltas  File , 
"_bootstrap, Thread 0x, ", cython.cimports.libc.math, /usr/local/python3.11.13/lib/python3.11/multiprocessing/managers.py  File 
scipy.linalg._linalg_pythran0000fff9affff120
scipy.linalg._matfuncs_expm (most recent call first):
Thread 0x, <string>pandas._libs.tslibs.tzconversionacl", "0000fff9c3fff120  File , scipy.linalg.cython_blas (most recent call first):
", , line scipy._lib._ccallback_c/usr/local/python3.11.13/lib/python3.11/threading.py"scipy.linalg._linalg_pythran, /usr/local/python3.11.13/lib/python3.11/threading.py  File , line "pandas._libs.tslibs.timestamps822, ", line , scipy.linalg._decomp_update, "2/usr/local/python3.11.13/lib/python3.11/threading.py in , torch_npu._Cpandas._libs.properties1045scipy.linalg._fblas, scipy.linalg.cython_blasscipy.sparse._sparsetools, line ,  in get"_callmethod in , , 331, scipy.linalg._decomp_updatescipy.linalg._flapack, 
, line 
331_bootstrap_innerpandas._libs.tslibs.offsets in _csparsetools, , , scipy.sparse._sparsetoolsmarkupsafe._speedups  File   File  in "
wait,   File 
"pandas._libs.tslibs.strptimescipy.linalg.cython_lapack, "wait<string>, scipy.sparse._csparsetools/usr/local/python3.11.13/lib/python3.11/threading.py  File , _csparsetools/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py, 
"scipy.linalg._cythonized_array_utilsyaml._yaml""pandas._libs.tslibs.parsing, ",   File , line , , line /usr/local/python3.11.13/lib/python3.11/threading.pyscipy.sparse.linalg._dsolve._superlu, , line scipy.sparse._csparsetools, "2/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.linalg._solve_toeplitz1002"pandas._libs.tslibs.conversion, , 68scipy.sparse.linalg._eigen.arpack._arpack, " in  in , line , scipy.linalg._decomp_lu_cythonpsutil._psutil_linux in scipy.sparse.linalg._dsolve._superlu, , line get_bootstrap629pandas._libs.tslibs.period, run, , scipy.sparse.linalg._propack._spropack629

 in  in waitscipy.linalg._matfuncs_sqrtm_triu, 
zmq.backend.cython._zmqscipy.sparse.linalg._eigen.arpack._arpack  File 
, wait
  File pandas._libs.tslibs.vectorized,   File "Thread 0xscipy.sparse.linalg._propack._dpropack, 
"  File ", scipy.linalg._matfuncs_expm, "/usr/local/Ascend/ascend-toolkit/latest/python/site-packages/tbe/common/repository_manager/utils/multiprocess_util.py0000fffcd1c9f120scipy.sparse.linalg._propack._spropack, /usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.pypandas._libs.ops_dispatchPIL._imaging/usr/local/python3.11.13/lib/python3.11/threading.py, " (most recent call first):
scipy.sparse.linalg._propack._cpropack  File ", ", , line 60" in scipy.linalg._linalg_pythran, line ", line scipy.sparse.linalg._propack._dpropack, pandas._libs.missing, line run68/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py, 60scipy.linalg.cython_blas,  in scipy.sparse.linalg._propack._zpropack, , , 1045
 in "scipy.sparse.linalg._propack._cpropackrun, line sentencepiece._sentencepiecescipy.linalg._decomp_update, pandas._libs.hashtable in   File run
, 
scipy.sparse.linalg._propack._zpropack61scipy.sparse.csgraph._tools in , _bootstrap_innerscipy.sparse._sparsetools, , "  File /usr/local/python3.11.13/lib/python3.11/threading.py  File , _recv_msg, "
scipy.sparse.csgraph._shortest_pathregex._regex, pandas._libs.algos""scipy.sparse.csgraph._tools
/usr/local/python3.11.13/lib/python3.11/threading.py  File , _csparsetools/usr/local/python3.11.13/lib/python3.11/threading.py, line , , 1045 in ,   File , ""scipy.sparse.csgraph._traversal"pandas._libs.intervalscipy.sparse._csparsetools_bootstrap_innernpu_utils"scipy.sparse.csgraph._shortest_path, line /usr/local/python3.11.13/lib/python3.11/threading.py, line , , scipy.sparse.csgraph._min_spanning_tree, 
/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py, , 1045"1045, line scipy.sparse.linalg._dsolve._superlupandas._libs.lib,   File "scipy.sparse.csgraph._flowscipy.sparse.csgraph._traversalPIL._imagingft in  in , 1002, , " in pyarrow._compute, line , /usr/local/python3.11.13/lib/python3.11/threading.py_bootstrap_inner_bootstrap_inner"scipy.sparse.csgraph._min_spanning_tree
scipy.sparse.linalg._eigen.arpack._arpack, _bootstrap195
, scipy.sparse.csgraph._matching
, 
, line   File , scipy.sparse.csgraph._flow_cffi_backend in scipy.sparse.linalg._propack._spropack, Thread 0xscipy.sparse.csgraph._reorderingpandas._libs.ops  File 1002", /usr/local/python3.11.13/lib/python3.11/threading.py, _read_thread, , scipy.sparse.linalg._propack._dpropack0000fff98ffff120" in , scipy.optimize._group_columns"scipy.sparse.csgraph._matching
cython.cimports.libc.math,  (most recent call first):
  File /usr/local/python3.11.13/lib/python3.11/threading.py_bootstrappandas._libs.hashing", line   File , ", scipy.sparse.linalg._propack._cpropack, "
, line 1002scipy._lib.messagestream in , /usr/local/python3.11.13/lib/python3.11/threading.py, "scipy.sparse.csgraph._reorderingscipy._lib._ccallback_c, /usr/local/python3.11.13/lib/python3.11/threading.py1002
_bootstrappandas._libs.arraysscipy.optimize._trlib._trlib, line scipy.sparse.linalg._propack._zpropack, , , , " in Thread 0x_bootstrap0000fffcf129f120
982, scipy.optimize._group_columnspandas._libs.tslibscipy.linalg._fblasscipy.sparse.csgraph._tools, line 
 (most recent call first):


scipy.optimize._lbfgsb in , , , 331,   File Thread 0xThread 0xrunscipy._lib.messagestream, pandas._libs.sparse, scipy.linalg._flapack in scipy.sparse.csgraph._shortest_path"0000fff9abfff1200000fffcde29f120
_moduleTNC, scipy.optimize._trlib._trlibwait, /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py,  (most recent call first):
",  (most recent call first):
  File , pandas._libs.internals
"scipy.linalg.cython_lapackscipy.optimize._lbfgsb  File , line scipy.sparse.csgraph._traversal"  File scipy.optimize._moduleTNC  File /usr/local/python3.11.13/lib/python3.11/threading.py, pandas._libs.indexing, , 61/usr/local/python3.11.13/lib/python3.11/threading.py_moduleTNC in , ""scipy.sparse.csgraph._min_spanning_tree, "scipy.linalg._cythonized_array_utils, ", _recv_msg/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.pyscipy.optimize._cobyla, line , pandas._libs.indexscipy.optimize._moduleTNC, line 
, ""1045scipy.sparse.csgraph._flow, , 331,   File  in scipy.linalg._solve_toeplitzwait, line , line  in scipy.optimize._slsqp, pandas._libs.writersscipy.optimize._cobyla"
, scipy.linalg._decomp_lu_cython62961_bootstrap_innerscipy.sparse.csgraph._matching, , ,   File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py in  in wait
, scipy.optimize._minpack, pandas._libs.joinscipy.optimize._slsqp""_recv_msg
  File   File scipy.linalg._matfuncs_sqrtm_triuscipy.sparse.csgraph._reordering, scipy.optimize._lsq.givens_elimination/usr/local/python3.11.13/lib/python3.11/threading.py, , line 
, "pandas._libs.window.aggregations", , , "scipy.optimize._minpack  File 195, /usr/local/python3.11.13/lib/python3.11/threading.pyscipy.optimize._zeros/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.pyscipy.linalg._matfuncs_expm"scipy.optimize._group_columnspandas._libs.window.indexers, line , " in , ", , line , line 6291002scipy.linalg._linalg_pythran in , , /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py_read_threadscipy.optimize._lsq.givens_eliminationscipy.optimize._cython_nnls
, 60 in _bootstrappandas._libs.reshape, scipy._lib.messagestream"  File scipy.optimize._zeros,  in wait
scipy.linalg.cython_blas, line 
, ", , scipy._lib._uarray._uarrayscipy.linalg._decomp_update, run
195Current thread 0x in pandas._libs.groupby/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.optimize._trlib._trlibscipy.optimize._cython_nnls, , , 
scipy.sparse._sparsetools  File scipy.optimize._lbfgsb0000ffff911bc060, _read_thread", , line scipy.special._ufuncs_cxx982,  in   File " (most recent call first):
  File _csparsetools", 
pandas._libs.json  File scipy._lib._uarray._uarray, runscipy.special._ufuncs"/usr/local/python3.11.13/lib/python3.11/site-packages/tqdm/_monitor.py/usr/local/python3.11.13/lib/python3.11/threading.py/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py_moduleTNC, ", , , 
, "scipy.special._specfun""scipy.sparse._csparsetools/usr/local/python3.11.13/lib/python3.11/threading.pypandas._libs.parsersscipy.optimize._moduleTNCscipy.special._ufuncs_cxx  File , line , line , , line ", , ", 60, 1045scipy.special._comb2981, line scipy.sparse.linalg._dsolve._superlu in , scipy.special._ellip_harm_2pandas._libs.testing/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.optimize._cobyla in scipy.special._ufuncs,  in 982run_scheduler_process, ", run
, pyarrow._parquet_bootstrap_inner,  in 
scipy.sparse.linalg._eigen.arpack._arpack, line scipy.linalg._decomp_interpolative  File scipy.optimize._slsqp
, scipy.special._specfunrun  File 1045,  in ",   File , pyarrow._fs
", scipy.sparse.linalg._propack._spropack_bootstrap_inner/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.optimize._bglu_densescipy.optimize._minpack"  File , /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.pyscipy.special._comb
", /usr/local/python3.11.13/lib/python3.11/threading.py, , "pyarrow._azurefsscipy.optimize._lsq.givens_elimination"/usr/local/python3.11.13/lib/python3.11/threading.py"  File , line , scipy.sparse.linalg._propack._dpropack"scipy.optimize._lsap, , line , , line "1045scipy.special._ellip_harm_2, line , pyarrow._hdfs, 108scipy.optimize._zeros1045/usr/local/python3.11.13/lib/python3.11/threading.py in 1002, scipy.sparse.linalg._propack._cpropackscipy.spatial._ckdtree in , " in , _bootstrap_innerscipy.linalg._decomp_interpolative in runpyarrow._gcsfs, line , , _bootstrap_innerscipy.optimize._cython_nnlsscipy.spatial._qhull
_bootstrap
, 1002, scipy.sparse.linalg._propack._zpropack
  File , 
,   File  in scipy.optimize._bglu_dense"pyarrow._s3fs  File , "scipy._lib._uarray._uarray/usr/local/python3.11.13/lib/python3.11/threading.py
scipy.spatial._voronoi_bootstrap/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py, "scipy.sparse.csgraph._tools, ", Thread 0x, 
"/usr/local/python3.11.13/lib/python3.11/threading.pyscipy.optimize._lsap, line xxhash._xxhash, , scipy.special._ufuncs_cxx0000fffcbe27f120scipy.spatial._ckdtreescipy.spatial._distance_wrap
, line "1002scipy.sparse.csgraph._shortest_path,  (most recent call first):
, , , Current thread 0x, 314, line  in pyarrow._acero1002  File scipy.special._ufuncsscipy.sparse.csgraph._traversalscipy.spatial._qhull"0000ffffb07f5060scipy.spatial._hausdorff in _bootstrap in 
, , , /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py (most recent call first):
, _bootstrap, _bootstrapscipy.spatial.transform._rotation
pyarrow._csvscipy.special._specfunscipy.sparse.csgraph._min_spanning_tree"  File scipy.spatial._voronoi
, 
Thread 0x, , , , , line "  File scipy.sparse.csgraph._flow
scipy.spatial._distance_wrap0000fffccfd5f120scipy.optimize._direct, pyarrow._jsonscipy.special._combscipy.sparse.csgraph._matching61/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py"Current thread 0x (most recent call first):
, , , ,  in "/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py, 0000ffff9d79c060scipy.spatial._hausdorff  File pyarrow._substraitscipy.special._ellip_harm_2scipy.sparse.csgraph._reordering_recv_msg", line setproctitle._setproctitle (most recent call first):
, 2981", scipy.spatial.transform._rotation, , 
, line   File scipy.optimize._group_columns in /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py, pyarrow._datasetscipy.linalg._decomp_interpolative, ,   File 135"run_scheduler_process"Cython.Utils, scipy._lib.messagestream, scipy.optimize._direct" in /usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py
, line pyarrow._dataset_orc, scipy.optimize._bglu_dense, /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py_main, "  File "61, "setproctitle._setproctitleCython.Plex.Actions, scipy.optimize._trlib._trlib
scipy.optimize._lsap, line  in , line /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py, Cython.Plex.Transitionspyarrow._parquet_encryption  File , , , 195scipy.optimize._lbfgsb, _recv_msg2981scipy.spatial._ckdtree"", Cython.Plex.Machines/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.pyCython.Utils in 
,  in , line , pyarrow._dataset_parquet_encryption", _read_thread  File , _moduleTNCrun_scheduler_process108scipy.spatial._qhull in , run, line , Cython.Plex.DFA
"Cython.Plex.Actions
scipy.optimize._moduleTNC, 
, 122pyarrow._dataset_parquet  File /usr/local/python3.11.13/lib/python3.11/site-packages/torch/_inductor/compile_worker/subproc_pool.py, ,   File scipy.spatial._voronoi  File "scipy.optimize._cobyla in ", "Cython.Plex.Scannersscipy.optimize._slsqpCython.Plex.Transitions/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py", spawn_main/usr/local/python3.11.13/lib/python3.11/threading.py, line ", , /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py, scipy.spatial._distance_wrap
"195, line Cython.Compiler.Scanningscipy.optimize._minpack"Cython.Plex.Machines  File , , line ,  in 108,  in , line , 314"scipy.spatial._hausdorff in 982Cython.Plex.DFA_read_threadCython.StringIOTreerun, 
scipy.optimize._lsq.givens_elimination<string>_bootstrap in , , 
Cython.Plex.Scanners,   File "
run  File scipy.spatial.transform._rotation"scipy.optimize._zeros  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py, , Cython.Compiler.Code", line 
, ", ", __triton_launcher, line Cython.Compiler.Scanning/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.py1351  File ,  in scipy.optimize._direct/usr/local/python3.11.13/lib/python3.11/threading.pygoogle._upb._messagescipy.optimize._cython_nnls (total: " in ", line , Cython.StringIOTree<module>"174_main/usr/local/python3.11.13/lib/python3.11/threading.py314, scipy._lib._uarray._uarray
, , line , )
" in setproctitle._setproctitleCython.Compiler.Code982scipy.special._ufuncs_cxx  File 
, line _bootstrap in 1045
, ", , scipy.special._ufuncs, run in 
  File /usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.pyCython.Utilsgoogle._upb._messagemsgspec._core, _bootstrap_inner  File "", , line scipy.special._specfun
/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py"Cython.Plex.Actions122
Extension modules: ,  in , ,   File spawn_main"/usr/local/python3.11.13/lib/python3.11/threading.pynumpy._core._multiarray_umathpyarrow.lib, scipy.special._combCython.Plex.Transitions"
, line , ", msgspec._core, line , , pandas._libs.tslibs.ccalendar/usr/local/python3.11.13/lib/python3.11/threading.py  File 135scipy.special._ellip_harm_2Cython.Plex.Machines1045numpy.linalg._umath_linalg"" in , _main, ,  in scipy.linalg._decomp_interpolative, , line <string>pandas._libs.tslibs.np_datetime
pyarrow.lib_bootstrap_innerCython.Plex.DFA1002, , "scipy.optimize._bglu_dense,   File 
pybase64._pybase64,  in pandas._libs.tslibs.ccalendar, , line , "  File pandas._libs.tslibs.dtypes_bootstrapCython.Plex.Scanners, , 1, scipy.optimize._lsap/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.pycharset_normalizer.md""
, line 
, pandas._libs.tslibs.basepandas._libs.tslibs.np_datetime in /usr/local/python3.11.13/lib/python3.11/threading.py, , 122requests.packages.charset_normalizer.mdCurrent thread 0xCython.Compiler.Scanning<module>, , , "scipy.spatial._ckdtree in 0000ffff7d77d060
, , pandas._libs.tslibs.nattypescipy.spatial._qhullrequests.packages.chardet.mdpandas._libs.tslibs.dtypes, line spawn_main (most recent call first):
Cython.StringIOTree, , 1002
,   File pandas._libs.tslibs.basepandas._libs.tslibs.timezonesscipy.spatial._voronoi,  in   File ", , , Cython.Compiler.Code_bootstrap, "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py
pandas._libs.tslibs.nattypepandas._libs.tslibs.fieldsmultidict._multidictscipy.spatial._distance_wrap<string>, "
google._upb._message, , line , , ", Current thread 0x, line pandas._libs.tslibs.timezones2981yarl._quoting_cpandas._libs.tslibs.timedeltas
Extension modules: scipy.spatial._hausdorff1numpy._core._multiarray_umath in 0000ffff8f278060<module> in , , , ,  (most recent call first):

, run_scheduler_process, scipy.spatial.transform._rotationpandas._libs.tslibs.fieldspandas._libs.tslibs.tzconversionpropcache._helpers_c  File msgspec._core
numpy.linalg._umath_linalg, , ", ,   File pandas._libs.tslibs.timedeltasscipy.optimize._direct/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/managers/scheduler.py, , aiohttp._http_writerpandas._libs.tslibs.timestamps""pandas._libs.tslibs.tzconversion/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.pypyarrow.lib, , , line ", , , setproctitle._setproctitlepandas._libs.propertiesaiohttp._http_parser2981, , line pandas._libs.tslibs.timestampspandas._libs.tslibs.ccalendar in , pandas._libs.tslibs.offsetspybase64._pybase64, 108aiohttp._websocket.mask, , run_scheduler_process, ,  in Cython.Utils, pandas._libs.propertiescharset_normalizer.md, 
Extension modules: 
pandas._libs.tslibs.np_datetimepandas._libs.tslibs.strptimerun, , aiohttp._websocket.reader_cnumpy._core._multiarray_umath  File , , 
, Cython.Plex.Actionspandas._libs.tslibs.offsets, "requests.packages.charset_normalizer.mdpandas._libs.tslibs.dtypes  File , pandas._libs.tslibs.parsing, , /usr/local/python3.11.13/lib/python3.11/multiprocessing/process.pyfrozenlist._frozenlist, , "numpy.linalg._umath_linalg, Cython.Plex.Transitionspandas._libs.tslibs.strptime"pandas._libs.tslibs.conversion, requests.packages.chardet.md/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.pypandas._libs.tslibs.base, line , , torch._C", pandas._libs.tslibs.parsing108, Cython.Plex.Machines, line pandas._libs.tslibs.period, torch._C._dynamo.autograd_compiler in , pandas._libs.tslibs.nattype, 314pandas._libs.tslibs.conversion, , run, , pybase64._pybase64,  in , Cython.Plex.DFApandas._libs.tslibs.vectorizedpandas._libs.tslibs.period
torch._C._dynamo.eval_framepandas._libs.tslibs.timezones_bootstrapmultidict._multidict,   File charset_normalizer.md, , , , 
pandas._libs.tslibs.vectorized, , , "yarl._quoting_c, Cython.Plex.Scannerspandas._libs.ops_dispatch  File pandas._libs.tslibs.fieldstorch._C._dynamo.guards, pandas._libs.ops_dispatch/usr/local/python3.11.13/lib/python3.11/multiprocessing/process.pyrequests.packages.charset_normalizer.md, , ", pandas._libs.missing, ", propcache._helpers_c, Cython.Compiler.Scanning/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.pypandas._libs.tslibs.timedeltastorch._C._dynamo.utils, , line pandas._libs.missingrequests.packages.chardet.md, ", pandas._libs.hashtable, 314,  in , aiohttp._http_writer, line Cython.StringIOTreepandas._libs.tslibs.tzconversion, , torch._C._fft_bootstrappandas._libs.hashtable135aiohttp._http_parser, , , pandas._libs.algos
 in , torch._C._linalg_main, , Cython.Compiler.Codepandas._libs.tslibs.timestamps  File , pandas._libs.interval, pandas._libs.algos
, , multidict._multidictaiohttp._websocket.mask", pandas._libs.properties  File , pandas._libs.libtorch._C._nested/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.pygoogle._upb._message, , ", pandas._libs.interval", , yarl._quoting_caiohttp._websocket.reader_c/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.pypandas._libs.tslibs.offsets, line torch._C._nn, pyarrow._compute, "propcache._helpers_c135, , frozenlist._frozenlistpandas._libs.lib, , , , line  in pandas._libs.tslibs.strptime122aiohttp._http_writertorch._C._sparse, , pandas._libs.ops, _main in , spawn_mainpyarrow._computetorch._C
, aiohttp._http_parser, , 
pandas._libs.tslibs.parsing, ,   File torch._C._specialpandas._libs.hashing, msgspec._core  File , pandas._libs.opstorch._C._dynamo.autograd_compiler", , aiohttp._websocket.maskpandas._libs.arrays"pandas._libs.tslibs.conversion<string>, torch._C._dynamo.eval_frame, pandas._libs.hashing/usr/local/python3.11.13/lib/python3.11/multiprocessing/spawn.py, , , "pandas._libs.tslibs.period, , "pyarrow.libaiohttp._websocket.reader_cpandas._libs.tslib, line torch._C._dynamo.guards, pandas._libs.arrayspandas._libs.sparse, , line , , 1, , , pandas._libs.tslibs.vectorized, 122numpy.random._commonpandas._libs.tslib in pandas._libs.tslibs.ccalendarfrozenlist._frozenlisttorch._C._dynamo.utilspandas._libs.internals, ,  in , <module>, pandas._libs.indexing, , pandas._libs.ops_dispatch, torch._C._fftspawn_maintorch._C
, numpy.random.bit_generatorpandas._libs.sparse, , pandas._libs.tslibs.np_datetime, 
pandas._libs.missingtorch._C._dynamo.autograd_compiler, pandas._libs.index, ,   File torch._C._linalgnumpy.random._bounded_integers, pandas._libs.internals, pandas._libs.tslibs.dtypes, , "pandas._libs.hashtable, torch._C._dynamo.eval_frame, torch._C._nestedpandas._libs.writers, , <string>numpy.random._pcg64, pandas._libs.indexing, pandas._libs.tslibs.base, "pandas._libs.jointorch._C._dynamo.guards, line pandas._libs.algos, torch._C._nn, , 1, , , torch._C._dynamo.utils, numpy.random._generatorpandas._libs.index
Extension modules: pandas._libs.tslibs.nattype in numpy._core._multiarray_umathpandas._libs.window.aggregationstorch._C._sparsepandas._libs.interval, , , <module>, , torch._C._fft, numpy.random._mt19937, , pandas._libs.writers
pandas._libs.tslibs.timezonespandas._libs.window.indexerstorch._C._special, , numpy.random._philoxpandas._libs.libnumpy.linalg._umath_linalg, , , torch._C._linalg, pandas._libs.join, numpy.random._sfc64pandas._libs.tslibs.fieldspandas._libs.reshape, torch._C._nestedpyarrow._compute, , , , , pandas._libs.window.aggregations, numpy.random.mtrandpandas._libs.tslibs.timedeltaspandas._libs.groupby, torch._C._nn, pandas._libs.ops, , , pybase64._pybase64pandas._libs.json, pandas._libs.window.indexerspandas._libs.tslibs.tzconversion
Extension modules: , acltorch._C._sparsenumpy._core._multiarray_umath, pandas._libs.parsers, pandas._libs.hashing, , , , , charset_normalizer.mdpandas._libs.tslibs.timestamps, , pandas._libs.reshapepandas._libs.testingtorch_npu._C, numpy.random._commontorch._C._specialnumpy.linalg._umath_linalg, pyarrow._parquet, , , pandas._libs.propertiespandas._libs.arrays, requests.packages.charset_normalizer.md, , pandas._libs.groupby, numpy.random.bit_generator, , markupsafe._speedups, pyarrow._fsnumpy.random._bounded_integerspandas._libs.tslibs.offsets, pandas._libs.tslibrequests.packages.chardet.md, , , pandas._libs.json, , , , pybase64._pybase64pyarrow._azurefsnumpy.random._pcg64pandas._libs.tslibs.strptimeyaml._yaml, pandas._libs.sparsepandas._libs.parsers, , pyarrow._hdfs, , numpy.random._generator, charset_normalizer.md, , pandas._libs.tslibs.parsingnumpy.random._mt19937, pyarrow._gcsfspandas._libs.internalspandas._libs.testing, , numpy.random._common, , , , numpy.random.bit_generator, , psutil._psutil_linuxpyarrow._s3fs, requests.packages.charset_normalizer.mdpandas._libs.tslibs.conversionnumpy.random._philoxmultidict._multidict, , pandas._libs.indexingpyarrow._parquet, , , , xxhash._xxhashnumpy.random._sfc64, numpy.random._bounded_integers, zmq.backend.cython._zmq, requests.packages.chardet.mdpandas._libs.tslibs.periodyarl._quoting_c, , , pandas._libs.indexpyarrow._fspyarrow._acero, numpy.random.mtrand, numpy.random._pcg64, , , , , pandas._libs.tslibs.vectorizedpropcache._helpers_cPIL._imaging, pandas._libs.writersaclpyarrow._azurefspyarrow._csv, numpy.random._generator, , , , multidict._multidictpandas._libs.ops_dispatch, , , aiohttp._http_writertorch_npu._Cpandas._libs.joinpyarrow._hdfspyarrow._json, , numpy.random._mt19937, , yarl._quoting_c, aiohttp._http_parser, , pandas._libs.missingpyarrow._gcsfs, sentencepiece._sentencepiecenumpy.random._philox, , , pandas._libs.window.aggregationspyarrow._substrait, , pandas._libs.hashtablepyarrow._s3fspropcache._helpers_caiohttp._websocket.mask, , , regex._regex, pyarrow._dataset, markupsafe._speedupsnumpy.random._sfc64, , , , pandas._libs.window.indexers, , pandas._libs.algos, xxhash._xxhashaiohttp._http_writeraiohttp._websocket.reader_cnumpy.random.mtrandpyarrow._dataset_orc, yaml._yamlnpu_utils, , , , , pandas._libs.reshapefrozenlist._frozenlist, pandas._libs.intervalacl, , aiohttp._http_parserpyarrow._acerotorch._Cpyarrow._parquet_encryption, , , , , pyarrow._csvPIL._imagingft, , pandas._libs.groupby, psutil._psutil_linuxpandas._libs.libtorch_npu._C, aiohttp._websocket.mask, torch._C._dynamo.autograd_compilerpyarrow._dataset_parquet_encryption, , _cffi_backendpyarrow._json, , , pyarrow._computepandas._libs.json, torch._C._dynamo.eval_framezmq.backend.cython._zmq, aiohttp._websocket.reader_c, pyarrow._substrait, pyarrow._dataset_parquet, , , , pandas._libs.parsers, cython.cimports.libc.mathpandas._libs.ops, pyarrow._datasetfrozenlist._frozenlistPIL._imagingtorch._C._dynamo.guardsmarkupsafe._speedups, , , , pyarrow._dataset_orc, , pandas._libs.testing, scipy._lib._ccallback_cpandas._libs.hashingtorch._C, yaml._yamltorch._C._dynamo.utils, , , pyarrow._parquet_encryption, , pyarrow._parquet, scipy.linalg._fblaspandas._libs.arraystorch._C._dynamo.autograd_compiler, sentencepiece._sentencepiecetorch._C._fft, , , pyarrow._dataset_parquet_encryptionscipy.linalg._flapack, , , , psutil._psutil_linuxregex._regexpyarrow._fs, pandas._libs.tslib, , torch._C._dynamo.eval_frametorch._C._linalgpyarrow._dataset_parquet, zmq.backend.cython._zmq, , scipy.linalg.cython_lapack, __triton_launcher, pyarrow._azurefs, npu_utilspandas._libs.sparse,  (total: torch._C._dynamo.guards, torch._C._nestedPIL._imaging, 174scipy.linalg._cythonized_array_utils, , , , torch._C._dynamo.utilspyarrow._hdfs)
PIL._imagingftpandas._libs.internals, torch._C._nn, , , scipy.linalg._solve_toeplitz, torch._C._fft, , sentencepiece._sentencepiecepyarrow._gcsfs, pandas._libs.indexingscipy.linalg._decomp_lu_cythontorch._C._sparse, _cffi_backend, torch._C._linalg, , regex._regex, , scipy.linalg._matfuncs_sqrtm_triupyarrow._s3fs, , pandas._libs.indextorch._C._special, cython.cimports.libc.mathtorch._C._nested, , , __triton_launcher, scipy.linalg._matfuncs_expmnpu_utils, , xxhash._xxhash (total: pandas._libs.writers174torch._C._nn, scipy._lib._ccallback_c, ), , scipy.linalg._linalg_pythran, PIL._imagingft, scipy.linalg._fblas
pyarrow._aceropandas._libs.jointorch._C._sparse, , , scipy.linalg.cython_blas, _cffi_backend, , scipy.linalg._flapackpyarrow._csv, torch._C._specialpandas._libs.window.aggregations, , scipy.linalg._decomp_update, scipy.linalg.cython_lapackcython.cimports.libc.math, , pyarrow._json, , pandas._libs.window.indexersscipy.sparse._sparsetools, , , numpy.random._commonscipy.linalg._cythonized_array_utilsscipy._lib._ccallback_c, pyarrow._substrait, _csparsetoolspandas._libs.reshape, , , , scipy.linalg._fblasnumpy.random.bit_generatorscipy.sparse._csparsetools, , scipy.linalg._solve_toeplitzpyarrow._dataset, scipy.linalg._flapackpandas._libs.groupby, , numpy.random._bounded_integersscipy.linalg._decomp_lu_cythonscipy.sparse.linalg._dsolve._superlu, , , , , scipy.linalg.cython_lapackpandas._libs.json, pyarrow._dataset_orc, scipy.linalg._matfuncs_sqrtm_triunumpy.random._pcg64, scipy.sparse.linalg._eigen.arpack._arpack, scipy.linalg._cythonized_array_utils, , numpy.random._common, pandas._libs.parsersscipy.linalg._matfuncs_expm, pyarrow._parquet_encryption, , numpy.random._generator, scipy.sparse.linalg._propack._spropack, numpy.random.bit_generator, , pandas._libs.testingscipy.linalg._solve_toeplitzpyarrow._dataset_parquet_encryption, numpy.random._mt19937scipy.linalg._linalg_pythran, , , scipy.linalg._decomp_lu_cythonscipy.sparse.linalg._propack._dpropack, , numpy.random._bounded_integers, pyarrow._parquet, pyarrow._dataset_parquetscipy.linalg._matfuncs_sqrtm_triu, scipy.sparse.linalg._propack._cpropacknumpy.random._philoxscipy.linalg.cython_blas, , , , numpy.random._pcg64scipy.linalg._matfuncs_expm, scipy.sparse.linalg._propack._zpropack, pyarrow._fsnumpy.random._sfc64, , scipy.linalg._linalg_pythranscipy.linalg._decomp_update, , , , numpy.random._generatornumpy.random.mtrand, scipy.sparse.csgraph._toolsscipy.linalg.cython_blas, pyarrow._azurefsscipy.sparse._sparsetools, numpy.random._mt19937, scipy.sparse.csgraph._shortest_path, scipy.linalg._decomp_update, acl, , , pyarrow._hdfs, _csparsetoolsnumpy.random._philoxscipy.sparse.csgraph._traversalscipy.sparse._sparsetools, , numpy.random._sfc64, , pyarrow._gcsfs, , scipy.sparse._csparsetools, scipy.sparse.csgraph._min_spanning_tree, , , torch_npu._C__triton_launcher_csparsetoolsnumpy.random.mtrand, scipy.sparse.csgraph._flowpyarrow._s3fsscipy.sparse.linalg._dsolve._superlu (total: , , , 174scipy.sparse._csparsetools, , aclscipy.sparse.csgraph._matching)xxhash._xxhash, scipy.sparse.linalg._eigen.arpack._arpack
, , scipy.sparse.linalg._dsolve._superlu, , scipy.sparse.csgraph._reordering, scipy.sparse.linalg._propack._spropackmarkupsafe._speedupspyarrow._aceroscipy.sparse.linalg._eigen.arpack._arpack, , , scipy.sparse.linalg._propack._dpropack, torch_npu._C, , scipy.optimize._group_columnspyarrow._csv, scipy.sparse.linalg._propack._spropackyaml._yamlscipy.sparse.linalg._propack._cpropack, scipy._lib.messagestream, , , scipy.sparse.linalg._propack._dpropackpyarrow._json, scipy.sparse.linalg._propack._zpropack, scipy.optimize._trlib._trlib, scipy.sparse.linalg._propack._cpropack, , , , , scipy.sparse.csgraph._toolsmarkupsafe._speedupspyarrow._substraitscipy.optimize._lbfgsbpsutil._psutil_linuxscipy.sparse.linalg._propack._zpropack, , scipy.sparse.csgraph._shortest_path, pyarrow._dataset, _moduleTNC, , yaml._yaml, , pyarrow._dataset_orczmq.backend.cython._zmqscipy.sparse.csgraph._tools, scipy.sparse.csgraph._traversal, , scipy.optimize._moduleTNCscipy.sparse.csgraph._shortest_path, pyarrow._parquet_encryption, , , , scipy.sparse.csgraph._min_spanning_treePIL._imagingscipy.sparse.csgraph._traversalscipy.optimize._cobyla, psutil._psutil_linux, , pyarrow._dataset_parquet_encryption, , scipy.sparse.csgraph._flowscipy.sparse.csgraph._min_spanning_treescipy.optimize._slsqp, , , scipy.sparse.csgraph._matchingzmq.backend.cython._zmqpyarrow._dataset_parquet, , scipy.sparse.csgraph._flowscipy.sparse.csgraph._reorderingscipy.optimize._minpack, , , , scipy.sparse.csgraph._matching, sentencepiece._sentencepiecescipy.optimize._group_columnsPIL._imagingscipy.optimize._lsq.givens_elimination, , scipy.sparse.csgraph._reorderingscipy._lib.messagestream, , scipy.optimize._zeros, regex._regex, scipy.optimize._group_columns, scipy.optimize._trlib._trlibscipy.optimize._cython_nnls, , scipy._lib.messagestreamscipy.optimize._lbfgsb, , , , scipy.optimize._trlib._trlibscipy._lib._uarray._uarray, npu_utils_moduleTNC, sentencepiece._sentencepiece, , scipy.optimize._lbfgsbscipy.optimize._moduleTNC, scipy.special._ufuncs_cxx, PIL._imagingft, , , _moduleTNCscipy.special._ufuncsscipy.optimize._cobylaregex._regex, , scipy.special._specfunscipy.optimize._moduleTNC, , , , , _cffi_backendscipy.optimize._slsqp, __triton_launchernpu_utilsscipy.special._combscipy.optimize._cobyla, ,  (total: , scipy.optimize._minpack, , cython.cimports.libc.math174scipy.special._ellip_harm_2PIL._imagingft, scipy.optimize._slsqp), scipy.optimize._lsq.givens_elimination, 
, , scipy._lib._ccallback_cscipy.linalg._decomp_interpolative, scipy.optimize._minpackscipy.optimize._zeros, _cffi_backend, , scipy.linalg._fblas, scipy.optimize._lsq.givens_eliminationscipy.optimize._bglu_dense, scipy.optimize._cython_nnls, , , cython.cimports.libc.math, scipy.linalg._flapackscipy.optimize._zerosscipy._lib._uarray._uarrayscipy.optimize._lsap, , , , scipy.optimize._cython_nnlsscipy.special._ufuncs_cxxscipy._lib._ccallback_cscipy.linalg.cython_lapack, , , scipy._lib._uarray._uarray, scipy.spatial._ckdtree, scipy.special._ufuncs, scipy.linalg._fblas, scipy.linalg._cythonized_array_utilsscipy.special._ufuncs_cxx, , scipy.spatial._qhullscipy.special._specfunscipy.linalg._flapack, , , , scipy.special._ufuncsscipy.linalg._solve_toeplitzscipy.special._comb, , scipy.spatial._voronoi, scipy.linalg.cython_lapack, scipy.special._specfunscipy.special._ellip_harm_2, , scipy.linalg._decomp_lu_cython, scipy.linalg._cythonized_array_utils, scipy.spatial._distance_wrapscipy.special._comb, scipy.linalg._decomp_interpolative, , scipy.linalg._matfuncs_sqrtm_triu, scipy.spatial._hausdorff, scipy.linalg._solve_toeplitzscipy.special._ellip_harm_2, scipy.optimize._bglu_dense, , scipy.linalg._matfuncs_expm, , scipy.spatial.transform._rotationscipy.linalg._decomp_lu_cythonscipy.linalg._decomp_interpolative, scipy.optimize._lsap, , scipy.optimize._bglu_densescipy.linalg._linalg_pythran, , scipy.linalg._matfuncs_sqrtm_triu, scipy.optimize._directscipy.optimize._lsap, scipy.spatial._ckdtree, scipy.linalg.cython_blas, scipy.linalg._matfuncs_expm, scipy.spatial._ckdtreescipy.spatial._qhull, , , scipy.spatial._voronoi, scipy.spatial._qhull, setproctitle._setproctitlescipy.linalg._linalg_pythran, , scipy.spatial._distance_wrapscipy.spatial._voronoiscipy.linalg._decomp_update, , , scipy.linalg.cython_blas, scipy.spatial._hausdorffscipy.spatial._distance_wrap, , Cython.Utilsscipy.linalg._decomp_update, , scipy.sparse._sparsetools, , Cython.Plex.Actionsscipy.spatial.transform._rotationscipy.spatial._hausdorffscipy.sparse._sparsetools, , , Cython.Plex.Transitions_csparsetools, , _csparsetools, scipy.optimize._direct, scipy.spatial.transform._rotationCython.Plex.Machines, scipy.sparse._csparsetoolsscipy.sparse._csparsetools, , Cython.Plex.DFAscipy.optimize._direct, , , , setproctitle._setproctitlescipy.sparse.linalg._dsolve._superluscipy.sparse.linalg._dsolve._superluCython.Plex.Scanners, , , , scipy.sparse.linalg._eigen.arpack._arpackscipy.sparse.linalg._eigen.arpack._arpackCython.Compiler.Scanningsetproctitle._setproctitle, , Cython.StringIOTree, , Cython.Utilsscipy.sparse.linalg._propack._spropackscipy.sparse.linalg._propack._spropack, , , , Cython.Compiler.CodeCython.Utils, Cython.Plex.Actionsscipy.sparse.linalg._propack._dpropackscipy.sparse.linalg._propack._dpropack, , , Cython.Plex.Actions, Cython.Plex.Transitions, google._upb._messagescipy.sparse.linalg._propack._cpropack, scipy.sparse.linalg._propack._cpropack, Cython.Plex.MachinesCython.Plex.Transitions, , , scipy.sparse.linalg._propack._zpropack, scipy.sparse.linalg._propack._zpropackCython.Plex.DFACython.Plex.Machines, scipy.sparse.csgraph._tools, , , , scipy.sparse.csgraph._toolsCython.Plex.ScannersCython.Plex.DFAscipy.sparse.csgraph._shortest_path, , scipy.sparse.csgraph._shortest_pathCython.Compiler.Scanning, , Cython.Plex.Scanners, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._traversal, , Cython.StringIOTreemsgspec._core, , , Cython.Compiler.Scanningscipy.sparse.csgraph._min_spanning_treescipy.sparse.csgraph._min_spanning_treeCython.Compiler.Code, , , Cython.StringIOTree, scipy.sparse.csgraph._flowpyarrow.lib, scipy.sparse.csgraph._flow, google._upb._message, , pandas._libs.tslibs.ccalendarCython.Compiler.Code, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._matchingpandas._libs.tslibs.np_datetime, , , scipy.sparse.csgraph._reordering, scipy.sparse.csgraph._reorderinggoogle._upb._messagepandas._libs.tslibs.dtypes, , scipy.optimize._group_columns, scipy.optimize._group_columnspandas._libs.tslibs.base, scipy._lib.messagestream, , scipy._lib.messagestream, pandas._libs.tslibs.nattype, msgspec._core, , scipy.optimize._trlib._trlibscipy.optimize._trlib._trlibpandas._libs.tslibs.timezones, scipy.optimize._lbfgsb, , , pandas._libs.tslibs.fieldsscipy.optimize._lbfgsbpyarrow.lib, , , , _moduleTNC, pandas._libs.tslibs.timedeltasmsgspec._core_moduleTNCpandas._libs.tslibs.ccalendar, , , scipy.optimize._moduleTNCpandas._libs.tslibs.tzconversion, scipy.optimize._moduleTNC, pandas._libs.tslibs.np_datetime, pyarrow.lib, scipy.optimize._cobyla, pandas._libs.tslibs.timestamps, , scipy.optimize._cobylapandas._libs.tslibs.ccalendar, pandas._libs.tslibs.dtypes, scipy.optimize._slsqp, , pandas._libs.properties, pandas._libs.tslibs.np_datetimescipy.optimize._slsqp, pandas._libs.tslibs.base, , , pandas._libs.tslibs.dtypesscipy.optimize._minpackpandas._libs.tslibs.offsets, scipy.optimize._minpackpandas._libs.tslibs.nattype, , , , pandas._libs.tslibs.base, scipy.optimize._lsq.givens_eliminationpandas._libs.tslibs.strptimepandas._libs.tslibs.timezonesscipy.optimize._lsq.givens_elimination, , , , pandas._libs.tslibs.nattypepandas._libs.tslibs.parsing, scipy.optimize._zerospandas._libs.tslibs.fieldsscipy.optimize._zeros, , , , pandas._libs.tslibs.timezones, scipy.optimize._cython_nnlspandas._libs.tslibs.conversionpandas._libs.tslibs.timedeltasscipy.optimize._cython_nnls, , , , pandas._libs.tslibs.fieldsscipy._lib._uarray._uarray, pandas._libs.tslibs.periodpandas._libs.tslibs.tzconversion, scipy._lib._uarray._uarray, , pandas._libs.tslibs.timedeltas, scipy.special._ufuncs_cxxpandas._libs.tslibs.vectorized, pandas._libs.tslibs.timestamps, scipy.special._ufuncs_cxxpandas._libs.tslibs.tzconversion, , , , , scipy.special._ufuncspandas._libs.ops_dispatchpandas._libs.propertiespandas._libs.tslibs.timestampsscipy.special._ufuncs, , , , pandas._libs.missing, scipy.special._specfun, pandas._libs.tslibs.offsetspandas._libs.propertiespandas._libs.hashtable, scipy.special._specfun, , scipy.special._comb, pandas._libs.tslibs.strptime, pandas._libs.tslibs.offsetspandas._libs.algos, scipy.special._comb, , , pandas._libs.tslibs.parsingscipy.special._ellip_harm_2pandas._libs.tslibs.strptimepandas._libs.interval, , , , scipy.special._ellip_harm_2pandas._libs.tslibs.conversion, scipy.linalg._decomp_interpolativepandas._libs.tslibs.parsing, pandas._libs.lib, pandas._libs.tslibs.period, , , scipy.linalg._decomp_interpolativepandas._libs.tslibs.conversionscipy.optimize._bglu_dense, pyarrow._compute, , pandas._libs.tslibs.vectorized, pandas._libs.tslibs.periodscipy.optimize._bglu_dense, pandas._libs.ops, scipy.optimize._lsap, , pandas._libs.ops_dispatch, pandas._libs.tslibs.vectorizedscipy.optimize._lsap, pandas._libs.hashing, , scipy.spatial._ckdtree, scipy.spatial._ckdtreepandas._libs.ops_dispatchpandas._libs.missing, , , , pandas._libs.missingpandas._libs.arrays, scipy.spatial._qhullscipy.spatial._qhull, pandas._libs.hashtable, , pandas._libs.hashtablepandas._libs.tslib, scipy.spatial._voronoi, , scipy.spatial._voronoi, pandas._libs.algospandas._libs.algos, pandas._libs.sparse, scipy.spatial._distance_wrap, , , scipy.spatial._distance_wrappandas._libs.internalspandas._libs.intervalpandas._libs.interval, , , , pandas._libs.indexingscipy.spatial._hausdorff, scipy.spatial._hausdorffpandas._libs.lib, pandas._libs.lib, pandas._libs.index, , , pyarrow._computescipy.spatial.transform._rotationscipy.spatial.transform._rotationpyarrow._compute, , , , pandas._libs.writerspandas._libs.opsscipy.optimize._direct, scipy.optimize._direct, , pandas._libs.opspandas._libs.joinpandas._libs.hashing, , pandas._libs.hashing, pandas._libs.arrays, , pandas._libs.window.aggregations, setproctitle._setproctitle, setproctitle._setproctitlepandas._libs.arrays, pandas._libs.tslibpandas._libs.window.indexers, , pandas._libs.tslibpandas._libs.sparse, , , , pandas._libs.internals, pandas._libs.reshapeCython.Utilspandas._libs.sparseCython.Utils, , , pandas._libs.internals, pandas._libs.indexingpandas._libs.groupby, Cython.Plex.Actions, , Cython.Plex.Actions, pandas._libs.indexpandas._libs.indexing, pandas._libs.jsonCython.Plex.Transitions, , , , Cython.Plex.Transitionspandas._libs.writers, pandas._libs.indexpandas._libs.parsers, , pandas._libs.joinCython.Plex.Machines, , Cython.Plex.Machinespandas._libs.writers, pandas._libs.testing, pandas._libs.window.aggregations, , Cython.Plex.DFApandas._libs.joinCython.Plex.DFA, , , , pandas._libs.window.indexerspandas._libs.window.aggregationspyarrow._parquet, Cython.Plex.Scanners, , pandas._libs.reshape, Cython.Plex.Scannerspandas._libs.window.indexerspyarrow._fs, , , Cython.Compiler.Scanning, , Cython.Compiler.Scanningpandas._libs.groupbypandas._libs.reshape, pyarrow._azurefsCython.StringIOTree, , , Cython.StringIOTree, pandas._libs.groupbypandas._libs.json, , pyarrow._hdfsCython.Compiler.CodeCython.Compiler.Code, , , pandas._libs.parserspandas._libs.jsonpyarrow._gcsfs, , , , google._upb._messagegoogle._upb._messagepandas._libs.parsers, pandas._libs.testingpyarrow._s3fs, pandas._libs.testing, pyarrow._parquet, xxhash._xxhash, , pyarrow._parquetpyarrow._fs, pyarrow._acero, , , pyarrow._fspyarrow._azurefspyarrow._csv, , pyarrow._azurefspyarrow._hdfs, pyarrow._json, , pyarrow._hdfspyarrow._gcsfs, pyarrow._substrait, , pyarrow._gcsfspyarrow._s3fs, pyarrow._dataset, , , msgspec._corexxhash._xxhashpyarrow._s3fs, , pyarrow._dataset_orc, msgspec._core, , pyarrow._parquet_encryptionpyarrow._acero, xxhash._xxhash, , pyarrow.lib, pyarrow._dataset_parquet_encryptionpyarrow._csv, pyarrow._acero, pyarrow.lib, , , pandas._libs.tslibs.ccalendarpyarrow._jsonpyarrow._csvpyarrow._dataset_parquet, , , pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetimepyarrow._substraitpyarrow._json, , , pandas._libs.tslibs.np_datetime, pyarrow._datasetpandas._libs.tslibs.dtypespyarrow._substrait, , , pandas._libs.tslibs.dtypes, pyarrow._dataset_orcpandas._libs.tslibs.basepyarrow._dataset, , , pandas._libs.tslibs.basepyarrow._parquet_encryption, pandas._libs.tslibs.nattypepyarrow._dataset_orc, , , pandas._libs.tslibs.nattypepyarrow._dataset_parquet_encryption, pandas._libs.tslibs.timezonespyarrow._parquet_encryption, , , pyarrow._dataset_parquet, pandas._libs.tslibs.timezonespandas._libs.tslibs.fieldspyarrow._dataset_parquet_encryption, , pandas._libs.tslibs.fields, pyarrow._dataset_parquetpandas._libs.tslibs.timedeltas, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, , pandas._libs.tslibs.tzconversionpandas._libs.tslibs.timestamps, , pandas._libs.tslibs.timestampspandas._libs.properties, , , __triton_launcherpandas._libs.propertiespandas._libs.tslibs.offsets (total: , 174, pandas._libs.tslibs.offsets)pandas._libs.tslibs.strptime, 
pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, , pandas._libs.tslibs.parsingpandas._libs.tslibs.conversion, , pandas._libs.tslibs.conversionpandas._libs.tslibs.period, , pandas._libs.tslibs.periodpandas._libs.tslibs.vectorized, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, , pandas._libs.ops_dispatch, __triton_launcherpandas._libs.missing,  (total: pandas._libs.missing, 174pandas._libs.hashtable), , 
__triton_launcher, pandas._libs.hashtablepandas._libs.algos (total: , 174pandas._libs.algos, )pandas._libs.interval, 
pandas._libs.interval, pandas._libs.lib, pandas._libs.lib, pyarrow._compute, , pyarrow._computepandas._libs.ops, , pandas._libs.opspandas._libs.hashing, pandas._libs.hashing, pandas._libs.arrays, , pandas._libs.arrayspandas._libs.tslib, , pandas._libs.tslibpandas._libs.sparse, , pandas._libs.sparsepandas._libs.internals, , pandas._libs.internalspandas._libs.indexing, , pandas._libs.indexingpandas._libs.index, , pandas._libs.indexpandas._libs.writers, , pandas._libs.writerspandas._libs.join, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.aggregations, pandas._libs.window.indexers, , pandas._libs.window.indexerspandas._libs.reshape, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.groupby, pandas._libs.json, pandas._libs.json, pandas._libs.parsers, , pandas._libs.parserspandas._libs.testing, pandas._libs.testing, pyarrow._parquet, , pyarrow._parquetpyarrow._fs, , pyarrow._fspyarrow._azurefs, , pyarrow._azurefspyarrow._hdfs, , pyarrow._hdfspyarrow._gcsfs, , pyarrow._gcsfspyarrow._s3fs, pyarrow._s3fs, xxhash._xxhash, xxhash._xxhash, pyarrow._acero, , pyarrow._aceropyarrow._csv, , pyarrow._csvpyarrow._json, , pyarrow._jsonpyarrow._substrait, pyarrow._substrait, pyarrow._dataset, pyarrow._dataset, , pyarrow._dataset_orcpyarrow._dataset_orc, , pyarrow._parquet_encryptionpyarrow._parquet_encryption, pyarrow._dataset_parquet_encryption, pyarrow._dataset_parquet_encryption, pyarrow._dataset_parquet, pyarrow._dataset_parquet, __triton_launcher,  (total: __triton_launcher174)
 (total: 174)
[2026-01-14 12:10:45] Scheduler or DataParallelController 1118 terminated with -3
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/launch_server.py", line 32, in <module>
    run_server(server_args)
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/launch_server.py", line 25, in run_server
    launch_server(server_args)
  File "/usr/local/python3.11.13/lib/python3.11/site-packages/sglang/srt/entrypoints/http_server.py", line 1707, in launch_server
    scheduler_info = scheduler_infos[0]
                     ~~~~~~~~~~~~~~~^^^
TypeError: 'NoneType' object is not subscriptable
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
................[ERROR] 2026-01-14-12:10:46 (PID:804, Device:-1, RankID:-1) ERR99999 UNKNOWN applicaiton exception
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
[ERROR] TBE Subprocess[task_distribute] raise error[], main process disappeared!
